layer: InputScaling
  scale: [
    1, 1,
  ]
layer: FullyConnected
  weights[0]: [
    1.91, -1.77,
  ]
  weights[1]: [
    -0.601, -0.533,
  ]
  weights[2]: [
    -1.4, -0.102,
  ]
  weights[3]: [
    -0.527, -0.78,
  ]
  weights[4]: [
    0.718, -1.16,
  ]
  weights[5]: [
    0.435, 0.132,
  ]
  weights[6]: [
    0.866, -0.0849,
  ]
  weights[7]: [
    -0.775, 0.635,
  ]
  weights[8]: [
    -0.526, -1.29,
  ]
  weights[9]: [
    -1.2, 1.06,
  ]
  weights[10]: [
    -0.936, -0.537,
  ]
  weights[11]: [
    -1.06, 0.829,
  ]
  weights[12]: [
    1.35, 0.532,
  ]
  weights[13]: [
    -1.65, -0.218,
  ]
  weights[14]: [
    -0.853, 0.853,
  ]
  weights[15]: [
    0.239, 1.65,
  ]
  weights[16]: [
    -0.425, -0.148,
  ]
  weights[17]: [
    0.413, -0.69,
  ]
  weights[18]: [
    -1.42, 0.292,
  ]
  weights[19]: [
    1.08, -1.08,
  ]
  weights[20]: [
    1.29, -1.29,
  ]
  weights[21]: [
    -1.31, 1.35,
  ]
  weights[22]: [
    0.812, -0.812,
  ]
  weights[23]: [
    -0.438, -0.0569,
  ]
  weights[24]: [
    -0.393, -0.706,
  ]
  weights[25]: [
    1.3, 0.608,
  ]
  weights[26]: [
    0.127, 0.816,
  ]
  weights[27]: [
    1.01, -1.34,
  ]
  weights[28]: [
    -0.446, -0.947,
  ]
  weights[29]: [
    0.526, 0.114,
  ]
  weights[30]: [
    0.909, -1.13,
  ]
  weights[31]: [
    -1.13, 0.815,
  ]
  biases: [
    -0.137, 0.347, -0.114, -0.00293, 0.399, 0.0391, 0.107, -0.0784,
    0.128, 0.141, 0.643, 0.233, -0.145, -0.174, 5.63e-05, 0.728,
    0.463, 0.277, 0.245, 6.04e-06, 2.37e-05, -0.0386, -8.92e-05, -0.026,
    0.488, 0.507, -0.109, 0.329, -0.11, -0.57, 0.431, 1.14e-05,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.26, 0.244, 0.292, 0.281, 0.274, 0.25, 0.25, 0.471,
    0.329, 0.148, 0.24, 0.166, 0.226, 0.328, 0.15, 0.25,
    0.233, 0.232, 0.274, 0.232, 0.223, 0.171, 0.219, 0.249,
    0.26, 0.25, 1.52, 0.238, 0.251, 0.473, 0.258, 0.207,
  ]
layer: BatchNormalization
  weights: [
    1.36, 5.38, 4.76, 8.42, 2.16, 4.74, 2.26, 2.97,
    4.26, 1.92, 3.43, 2.29, 1.51, 3.84, 2.67, 1.26,
    5.14, 3.38, 3.03, 2.1, 1.72, 1.76, 2.95, 18,
    4.53, 1.36, 2.44, 1.75, 7.15, 7.2, 1.85, 2.86,
  ]
  biases: [
    -0.571, -0.0423, 1.15, 1.58, -0.731, -1.52, -1.12, -0.0766,
    1.01, -0.525, -0.364, -0.644, -1.28, 1.31, -0.549, -1.96,
    -0.92, -0.688, -0.146, -0.457, -0.496, -0.671, -0.51, 1.22,
    -0.401, -1.89, -0.895, -0.587, 1.42, 0.693, -0.827, -0.502,
  ]
layer: FullyConnected
  weights[0]: [
    -0.166, -0.122, 0.0237, 0.207, -0.151, 0.109, -0.146, 0.181,
    -0.0575, 0.232, 0.151, 0.0627, -0.234, -0.00884, 0.159, 0.024,
    -0.0263, -0.218, 0.252, -0.192, 0.144, 0.136, -0.0419, 0.137,
    0.0235, -0.0178, -0.02, 0.0765, 0.15, -0.0581, 0.157, 0.24,
  ]
  weights[1]: [
    -0.209, -0.0609, -0.00888, -0.158, -0.0322, 0.0446, -0.266, -0.104,
    0.0425, 0.155, 0.154, 0.217, 0.0797, 0.114, 0.262, 0.262,
    0.148, 0.013, 0.118, 0.131, -0.0617, -0.114, 0.127, 0.218,
    -0.234, 0.0727, 0.0378, -0.205, 0.0405, 0.0813, 0.145, 0.123,
  ]
  weights[2]: [
    -0.0804, -0.11, -0.228, -0.195, -0.132, -0.0905, -0.124, -0.177,
    -0.259, 0.0175, -0.134, 0.141, 0.289, -0.179, 0.0514, 0.114,
    -0.0282, 0.0548, -0.174, 0.0751, 0.0784, 0.124, -0.184, -0.0141,
    -0.244, -0.0109, 0.165, -0.0827, -0.132, 0.144, 0.125, -0.198,
  ]
  weights[3]: [
    0.145, 0.0637, 0.0857, 0.0401, 0.211, 0.198, 0.0347, 0.0433,
    0.105, -0.117, -0.127, 0.0597, -0.0286, 0.094, -0.173, 0.0946,
    -0.00986, 0.139, 0.041, -0.0636, 0.0405, -0.0355, 0.122, -0.203,
    -0.0664, -0.0631, -0.0813, 0.0783, 0.196, 0.177, 0.108, -0.214,
  ]
  weights[4]: [
    -0.152, -0.106, 0.113, 0.105, -0.051, 0.0734, -0.031, 0.119,
    0.108, -0.0612, 0.0785, 0.078, 0.0564, -0.136, -0.0307, 0.133,
    0.00385, -0.103, 0.0632, -0.196, -0.107, -0.281, -0.203, -0.209,
    0.0322, 0.143, -0.134, 0.181, 0.0563, -0.00101, -0.121, -0.219,
  ]
  weights[5]: [
    -0.12, -0.177, 0.0445, 0.215, 0.173, -0.0658, -0.0189, -0.0828,
    0.206, 0.197, -0.187, 0.0056, 0.118, 0.039, -0.192, -0.091,
    -0.0941, -0.122, 0.158, 0.0566, 0.0827, -0.164, 0.0233, -0.219,
    -0.152, 0.0702, -0.038, 0.127, 0.0433, -0.0473, 0.238, 0.194,
  ]
  weights[6]: [
    0.0435, -0.246, 0.0545, -0.352, -0.144, 0.162, -0.0177, -0.0617,
    -0.316, 0.0339, -0.148, 0.0682, 0.23, -0.289, 0.048, 0.0801,
    -0.138, -0.217, 0.0153, 0.0403, -0.227, -0.202, 0.0278, 0.00962,
    0.0497, 0.128, -0.0285, 0.0308, -0.211, 0.158, -0.139, -0.271,
  ]
  weights[7]: [
    -0.284, 0.169, 0.00651, 0.162, -0.127, 0.171, -0.148, -0.211,
    -0.0206, 0.14, 0.133, -0.0188, 0.028, -0.219, -0.158, 0.151,
    0.0797, -0.168, -0.102, -0.0103, -0.281, -0.122, -0.201, -0.0146,
    0.0481, 0.155, -0.237, -0.0259, -0.164, -0.155, 0.0784, -0.232,
  ]
  weights[8]: [
    -0.307, -0.146, -0.119, -0.274, -0.106, 0.0726, 0.124, -0.0773,
    -0.157, -0.128, -0.191, -0.221, 0.235, -0.169, -0.129, 0.191,
    0.069, -0.0663, -0.228, -0.135, -0.286, -0.272, -0.0939, -0.257,
    -0.234, 0.319, 0.188, 0.0423, -0.0502, 0.28, -0.301, -0.281,
  ]
  weights[9]: [
    0.312, -0.207, -0.17, 0.184, 0.136, -0.0539, 0.222, -0.0733,
    0.0353, -0.125, -0.123, -0.011, 0.144, -0.0168, -0.1, 0.032,
    0.127, 0.345, 0.0679, 0.236, 0.19, -0.0893, 0.183, -0.267,
    0.137, 0.083, -0.203, 0.0518, 0.0635, 0.226, 0.0921, 0.12,
  ]
  weights[10]: [
    -0.0288, 0.113, -0.18, 0.0782, -0.172, -0.141, 0.0894, 0.24,
    -0.0844, -0.0926, 0.177, 0.179, -0.142, 0.0812, -0.0693, 0.206,
    -0.00985, -0.033, 0.163, 0.018, 0.139, 0.0721, -0.132, -0.143,
    -0.265, -0.0892, -0.0473, 0.133, 0.0161, 0.0731, -0.223, 0.00521,
  ]
  weights[11]: [
    0.0702, -0.134, 0.107, 0.0361, 0.144, 0.136, 0.143, -0.0654,
    0.23, -0.0832, -0.0358, -0.028, 0.157, -0.262, -0.131, -0.0321,
    -0.0449, 0.178, -0.0519, 0.105, 0.137, 0.129, 0.126, -0.0233,
    0.151, -0.141, -0.0789, 0.249, -0.0882, 0.0954, 0.225, -0.226,
  ]
  weights[12]: [
    -0.0834, -0.0656, 0.156, -0.071, -0.00325, -0.197, 0.0434, -0.124,
    0.0916, -0.248, 0.114, -0.198, 0.177, 0.179, -0.305, 0.00239,
    0.268, -0.158, -0.148, -0.0868, -0.0248, -0.239, -0.196, -0.177,
    0.267, 0.139, 0.00923, -0.116, 0.116, -0.1, -0.0894, -0.29,
  ]
  weights[13]: [
    -0.0193, 0.0453, -0.26, -0.244, -0.116, 0.208, -0.116, 0.126,
    -0.196, 0.0606, -0.178, -0.259, 0.0954, -0.0758, -0.263, 0.164,
    -0.23, -0.194, 0.0218, -0.167, -0.0705, -0.181, -0.202, 0.0767,
    -0.0691, 0.215, 0.0843, -0.149, -0.0148, 0.0245, -0.0728, -0.175,
  ]
  weights[14]: [
    -0.199, 0.0882, -0.244, -0.136, -0.0934, 0.0876, 0.0986, -0.0766,
    0.0922, -0.237, 0.308, -0.286, -0.192, -0.0311, -0.246, -0.157,
    0.00901, -0.0231, -0.23, -0.264, -0.203, -0.0382, -0.0859, 0.138,
    0.111, 0.0568, 0.173, -0.185, 0.16, 0.162, -0.141, -0.25,
  ]
  weights[15]: [
    -0.0267, 0.137, 0.105, 0.227, 0.158, -0.265, -0.0938, 0.0949,
    -0.0612, -0.141, 0.0539, -0.077, -0.227, 0.221, -0.0477, 0.0665,
    0.0762, 0.0938, -0.0612, -0.0919, 0.0496, -0.214, -0.187, -0.0697,
    0.206, -0.113, -0.268, 0.0813, 0.124, 0.056, 0.0426, 0.0246,
  ]
  weights[16]: [
    -0.177, 0.119, 0.186, 0.253, -0.00136, -0.00539, -0.17, -0.19,
    0.258, 0.0948, 0.329, 0.08, -0.036, 0.132, -0.144, -0.0144,
    0.0882, 0.239, -0.157, -0.12, -0.0904, -0.22, -0.0901, 0.216,
    0.287, -0.0907, -0.237, 0.161, 0.087, -0.148, -0.000672, -0.0443,
  ]
  weights[17]: [
    -0.0369, -0.174, -0.0325, 0.178, -0.0935, -0.085, -0.0272, -0.0361,
    -0.137, 0.263, -0.0365, -0.00297, 0.145, 0.0808, 0.0123, 0.241,
    0.177, 0.126, 0.207, -0.232, -0.0962, 0.206, -0.227, 0.185,
    0.0189, -0.00156, 0.167, -0.0572, 0.0789, 0.0815, 0.0561, 0.0616,
  ]
  weights[18]: [
    0.27, -0.0905, -0.198, -0.0702, 0.215, 0.193, 0.167, -0.244,
    0.198, -0.0348, -0.00896, 0.0974, 0.189, -0.105, 0.101, 0.0774,
    0.17, 0.215, -0.0265, 0.104, 0.08, 0.112, 0.336, 0.0831,
    0.049, -0.0543, 0.0314, 0.206, 0.037, -0.128, 0.236, -0.0953,
  ]
  weights[19]: [
    0.0341, -0.027, -0.152, 0.155, 0.0424, -0.172, 0.0368, -0.0744,
    -0.152, 0.221, -0.261, 0.232, -0.243, -0.0178, 0.225, 0.148,
    -0.0379, 0.209, 0.176, 0.121, 0.17, 0.0243, 0.201, -0.0691,
    -0.19, 0.112, 0.0349, 0.25, -0.16, -0.22, 0.048, 0.184,
  ]
  weights[20]: [
    -0.00295, -0.2, 0.16, -0.105, -0.000876, -0.146, 0.0863, -0.114,
    -0.0201, 0.0987, -0.153, 0.0659, -0.034, -0.203, -0.172, 0.0144,
    -0.208, 0.228, 0.185, 0.294, -0.114, -0.139, 0.197, -0.182,
    0.172, 0.169, -0.221, 0.184, -0.151, -0.179, 0.217, 0.198,
  ]
  weights[21]: [
    -0.203, -0.189, -0.113, 0.0913, -0.0397, 0.221, -0.122, -0.0534,
    -0.157, 0.0109, -0.229, -0.0584, 0.198, -0.252, 0.178, -0.0694,
    -0.106, 0.0677, 0.0146, -0.179, -0.0448, 0.156, 0.0336, 0.0809,
    -0.0729, -0.0511, 0.1, 0.165, 0.214, 0.0404, 0.13, -0.21,
  ]
  weights[22]: [
    -0.0768, 0.265, 0.0868, 0.251, 0.0983, -0.228, 0.105, -0.00446,
    0.125, -0.0229, -0.0902, 0.11, 0.0142, 0.22, -0.0143, 0.134,
    0.14, 0.2, 0.0323, -0.0922, -0.136, -0.241, -0.0529, -0.0774,
    0.14, 0.0146, -0.146, 0.0435, -0.104, -0.0753, -0.0124, 0.0109,
  ]
  weights[23]: [
    0.3, -0.0835, -0.163, -0.11, 0.262, -0.18, 0.152, -0.236,
    -0.14, -0.0908, 0.115, -0.187, -0.0686, -0.132, 0.155, 0.0886,
    0.0998, -0.0729, -0.176, 0.209, 0.196, 0.0546, 0.0204, -0.0256,
    -0.0564, -0.03, 0.0642, 0.0296, 0.0903, -0.157, 0.272, 0.0529,
  ]
  weights[24]: [
    -0.0799, 0.0652, 0.116, 0.151, 0.0214, 0.0366, 0.0457, 0.0383,
    0.138, -0.0181, 0.175, -0.089, -0.143, -0.0552, -0.208, 0.198,
    -0.194, -0.0921, -0.111, 0.252, 0.23, 0.0802, 0.206, 0.115,
    -0.212, 0.0781, -0.056, 0.205, -0.0478, -0.0257, -0.128, -0.0504,
  ]
  weights[25]: [
    -0.248, 0.156, 0.0667, 0.27, 0.182, -0.248, 0.103, -0.107,
    -0.0735, -0.241, 0.259, -0.137, -0.0299, 0.0157, -0.0996, 0.0492,
    0.0689, 0.231, 0.22, 0.0105, -0.256, -0.195, -0.183, 0.189,
    0.187, 0.0643, -0.259, 0.00288, 0.023, -0.141, -0.0977, -0.215,
  ]
  weights[26]: [
    -0.228, 0.112, 0.156, 0.00788, 0.0555, -0.108, 0.107, -0.208,
    -0.0821, 0.134, 0.045, 0.0327, -0.0967, -0.0816, -0.179, -0.0645,
    0.00866, 0.0949, 0.111, -0.132, -0.0858, -0.153, -0.242, -0.047,
    0.227, -0.0287, -0.166, 0.0772, 0.225, -0.213, 0.0565, -0.237,
  ]
  weights[27]: [
    0.157, -0.081, -0.0232, -0.233, -0.0847, -0.0376, 0.105, 0.0331,
    -0.128, -0.167, 0.0331, -0.0891, 0.2, 0.157, 0.0387, 0.119,
    -0.094, -0.203, -0.158, 0.0747, -0.106, -0.178, -0.131, -0.0308,
    0.0913, -0.164, 0.0869, -0.0691, -0.0107, 0.234, 0.129, 0.175,
  ]
  weights[28]: [
    0.141, -0.168, -0.0152, -0.247, -0.0874, 0.0887, 0.109, -0.217,
    -0.00304, -0.0246, 0.161, 0.0338, 0.112, -0.0864, 0.116, 0.185,
    -0.157, -0.0936, -0.134, -0.0402, -0.0912, -0.044, -0.195, 0.00227,
    -0.191, 0.116, 0.0636, -0.118, 0.0904, -0.0179, 0.0946, -0.114,
  ]
  weights[29]: [
    -0.28, 0.252, 0.211, -0.157, -0.00977, -0.215, -0.00569, -0.152,
    0.245, 0.21, 0.243, 0.141, -0.055, 0.234, 0.0843, 0.0946,
    0.158, 0.0387, 0.192, -0.122, -0.193, 0.136, -0.268, 0.169,
    0.056, -0.0896, -0.081, -0.0218, -0.139, -0.0504, 0.0445, -0.103,
  ]
  weights[30]: [
    -0.262, -0.00928, 0.0466, -0.0216, 0.00195, 0.238, -0.0479, -0.139,
    -0.0388, 0.145, -0.154, -0.219, -0.0667, -0.0936, -0.139, 0.121,
    0.0668, 0.0921, -0.268, 0.063, -0.0808, -0.195, -0.215, 0.0394,
    -0.184, 0.139, 0.0659, -0.279, -0.0319, -0.00769, -0.0404, -0.288,
  ]
  weights[31]: [
    -0.218, -0.0796, 0.188, 0.0325, -0.115, 0.0669, 0.0309, -0.0682,
    0.0959, 0.224, -0.203, 0.238, -0.154, 0.0905, -0.108, 0.273,
    0.00758, -0.136, 0.16, -0.224, 0.1, 0.134, -0.0733, 0.257,
    0.0442, 0.145, 0.132, 0.0399, -0.212, -0.243, -0.0333, 0.11,
  ]
  biases: [
    0.0161, 0.0554, -0.0844, -0.0973, 0.166, -0.0217, -0.00967, 0.176,
    0.00195, 0.12, 0.0221, 0.0689, 0.0755, 0.132, 0.123, 0.0319,
    0.0157, 0.00158, 0.0924, 0.129, 0.0153, -0.00457, 0.0371, 0.0675,
    -0.032, 0.159, 0.0626, -0.00957, -0.0343, 0.0786, 0.0442, 0.0445,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.319, 0.198, 0.283, 0.299, 0.311, 0.312, 0.206, 0.311,
    0.292, 0.132, 0.215, 0.0842, 0.402, 0.234, 0.304, 0.191,
    0.192, 0.197, 0.182, 0.311, 0.301, 0.217, 0.256, 0.165,
    0.279, 0.252, 0.265, 0.228, 0.252, 0.318, 0.268, 0.15,
  ]
layer: BatchNormalization
  weights: [
    0.755, 1.17, 0.822, 0.976, 2.1, 1.65, 0.725, 1.81,
    0.498, 0.616, 1.72, 0.778, 1.25, 0.673, 1.35, 0.815,
    0.623, 0.921, 0.72, 1.58, 1.13, 1.61, 1.07, 0.887,
    1.59, 0.687, 0.953, 1.53, 1.06, 0.608, 1, 0.826,
  ]
  biases: [
    -0.544, -0.479, -0.548, -0.409, -0.75, -0.429, -0.627, -1.05,
    -0.637, -0.504, -0.384, -0.818, -0.613, -0.47, -0.805, -0.629,
    -0.6, -0.414, -0.49, -0.547, -0.573, -0.593, -0.558, -0.453,
    -0.428, -0.517, -0.561, -0.542, -0.545, -0.498, -0.424, -0.457,
  ]
layer: FullyConnected
  weights[0]: [
    0.0106, -0.0953, -0.0569, -0.059, 0.263, -0.261, 0.294, 0.316,
    -0.00311, -0.226, -0.292, -0.407, 0.0648, 0.153, 0.289, 0.123,
    0.288, -0.314, -0.416, -0.0628, -0.219, 0.000331, 0.141, -0.259,
    0.129, 0.169, 0.0576, -0.0318, 0.219, -0.0326, 0.101, -0.0394,
  ]
  weights[1]: [
    -0.00926, -0.191, 0.192, 0.00976, 0.0275, 0.0548, 0.305, 0.301,
    0.211, -0.273, -0.144, -0.368, -0.0714, 0.155, 0.111, 0.246,
    0.296, -0.0346, -0.281, -0.000837, 0.109, 0.115, 0.0717, -0.183,
    -0.087, -0.0564, 0.254, 0.157, 0.13, -0.0577, 0.101, -0.122,
  ]
  weights[2]: [
    -0.0343, -0.169, -0.0872, -0.0595, 0.0192, 0.0166, 0.408, 0.238,
    0.184, -0.203, -0.13, -0.235, 0.115, 0.353, 0.241, -0.104,
    0.3, -0.00488, -0.402, 0.0698, -0.278, 0.104, 0.329, -0.27,
    0.0847, 0.298, 0.121, 0.0316, -0.0628, 0.18, 0.0165, 0.0797,
  ]
  weights[3]: [
    -0.0667, -0.0204, 0.146, 0.275, -0.193, 0.134, -0.142, -0.239,
    -0.095, 0.241, -0.147, 0.15, 0.0762, -0.151, 0.0375, -0.189,
    -0.24, -0.186, 0.294, 0.0916, 0.0719, 0.0441, -0.0503, 0.265,
    0.248, -0.0141, -0.0661, -0.19, -0.0843, -0.226, -0.108, 0.192,
  ]
  weights[4]: [
    0.0819, 0.315, -0.0702, -0.0473, 0.0204, -0.0283, -0.0224, -0.229,
    -0.2, 0.273, 0.258, 0.116, -0.114, -0.0117, -0.28, 0.0803,
    -0.155, 0.282, 0.221, -0.00702, 0.0142, -0.0268, -0.182, 0.0711,
    0.24, -0.23, -0.193, -0.27, -0.214, -0.0552, 0.0804, 0.235,
  ]
  weights[5]: [
    -0.28, -0.186, 0.205, -0.277, -0.0473, -0.17, 0.179, 0.341,
    0.145, -0.154, -0.071, 0.08, 0.112, 0.279, 0.119, 0.121,
    -0.146, -0.279, -0.0529, -0.105, -0.0475, 0.016, -0.206, -0.23,
    -0.231, -0.00974, -0.0237, 0.0259, 0.268, -0.121, 0.305, -0.103,
  ]
  weights[6]: [
    -0.264, -0.204, 0.047, -0.22, 0.326, -0.277, 0.24, 0.273,
    0.278, -0.276, -0.132, -0.19, 0.234, 0.191, 0.364, 0.135,
    0.219, -0.248, -0.0838, -0.257, -0.159, -0.0357, 0.229, -0.26,
    -0.0495, 0.321, 0.306, 0.243, 0.173, -0.000944, 0.203, -0.356,
  ]
  weights[7]: [
    3.37e-05, -0.0572, -0.0223, 0.0992, -0.0325, 0.169, -0.114, 0.0407,
    0.0345, 0.19, 0.0119, 0.104, 0.0734, -0.116, -0.165, -0.0356,
    -0.198, 0.0514, 0.112, -0.0751, 0.141, -0.0717, -0.165, -0.0403,
    0.0509, 0.0784, -0.0611, -0.0924, -0.101, -0.173, -0.155, 0.0337,
  ]
  weights[8]: [
    0.0725, 0.155, -0.0198, 0.0883, -0.172, 0.29, -0.0241, -0.332,
    -0.381, 0.304, -0.0756, 0.241, -0.0379, -0.169, -0.128, -0.0641,
    -0.0157, -0.00824, 0.189, 0.247, 0.173, -0.171, -0.218, 0.208,
    0.11, -0.287, -0.296, -0.0853, -0.223, -0.209, -0.0529, 0.148,
  ]
  weights[9]: [
    -0.108, 0.129, -0.11, -0.19, 0.114, -0.106, -0.165, -0.295,
    0.00349, 0.2, 0.157, 0.0306, 0.00921, 0.0942, -0.237, -0.169,
    -0.358, -0.0113, 0.201, 0.126, 0.234, 0.0756, 0.148, -0.00455,
    0.0985, 0.11, -0.0325, -0.329, 0.0442, 0.0726, -0.126, 0.207,
  ]
  weights[10]: [
    -0.276, 0.0642, 0.0838, 0.111, 0.266, -0.131, 0.249, -0.0317,
    0.288, -0.0171, -0.208, 0.0758, -0.00732, 0.291, 0.117, -0.0323,
    0.155, 0.073, -0.0844, -0.232, -0.136, 0.0947, -0.146, -0.0914,
    -0.131, 0.0905, -0.0756, 0.176, -0.0093, -0.237, 0.256, 0.0669,
  ]
  weights[11]: [
    -0.251, -0.254, 0.0999, 0.0719, 0.106, -0.0853, 0.309, 0.267,
    0.232, -0.319, -0.242, -0.0182, 0.184, 0.129, 0.132, 0.213,
    -0.0411, -0.244, -0.245, -0.299, -0.142, -0.0317, 0.314, -0.265,
    0.0729, 0.0881, 0.216, 0.202, 0.0798, -0.0384, 0.237, -0.189,
  ]
  weights[12]: [
    0.0627, -0.0932, -0.106, 0.14, -0.269, 0.0957, -0.0865, -0.345,
    -0.0433, 0.263, 0.229, 0.173, 0.00461, -0.139, 0.0511, -0.147,
    -0.121, 0.0844, 0.156, 0.168, 0.186, 0.172, 0.0582, 0.0421,
    0.12, -0.0169, -0.0603, -0.0771, -0.247, -0.118, -0.008, 0.00244,
  ]
  weights[13]: [
    0.0726, 0.281, -0.191, -0.16, -0.0132, -0.0268, -0.241, 0.0366,
    -0.228, -0.125, 0.167, -0.268, -0.0947, 0.116, -0.251, 0.0208,
    -0.205, -0.00461, -0.0577, -0.0595, -0.176, -0.195, -0.296, 0.0769,
    0.0301, -0.082, -0.0638, -0.0761, -0.11, 0.149, 0.0471, 0.203,
  ]
  weights[14]: [
    0.091, 0.00777, -0.265, -0.0333, 0.0496, -0.135, -0.204, 0.124,
    0.0306, -0.0245, 0.0809, 0.0349, 0.316, -0.0987, 0.279, 0.121,
    0.23, -0.0864, 0.0815, -0.00348, -0.17, -0.18, 0.214, 0.0919,
    -0.126, -0.0228, 0.176, 0.104, 0.0174, 0.233, -0.017, -0.224,
  ]
  weights[15]: [
    0.21, 0.0139, -0.247, 0.0928, -0.266, 0.199, -0.272, -0.119,
    -0.229, 0.0473, 0.291, 0.0483, -0.345, -0.284, -0.348, -0.167,
    -0.26, 0.146, 0.258, 0.18, 0.0343, -0.0622, -0.248, 0.164,
    0.096, -0.083, -0.255, -0.223, -0.127, 0.0149, -0.209, 0.178,
  ]
  weights[16]: [
    -0.0839, -0.0266, 0.143, -0.118, 0.17, -0.129, -0.13, 0.0569,
    -0.0399, -0.256, 0.0679, -0.331, 0.244, -0.0429, 0.28, -0.0112,
    0.279, -0.0359, -0.111, -0.0819, -0.181, 0.0936, -0.098, -0.112,
    -0.117, -0.0875, -0.122, 0.282, -0.0619, 0.129, 0.144, -0.119,
  ]
  weights[17]: [
    0.0663, 0.368, 0.0336, -0.00595, 0.0745, 0.123, -0.166, -0.11,
    -0.272, -0.0203, 0.156, -0.282, -0.13, -0.179, -0.112, -0.295,
    0.0877, 0.367, -0.11, -0.0944, -0.0114, 0.0246, -0.16, -0.236,
    0.096, -0.0752, 0.000331, -0.0154, -0.076, 0.267, -0.0833, -0.0312,
  ]
  weights[18]: [
    0.151, 0.148, -0.0872, 0.279, -0.158, 0.191, 0.135, -0.1,
    0.115, 0.156, -0.0481, -0.0617, 0.0207, 0.0198, 0.106, 0.0345,
    0.00384, -0.166, 0.222, 0.196, 0.206, 0.152, 0.0874, 0.173,
    0.287, -0.141, -0.249, -0.048, 0.0714, -0.125, -0.124, -0.0535,
  ]
  weights[19]: [
    0.167, 0.336, 0.114, 0.0175, -0.159, -1.69e-05, 0.0393, 0.0535,
    -0.0594, -0.00529, 0.162, -0.275, -0.18, 0.163, -0.219, -0.208,
    -0.296, 0.116, 0.148, 0.0516, -0.0269, -0.187, 0.108, 0.00745,
    -0.183, -0.0903, 0.0621, 0.102, -0.175, 0.213, -0.233, 0.0311,
  ]
  weights[20]: [
    -0.0792, -0.087, -0.0597, -0.0573, 0.0342, -0.00662, 0.094, 0.211,
    -0.167, 0.12, -0.132, -0.041, 0.0801, 0.0153, -0.0597, 0.154,
    -0.0361, -0.0803, 0.105, -0.261, -0.177, 0.0634, 0.197, 0.013,
    -0.1, 0.203, 0.195, 0.0341, -0.221, 0.136, -0.174, 0.141,
  ]
  weights[21]: [
    -0.203, 0.141, -0.0909, -0.00765, 0.153, 0.0362, 0.023, 0.176,
    0.209, 0.04, 0.055, -0.125, 0.06, -0.143, 0.0161, -0.162,
    -0.0198, 0.11, -0.175, 0.0313, 0.0602, 0.234, -0.165, -0.144,
    0.0766, 0.00283, -0.0973, 0.0813, 0.105, -0.0515, -0.073, -0.194,
  ]
  weights[22]: [
    0.197, 0.0361, -0.0108, -0.217, -0.105, -0.136, -0.15, 0.119,
    -0.233, -0.226, 0.0304, 0.0085, -0.268, 0.0637, -0.0418, -0.0711,
    -0.113, 0.342, -0.187, 0.167, -0.176, -0.0597, -0.0394, -0.23,
    -0.0246, -0.234, -0.21, -0.13, 0.0303, 0.277, -0.218, 0.159,
  ]
  weights[23]: [
    0.0142, 0.257, -0.304, -0.0855, -0.0977, 0.249, -0.318, -0.324,
    -0.136, 0.158, 0.0205, 0.0373, 0.0239, -0.129, -0.0934, -0.224,
    -0.173, 0.252, 0.113, 0.123, -0.00836, -0.124, -0.266, 0.0539,
    -0.148, -0.148, -0.256, -0.19, -0.0225, -0.0968, -0.0659, 0.129,
  ]
  weights[24]: [
    -0.181, 0.0822, 0.112, 0.0697, 0.00791, 0.254, 0.0046, -0.18,
    0.0616, 0.22, -0.0553, 0.183, 0.0841, -0.246, 0.0677, -0.107,
    0.177, 0.186, 0.0214, 0.0731, -0.106, -0.0304, 0.0566, 0.246,
    0.1, -0.14, -0.1, 0.188, -0.225, 0.0216, -0.0964, 0.145,
  ]
  weights[25]: [
    -0.0373, 0.0169, 0.0873, 0.173, -0.0467, 0.119, -0.134, -0.314,
    -0.18, 0.0699, -0.0494, 0.242, 0.0348, -0.15, -0.141, -0.123,
    0.13, 0.174, 0.181, 0.135, 0.111, 0.123, -0.257, -0.0969,
    0.112, 0.155, -0.0912, -0.229, 0.0391, -0.184, 0.0298, 0.238,
  ]
  weights[26]: [
    -0.0799, -0.153, -0.168, -0.00288, -0.0156, -0.158, -0.0535, 0.258,
    -0.019, -0.0614, -0.142, -0.142, -0.00657, 0.0124, 0.101, 0.0208,
    0.0963, -0.0311, -0.155, 0.128, -0.165, 0.0696, 0.11, 0.00291,
    0.00131, 0.202, 0.129, -0.0732, 0.0416, 0.201, -0.033, -0.236,
  ]
  weights[27]: [
    0.0479, 0.166, -0.236, -0.0943, -0.0671, 0.0302, -0.353, -0.318,
    -0.0281, 0.155, 0.251, 0.182, -0.298, -0.35, -0.334, 0.0185,
    -0.236, 0.0304, 0.145, 0.286, 0.0435, -0.107, -0.0797, 0.304,
    -0.141, -0.203, 0.104, -0.202, -0.247, 0.0516, -0.0146, 0.0131,
  ]
  weights[28]: [
    0.194, -0.15, -0.162, 0.0247, 0.069, 0.126, -0.0197, -0.0668,
    -0.19, -0.125, 0.00859, 0.0723, 0.00751, -0.105, 0.087, 0.198,
    0.0713, -0.139, 0.049, 0.0799, -0.162, -0.0335, 0.271, -0.022,
    -0.089, -0.0246, 0.225, -0.0449, 0.0754, -0.0381, -0.0246, -0.145,
  ]
  weights[29]: [
    0.0266, -0.101, -0.104, 0.00911, -0.119, -0.122, -0.293, -0.166,
    -0.00534, 0.237, 0.232, -0.0529, -0.287, -0.0201, -0.284, -0.168,
    -0.0639, 0.257, -0.117, 0.218, -0.153, -0.15, -0.177, 0.237,
    0.022, 0.0325, -0.0366, -0.291, -0.029, -0.128, -0.00979, 0.184,
  ]
  weights[30]: [
    -0.223, -0.0657, 0.117, -0.0108, 0.271, -0.232, 0.078, 0.198,
    0.107, -0.163, -0.196, -0.068, 0.211, 0.252, 0.299, 0.0634,
    0.0996, -0.164, -0.119, -0.212, -0.173, 0.12, 0.0903, -0.0807,
    -0.0755, 0.119, 0.0235, 0.214, 0.238, -0.0256, 0.21, -0.141,
  ]
  weights[31]: [
    0.169, 0.175, -0.23, -0.2, 0.142, -0.0801, -0.317, 0.0379,
    -0.305, 0.168, 0.0544, 0.263, -0.177, -0.164, -0.271, -0.14,
    -0.324, 0.0633, 0.266, 0.183, 0.138, -0.141, -0.276, 0.231,
    -0.161, -0.0715, -0.204, -0.227, -0.205, 0.214, 0.054, -0.0136,
  ]
  biases: [
    0.164, 0.146, 0.153, 0.0618, 0.0701, 0.124, 0.317, 0.0127,
    0.147, 0.073, 0.0629, 0.231, 0.0744, 0.0569, 0.0959, 0.196,
    0.0939, 0.156, 0.046, 0.0705, 0.0425, 0.00636, 0.116, 0.0962,
    0.00744, 0.0483, 0.0915, 0.188, 0.00645, 0.0988, 0.184, 0.104,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.535, 0.386, 0.455, 0.252, 0.474, 0.475, 0.667, 0.456,
    0.473, 0.345, 0.282, 0.457, 0.293, 0.263, 0.268, 0.467,
    0.349, 0.234, 0.237, 0.27, 0.313, 0.217, 0.169, 0.369,
    0.271, 0.328, 0.419, 0.4, 0.208, 0.343, 0.492, 0.341,
  ]
layer: BatchNormalization
  weights: [
    0.532, 0.665, 0.662, 0.489, 0.606, 0.491, 0.378, 0.498,
    0.447, 0.97, 0.61, 0.528, 0.69, 0.693, 0.691, 0.445,
    0.815, 0.725, 0.675, 0.744, 0.876, 1.16, 0.559, 0.651,
    1.05, 0.771, 0.87, 0.56, 0.954, 0.699, 0.422, 0.656,
  ]
  biases: [
    -0.437, -0.458, -0.519, -0.453, -0.559, -0.291, -0.285, -0.195,
    -0.455, -0.711, -0.434, -0.44, -0.556, -0.542, -0.503, -0.599,
    -0.581, -0.574, -0.406, -0.515, -0.433, -0.391, -0.541, -0.677,
    -0.387, -0.504, -0.386, -0.691, -0.399, -0.653, -0.287, -0.719,
  ]
layer: FullyConnected
  weights[0]: [
    -0.324, -0.318, -0.492, 0.321, 0.142, -0.32, -0.186, 0.0496,
    0.346, 0.291, -0.343, -0.209, 0.382, 0.331, -0.437, 0.143,
    -0.325, 0.335, 0.198, 0.284, -0.366, -0.0458, 0.255, 0.37,
    0.147, 0.29, -0.183, 0.463, -0.112, 0.263, -0.131, 0.314,
  ]
  biases: [
    0.00657,
  ]
layer: Activation
  function: Sigmoid
