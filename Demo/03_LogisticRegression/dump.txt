layer: InputScaling
  scale: [
    0.1,
  ]
layer: FullyConnected
  weights[0]: [
    -0.746,
  ]
  weights[1]: [
    -0.0392,
  ]
  weights[2]: [
    -0.095,
  ]
  weights[3]: [
    -0.99,
  ]
  weights[4]: [
    0.486,
  ]
  weights[5]: [
    0.234,
  ]
  weights[6]: [
    0.787,
  ]
  weights[7]: [
    -0.0663,
  ]
  weights[8]: [
    0.0754,
  ]
  weights[9]: [
    -0.252,
  ]
  weights[10]: [
    -1.34,
  ]
  weights[11]: [
    -0.813,
  ]
  weights[12]: [
    -0.325,
  ]
  weights[13]: [
    0.867,
  ]
  weights[14]: [
    -1.17,
  ]
  weights[15]: [
    -0.636,
  ]
  weights[16]: [
    -0.826,
  ]
  weights[17]: [
    1.05,
  ]
  weights[18]: [
    1.33,
  ]
  weights[19]: [
    0.614,
  ]
  weights[20]: [
    -1.41,
  ]
  weights[21]: [
    0.142,
  ]
  weights[22]: [
    -1.31,
  ]
  weights[23]: [
    1.13,
  ]
  weights[24]: [
    0.257,
  ]
  weights[25]: [
    1.28,
  ]
  weights[26]: [
    0.0956,
  ]
  weights[27]: [
    -0.27,
  ]
  weights[28]: [
    0.36,
  ]
  weights[29]: [
    -1.31,
  ]
  weights[30]: [
    -1.28,
  ]
  weights[31]: [
    -0.128,
  ]
  biases: [
    -0.109, 1.54, -0.744, 0.375, 0.376, 0.273, -0.571, 0.00762,
    1.17, -1.19, -0.364, 0.241, 0.195, -0.543, 0.0355, 0.253,
    0.333, 0.378, -0.134, -0.15, -0.126, 0.411, -0.399, 0.319,
    -0.0658, -0.133, 0.355, 0.39, 0.435, -0.412, 0.391, -0.153,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.266, 0.233, 0.429, 0.224, 0.25, 0.25, 0.453, 0.212,
    0.236, 0.332, 0.294, 0.244, 0.248, 0.142, 0.253, 0.228,
    0.237, 0.25, 0.234, 0.285, 0.25, 0.248, 0.3, 0.25,
    0.312, 0.265, 0.252, 0.239, 0.25, 0.298, 0.225, 0.289,
  ]
layer: BatchNormalization
  weights: [
    18.1, 90.5, 85.1, 8.07, 7.32, 14.9, 8.03, 233,
    45, 41.2, 8.99, 11.5, 15, 8.11, 11.8, 11.4,
    8.87, 3.46, 2.6, 5.89, 9.57, 23.8, 8.95, 3.1,
    14.8, 2.67, 36.2, 12.7, 9.58, 8.8, 7.19, 88.2,
  ]
  biases: [
    2.47, -137, 29, 0.0294, -4.66, -5.98, 0.217, 1.44,
    -54.3, 18, 2.84, 0.388, -0.599, -0.535, 1.8, -0.0528,
    -0.00835, -3.26, -1.59, -1.17, 2.13, -11.6, 2.93, -2.89,
    -1.2, -1.56, -14.7, -3.04, -6.01, 2.9, 0.328, 5.58,
  ]
layer: FullyConnected
  weights[0]: [
    0.0533, -0.225, 0.192, -0.233, -0.12, 0.238, 0.095, -0.122,
    -0.0683, -0.00871, -0.115, -0.122, 0.156, 0.106, 0.0778, 0.0854,
    0.0857, -0.154, 0.0304, -0.14, 0.0804, -0.0233, 0.0153, -0.146,
    -0.0601, 0.0892, -0.105, -0.148, 0.000998, 0.182, -0.18, 0.13,
  ]
  weights[1]: [
    -0.072, 0.168, -0.0829, 0.196, 0.134, -0.0246, -0.235, -0.0358,
    0.134, -0.0379, -0.013, -0.194, 0.186, -0.208, 0.226, 0.108,
    0.0316, 0.0813, 0.0162, -0.00927, 0.00173, 0.169, 0.177, -0.0239,
    0.181, 0.144, -0.113, -0.01, -0.0867, -0.144, 0.0188, 0.106,
  ]
  weights[2]: [
    -0.256, -0.231, 0.0875, 0.041, 0.181, 0.206, 0.234, -0.0161,
    0.153, 0.252, 0.0976, 0.00509, -0.00988, 0.263, -0.0748, -0.216,
    0.131, 0.199, -0.0868, 0.192, 0.0101, -0.12, 0.0149, 0.201,
    0.255, 0.115, -0.0844, -0.119, -0.124, -0.15, -0.151, -0.23,
  ]
  weights[3]: [
    -0.229, -0.219, -0.117, 0.0201, -0.0365, 0.239, 0.256, -0.171,
    0.0657, 0.111, -0.0149, 0.052, -0.166, 0.165, 0.062, 0.136,
    -0.2, 0.112, -0.158, -0.0463, 0.00299, -0.0714, -0.138, 0.136,
    0.205, -0.117, 0.143, 0.00297, 0.172, -0.0153, 0.171, 0.168,
  ]
  weights[4]: [
    0.0204, 0.143, 0.0771, -0.015, -0.182, 0.12, -0.0871, 0.158,
    -0.0987, 0.161, 0.00236, 0.173, 0.126, -0.0723, 0.0802, 0.0731,
    0.182, -0.227, -0.151, -0.104, -0.0485, 0.0746, 0.228, 0.15,
    0.0939, -0.176, -0.0597, -0.139, 0.143, 0.147, -0.0376, 0.0559,
  ]
  weights[5]: [
    -0.113, 0.144, 0.16, -0.000165, 0.0648, 0.165, 0.0309, -0.112,
    0.0109, 0.169, -0.0343, -0.116, 0.112, -0.105, -0.0813, -0.214,
    -0.171, -0.122, -0.000931, 0.11, -0.202, 0.197, 0.0317, -0.0313,
    -0.0852, -0.119, -0.219, -0.186, 0.101, 0.173, 0.11, -0.106,
  ]
  weights[6]: [
    -0.103, -0.103, 0.213, 0.201, -0.0819, 0.0657, 0.15, 0.0363,
    -0.174, -0.0687, -0.133, -0.202, 0.155, 0.075, -0.0363, -0.161,
    -0.0618, -0.124, -0.0951, 0.0812, -0.0554, 0.102, -0.0243, -0.0325,
    0.229, 0.253, 0.135, -0.138, 0.166, -0.236, -0.0672, 0.0176,
  ]
  weights[7]: [
    -0.157, -0.164, -0.0884, 0.065, -0.00022, 0.195, 0.235, -0.277,
    0.0566, -0.0103, -0.101, -0.181, 0.0451, 0.273, -0.224, -0.154,
    0.0864, 0.187, 0.251, 0.103, -0.23, 0.108, -0.145, 0.168,
    0.0244, -0.128, -0.199, 0.0688, 0.114, 0.0633, -0.16, 0.091,
  ]
  weights[8]: [
    -0.0906, -0.0511, -0.141, 0.323, -0.0666, -0.0613, -0.083, -0.0776,
    -0.00675, 0.122, 0.129, -0.0564, 0.0685, -0.0251, -0.083, 0.0537,
    -0.0145, -0.0962, -0.129, 0.0181, -0.108, -0.0278, -0.0902, -0.292,
    -0.016, -0.26, -0.165, 0.043, -0.0855, -0.0292, 0.18, -0.00452,
  ]
  weights[9]: [
    0.0201, -0.148, -0.0168, 0.0596, -0.142, -0.0891, 0.0888, -0.0401,
    0.0293, 0.0361, 0.198, 0.124, -0.105, 0.0118, -0.159, -0.107,
    0.0513, -0.163, -0.171, 0.193, 0.0475, 0.139, 0.14, 0.156,
    -0.183, -0.154, 0.189, -0.153, -0.0859, 0.185, 0.0163, -0.108,
  ]
  weights[10]: [
    0.139, 0.0148, 0.0222, -0.0609, -0.0618, 0.0229, 0.0998, 0.0733,
    -0.0747, 0.105, 0.184, 0.227, 0.177, 0.13, 0.0888, -0.0371,
    0.0911, -0.221, 0.172, 0.0214, -0.193, -0.0428, 0.0223, 0.151,
    -0.0429, 0.193, 0.0124, 0.157, -0.215, 0.113, -0.129, -0.0871,
  ]
  weights[11]: [
    0.159, 0.25, -0.0673, -0.0828, 0.156, 0.104, -0.141, 0.0861,
    -0.0791, 0.157, 0.0525, 0.0359, 0.17, 0.0087, 0.199, 0.0868,
    -0.0464, -0.218, -0.208, -0.0979, -0.00423, 0.169, 0.0797, 0.0645,
    -0.23, -0.0688, -0.0111, -0.0447, 0.143, -0.007, 0.0611, 0.105,
  ]
  weights[12]: [
    0.015, -0.0363, 0.199, -0.0466, 0.0949, 0.0862, 0.193, -0.245,
    -0.111, 0.105, -0.0634, 0.0233, -0.0277, 0.0885, -0.0155, 0.165,
    -0.0139, 0.0804, 0.219, -0.13, -0.0593, 0.134, -0.217, 0.0926,
    0.173, -0.108, -0.0357, -0.235, 0.203, -0.176, -0.038, -0.204,
  ]
  weights[13]: [
    0.0195, -0.0229, 0.0612, -0.138, 0.0131, -0.0692, 0.24, 0.15,
    -0.175, 0.0832, 0.136, -0.184, -0.134, 0.0168, 0.0226, -0.114,
    -0.137, -0.168, 0.173, 0.193, 0.0269, -0.077, 0.0284, -0.0903,
    -0.0481, -0.145, 0.07, 0.112, -0.176, -0.175, -0.0405, 0.104,
  ]
  weights[14]: [
    -0.224, 0.0947, -0.0731, 0.0837, -0.0815, -0.158, 0.0677, -0.0447,
    -0.22, 0.106, -0.198, -0.149, 0.0649, -0.00506, -0.0229, -0.146,
    -0.147, 0.214, 0.0345, 0.19, -0.0439, -0.0565, 0.0657, -0.00325,
    0.0672, -0.0702, -0.129, -0.0376, -0.157, -0.205, -0.0634, 0.0313,
  ]
  weights[15]: [
    0.0631, 0.0457, 0.0258, -0.138, 0.204, -0.193, -0.235, 0.00349,
    -0.0977, -0.176, -0.0651, 0.0565, -0.129, -0.222, -0.115, 0.0923,
    0.0254, 0.136, 0.012, 0.0335, 0.194, -0.0789, 0.137, 0.136,
    -0.0628, -0.14, 0.114, 0.0376, 0.0196, 0.172, 0.144, -0.211,
  ]
  weights[16]: [
    -0.00583, 0.142, -0.111, -0.0796, -0.0532, -0.0519, -0.171, 0.176,
    -0.0366, 0.17, 0.0271, 0.166, -0.104, -0.00116, 0.147, -0.231,
    -0.193, -0.151, 0.108, -0.0633, -0.184, 0.103, 0.0899, 0.115,
    0.0846, 0.102, -0.233, 0.0421, 0.168, 0.175, 0.0168, 0.0742,
  ]
  weights[17]: [
    -0.243, -0.217, 0.18, 0.0825, 0.196, 0.189, 0.152, 0.044,
    -0.127, 0.0739, -0.071, 0.134, -0.219, -0.0343, -0.165, -0.223,
    -0.151, 0.233, 0.22, 0.0215, -0.107, 0.146, -0.0465, -0.0736,
    0.0446, 0.0719, -0.0482, -0.207, 0.0304, 0.118, -0.0758, -0.133,
  ]
  weights[18]: [
    -0.0611, -0.214, -0.0676, 0.1, 0.0277, -0.0356, 0.21, 0.0167,
    -0.123, 0.219, 0.15, 0.148, 0.15, -0.141, -0.136, 0.072,
    -0.234, 0.228, 0.099, 0.0461, 0.105, -0.00265, 0.0667, 0.144,
    0.181, 0.0435, 0.144, -0.12, -0.127, -0.156, 0.0776, 0.126,
  ]
  weights[19]: [
    0.168, -0.137, 0.127, 0.0525, -0.0267, 0.0873, 0.168, -0.0461,
    0.179, 0.0811, 0.206, 0.136, 0.0376, -0.0581, -0.0222, 0.242,
    0.254, 0.0695, 0.0105, -0.087, 0.1, 0.103, 0.0175, -0.213,
    0.0987, -0.11, 0.0125, 0.109, -0.21, 0.169, 0.00972, -0.13,
  ]
  weights[20]: [
    0.0967, -0.11, -0.197, 0.138, -0.216, 0.131, -0.222, -0.021,
    0.18, 0.0867, 0.00557, 0.171, 0.14, 0.0165, 0.12, -0.0404,
    0.148, -0.134, -0.104, 0.113, 0.0756, 0.18, -0.148, -0.21,
    -0.0246, 0.0837, -0.0485, -0.159, 0.136, -0.125, -0.0733, -0.122,
  ]
  weights[21]: [
    0.0585, -0.129, -0.0368, 0.132, -0.119, 0.0744, 0.04, -0.223,
    -0.141, 0.0298, -0.224, 0.145, 0.169, 0.302, -0.231, -0.112,
    0.134, -0.158, 0.2, 0.206, -0.217, 0.168, -0.204, -0.154,
    0.171, 0.215, -0.157, -0.182, -0.054, 0.0999, -0.0327, 0.133,
  ]
  weights[22]: [
    -0.149, -0.0235, -0.119, 0.0126, -0.176, -0.0309, 0.111, -0.193,
    0.195, -0.0956, -0.0992, 0.0461, 0.0513, -0.208, -0.0424, 0.183,
    0.0317, 0.134, -0.0574, -0.102, 0.00273, 0.14, 0.214, -0.00015,
    0.128, -0.179, -0.0563, 0.187, 0.0272, 0.195, -0.00361, -0.166,
  ]
  weights[23]: [
    0.194, 0.087, 0.0339, 0.0882, -0.203, 0.116, 0.0325, 0.21,
    0.067, 0.179, 0.12, 0.207, 0.0513, -0.127, -0.0893, -0.14,
    0.00341, -0.174, 0.0292, 0.0346, -0.0429, 0.0137, -0.12, -0.0628,
    -0.0915, 0.0305, 0.175, -0.0701, -0.209, -0.131, 0.221, -0.125,
  ]
  weights[24]: [
    0.152, -0.162, -0.197, -0.000546, 0.105, -0.193, -0.0306, -0.14,
    0.177, 0.168, 0.0673, -0.17, -0.175, 0.106, 0.0759, 0.115,
    -0.1, -0.0434, -0.0903, 0.000177, 0.118, -0.0969, 0.0236, -0.173,
    0.177, 0.0612, -0.135, 0.0891, 0.156, 0.169, -0.0113, 0.0031,
  ]
  weights[25]: [
    -0.0436, -0.0264, 0.196, -0.0241, 0.254, -0.0187, -0.0742, -0.0771,
    -0.2, 0.167, -0.219, -0.154, -0.0751, 0.338, 0.132, 0.0754,
    0.144, 0.196, -0.132, 0.104, -0.128, 0.183, -0.0823, -0.00774,
    -0.124, 0.0443, -0.138, 0.0273, 0.0363, 0.139, 0.129, -0.241,
  ]
  weights[26]: [
    0.126, -0.0773, -0.123, -0.18, 0.199, -0.035, 0.121, -0.112,
    -0.00362, 0.17, -0.0814, 0.162, 0.118, 0.161, -0.248, -0.109,
    -0.152, 0.165, 0.132, 0.204, -0.225, 0.00219, -0.116, 0.00347,
    -0.0758, -0.087, -0.203, 0.0175, 0.153, -0.0888, -0.0115, -0.101,
  ]
  weights[27]: [
    0.211, -0.0913, -0.173, 0.237, -0.0675, 0.0474, -0.106, -0.0715,
    -0.0781, -0.0436, 0.00917, 0.127, 0.141, -0.101, 0.0339, -0.034,
    -0.0876, -0.146, 0.116, -0.0362, -0.0626, 0.139, 0.231, -0.216,
    -0.0129, -0.167, 0.176, -0.0122, -0.0445, -0.0671, -0.0361, -0.0408,
  ]
  weights[28]: [
    0.0416, 0.00495, -0.0296, -0.0534, 0.0931, -0.0346, 0.245, 0.158,
    0.0788, 0.0765, -0.0851, -0.183, -0.0712, 0.236, -0.126, -0.068,
    -0.0566, 0.0369, 0.18, -0.161, 0.00363, -0.0199, -0.0184, 0.22,
    0.159, 0.24, 0.225, -0.116, 0.0434, -0.223, -0.0275, 0.0367,
  ]
  weights[29]: [
    0.02, -0.233, 0.0724, 0.0449, 0.227, 0.137, 0.145, -0.0949,
    0.183, 0.144, -0.177, -0.108, -0.125, 0.0964, -0.12, 0.0138,
    -0.177, 0.0972, -0.134, 0.131, -0.0235, -0.01, 0.089, -0.0123,
    0.168, -0.00305, -0.147, 0.173, 0.183, -0.255, 0.0146, -0.19,
  ]
  weights[30]: [
    0.0115, -0.221, 0.247, 0.162, 0.24, 0.152, 0.0846, 0.103,
    0.0393, 0.167, 0.0379, 0.0143, 0.053, 0.0729, -0.163, 0.0831,
    -0.208, 0.165, 0.0636, 0.0371, -0.0889, 0.075, -0.248, 0.0952,
    0.18, -0.0965, -0.172, -0.00157, 0.199, -0.00482, 0.0355, 0.102,
  ]
  weights[31]: [
    -0.115, -0.177, 0.0249, 0.165, -0.111, -0.163, -0.161, 0.00637,
    -0.0828, 0.0459, 0.145, 0.177, -0.18, 0.166, 0.0595, -0.157,
    -0.087, 0.102, -0.14, 0.0397, 0.0044, -0.145, 0.0611, -0.129,
    0.0285, -0.218, -0.152, -0.00258, 0.115, 0.0634, 0.00882, 0.139,
  ]
  biases: [
    -0.103, 0.0615, 0.0245, 0.0235, -0.00174, -0.0966, -0.0191, -0.106,
    -0.0834, -0.0646, -0.0779, 0.0329, 0.0043, -0.0478, 0.0211, -0.0146,
    -0.0949, 0.0459, -0.127, 0.0469, 0.0458, -0.13, 0.00911, -0.0619,
    -0.0427, -0.124, -0.021, 0.0657, -0.264, -0.106, 0.0423, -0.0369,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.342, 0.253, 0.222, 0.223, 0.306, 0.302, 0.192, 0.231,
    0.273, 0.246, 0.32, 0.232, 0.231, 0.222, 0.231, 0.213,
    0.222, 0.212, 0.287, 0.218, 0.207, 0.229, 0.237, 0.226,
    0.292, 0.28, 0.22, 0.21, 0.262, 0.239, 0.21, 0.204,
  ]
layer: BatchNormalization
  weights: [
    12, 2.95, 0.666, 0.977, 0.761, 5.21, 1.11, 0.639,
    1.06, 6.43, 1.94, 0.991, 0.832, 11.5, 2.78, 3.21,
    5.45, 0.763, 3.43, 1.04, 4.99, 1.27, 10.5, 1.53,
    58.3, 3.19, 0.925, 1.91, 0.788, 0.863, 1.37, 1.51,
  ]
  biases: [
    0.703, -0.72, -0.47, -0.532, -0.505, -0.269, -0.552, -0.679,
    -0.525, -0.194, -0.466, -0.585, -0.496, 0.113, -0.472, -0.878,
    -0.46, -0.501, -0.387, -0.411, -0.426, -0.525, -0.637, -0.567,
    2, -0.528, -0.502, -0.502, -0.603, -0.566, -0.45, -0.449,
  ]
layer: FullyConnected
  weights[0]: [
    0.0845, -0.177, 0.18, 0.195, -0.206, 0.207, -0.0202, 0.101,
    -0.109, 0.195, 0.0235, -0.0801, 0.148, -0.168, 0.213, 0.0317,
    0.0298, 0.253, 0.126, 0.17, 0.118, 0.196, -0.182, -0.156,
    0.0382, 0.0913, 0.164, 0.0533, -0.0689, 0.104, 0.267, -0.157,
  ]
  weights[1]: [
    0.00885, 0.171, -0.14, -0.104, -0.204, -0.153, -0.0757, -0.0171,
    0.253, 0.0637, 0.194, -0.176, -0.17, 0.0215, -0.0876, -0.0402,
    -0.0484, -0.0429, 0.103, 0.0731, -0.0341, -0.0595, 0.201, 0.0331,
    -0.00236, 0.0997, 0.077, -0.11, 0.131, 0.143, 0.0493, 0.138,
  ]
  weights[2]: [
    0.255, 0.224, 0.0943, -0.238, -0.0634, -0.236, -0.183, 0.0409,
    -0.0591, 0.175, 0.195, 0.111, -0.181, 0.0812, 0.159, 0.107,
    -0.074, -0.176, 0.00497, -0.0945, 0.209, 0.0659, 0.102, -0.0633,
    0.0327, -0.0854, -0.00731, -0.0112, -0.155, -0.0298, -0.0586, 0.0612,
  ]
  weights[3]: [
    0.116, 0.136, 0.188, 0.0068, -0.0397, 0.0977, 0.103, 0.345,
    0.188, -0.168, 0.222, 0.166, -0.0554, 0.123, -0.0878, 0.106,
    0.129, 0.00108, 0.224, 0.22, 0.0544, 0.192, -0.0532, 0.219,
    -0.0322, 0.368, 0.0549, -0.0634, 0.345, 0.338, 0.0173, 0.0807,
  ]
  weights[4]: [
    -0.087, -0.104, 0.0309, 0.176, -0.162, 0.0974, 0.16, -0.0183,
    0.144, -0.141, -0.109, -0.171, 0.214, 0.00864, 0.0265, 0.0233,
    0.0508, 0.226, 0.0988, 0.0515, 0.0428, -0.0259, -0.0639, -0.172,
    -0.0534, 0.2, 0.0871, 0.0831, 0.156, -0.0349, 0.164, -0.0711,
  ]
  weights[5]: [
    0.0791, -0.0227, -0.0646, 0.267, 0.203, 0.0266, 0.0638, 0.139,
    -0.119, 0.195, 0.0619, 0.0918, 0.14, -0.143, -0.0129, 0.0946,
    -0.0242, 0.0123, 0.205, -0.176, -0.13, -0.0524, -0.0467, -0.0117,
    0.171, 0.252, -0.132, -0.0866, 0.169, -0.141, -0.129, 0.000998,
  ]
  weights[6]: [
    0.144, 0.212, -0.0896, -0.182, 0.0692, 0.0858, -0.0595, 0.0801,
    -0.0826, 0.158, -0.128, -0.177, -0.0663, 0.00506, -0.062, -0.0123,
    -0.251, -0.284, -0.0654, -0.0382, -0.0461, -0.149, 0.174, -0.066,
    0.156, 0.0158, -0.19, 0.0314, -0.223, -0.285, -0.143, -0.22,
  ]
  weights[7]: [
    0.0709, -0.0166, 0.0308, -0.196, 0.151, -0.01, -0.113, -0.195,
    -0.0175, -0.114, 0.0174, -0.102, 0.0896, 0.0052, -0.0106, -0.109,
    -0.0374, -0.173, 0.243, 0.159, 0.144, -0.0342, 0.107, -0.185,
    -0.0969, -0.188, -0.0547, -0.132, -0.0331, -0.0443, -0.0413, 0.1,
  ]
  weights[8]: [
    -0.0753, 0.184, 0.142, 0.177, -0.00821, 0.00994, 0.188, -0.0539,
    -0.0876, 0.0108, -0.215, 0.0412, 0.0271, -0.158, 0.128, -0.103,
    -0.124, -0.17, -0.00757, 0.148, -0.0279, -0.0112, -0.0885, -0.205,
    -0.163, 0.0434, 0.0461, 0.0456, 0.196, 0.0382, 0.00364, 0.162,
  ]
  weights[9]: [
    0.0985, -0.137, -0.111, 0.194, -0.159, 0.15, 0.109, -0.00424,
    0.0488, 0.0978, 0.0686, -0.0743, 0.0983, 0.0898, 0.0641, -0.148,
    0.00737, 0.0943, 0.00504, -0.167, -0.16, 0.0882, -0.0911, -0.155,
    0.0363, 0.0424, -0.0741, -0.0337, -0.00564, -0.124, 0.129, -0.115,
  ]
  weights[10]: [
    -0.111, -0.179, 0.111, 0.205, 0.108, 0.0133, 0.126, 0.199,
    -0.108, -0.0594, -0.201, -0.0956, 0.168, 0.0692, 0.208, 0.122,
    0.195, 0.0536, 0.0869, 0.179, 0.044, -0.123, 0.0882, 0.0599,
    -0.0562, 0.234, -0.131, 0.142, 0.0454, 0.244, 0.229, -0.027,
  ]
  weights[11]: [
    0.12, -0.141, 0.216, 0.147, -0.156, 0.198, 0.017, 0.286,
    0.134, 0.0285, 0.161, 0.0712, 0.0663, -0.154, -0.014, 0.0129,
    -0.0789, 0.0629, -0.0503, 0.066, -0.0826, 0.19, -0.119, -0.102,
    0.202, 0.25, -0.021, -0.116, 0.118, 0.285, -0.0217, 0.114,
  ]
  weights[12]: [
    0.117, -0.0182, 0.0753, -0.221, -0.196, 0.14, -0.114, -0.127,
    -0.115, 0.0501, -0.198, -0.261, -0.148, -0.108, -0.0242, -0.0949,
    0.3, -0.162, 0.0622, -0.0746, 0.0666, 0.0253, -0.0783, -0.114,
    0.0712, -0.0973, -0.00491, -0.194, -0.102, 0.0405, -0.178, -0.0544,
  ]
  weights[13]: [
    -0.0284, -0.181, 0.00564, 0.117, 0.216, 0.0596, 0.0566, -0.0953,
    0.159, -0.1, -0.0191, 0.114, 0.0306, 0.0795, 0.0983, 0.181,
    0.13, -0.0895, 0.0509, 0.0522, 0.0119, -0.0521, -0.184, 0.00197,
    0.0412, -0.0747, -0.00396, 0.174, -0.224, -0.11, -0.0546, 0.00137,
  ]
  weights[14]: [
    -0.164, 0.00251, -0.233, -0.18, 0.0533, -0.246, -0.0809, 0.0695,
    -0.208, 0.0206, -0.2, -0.162, -0.097, -0.0564, -0.241, -0.257,
    -0.0422, 0.0673, -0.128, -0.0834, -0.0615, -0.226, -0.181, 0.0785,
    0.0408, -0.0512, 0.0622, 0.035, -0.31, -0.0825, -0.0678, -0.0829,
  ]
  weights[15]: [
    -0.185, 0.00334, 0.178, 0.173, 0.109, 0.156, 0.26, 0.0247,
    0.256, 0.0343, 0.146, -0.0663, 0.235, 0.0126, -0.0151, -0.0894,
    0.118, 0.241, -0.057, -0.0786, 0.0891, 0.26, 0.0293, 0.156,
    -0.0102, 0.0315, 0.178, -0.156, 0.0151, 0.256, -0.0442, 0.127,
  ]
  weights[16]: [
    0.0049, 0.138, -0.173, -0.245, 0.169, -0.164, -0.284, -0.285,
    -0.267, -0.00874, -0.0903, -0.089, 0.0712, -0.0248, -0.189, 0.151,
    -0.212, -0.0311, 0.0937, 0.108, -0.102, -0.161, -0.022, -0.0967,
    -0.043, -0.0672, -0.139, 0.0622, -0.0493, -0.194, 0.0343, -0.112,
  ]
  weights[17]: [
    -0.238, -0.0272, -0.136, -0.224, 0.166, -0.23, 0.137, -0.139,
    0.207, -0.0494, 0.181, 0.0877, -0.0466, -0.0349, -0.106, 0.0547,
    -0.0997, -0.13, -0.106, -0.152, -0.182, 0.194, -0.158, 0.206,
    0.0517, -0.0654, -0.054, 0.227, 0.0567, 0.125, 0.0502, 0.123,
  ]
  weights[18]: [
    0.114, -0.0191, -0.161, 0.00503, 0.0544, -0.162, 0.0165, -0.0944,
    -0.0779, -0.215, 0.189, 0.193, -0.0584, -0.197, -0.0552, 0.1,
    -0.111, -0.194, 0.197, 0.0221, 0.0938, 0.0129, -0.0834, 0.122,
    -0.0171, -0.14, 0.118, 0.115, -0.0459, 0.183, -0.0921, 0.0532,
  ]
  weights[19]: [
    0.114, -0.0241, 0.214, 0.115, -0.082, -0.0885, 0.113, 0.127,
    0.0945, -0.0141, 0.0907, -0.153, 0.157, 0.0858, 0.159, 0.106,
    0.0414, 0.138, 0.18, -0.0478, -0.132, 0.081, 0.073, -0.128,
    -0.108, -0.00189, 0.133, 0.118, 0.218, 0.173, -0.0855, -0.0706,
  ]
  weights[20]: [
    0.081, 0.105, 0.0697, 0.102, 0.0315, -0.138, -0.0283, 0.276,
    -0.0742, -0.112, -0.189, -0.0445, 0.253, -0.0294, 0.00771, -0.133,
    0.16, 0.106, -0.14, -0.0342, 0.115, 0.244, -0.162, 0.154,
    -0.153, 0.0164, 0.0126, -0.0284, 0.0638, 0.0127, 0.109, 0.0175,
  ]
  weights[21]: [
    0.178, 0.196, -0.205, 0.0905, -0.0748, 0.0165, -0.0333, -0.0343,
    -0.198, 0.0862, -0.113, 0.00752, 0.151, -0.199, -0.154, 0.135,
    -0.0101, 0.0434, -0.0512, 0.165, 0.152, 0.0214, -0.167, 0.0671,
    -0.205, 0.147, -0.197, 0.219, -0.204, 0.0104, 0.12, 0.0388,
  ]
  weights[22]: [
    0.0855, 0.146, 0.0323, -0.0589, 0.0929, -0.106, -0.0952, -0.319,
    -0.151, -0.224, 0.00501, 0.148, -0.259, 0.0497, 0.0918, 0.216,
    -0.243, -0.268, 0.182, -0.0263, -0.136, -0.0737, -0.0385, -0.0777,
    -0.134, -0.244, 0.0111, -0.124, -0.0946, -0.238, -0.243, -0.224,
  ]
  weights[23]: [
    -0.0966, 0.159, -0.0987, -0.145, -0.0623, 0.194, -0.0989, 0.185,
    0.161, 0.0331, -0.0195, 0.187, -0.108, 0.099, -0.17, -0.0341,
    0.18, -0.136, -0.0744, -0.186, -0.157, -0.0655, 0.00171, 0.288,
    -0.127, 0.117, -0.0159, 0.134, -0.101, -0.0683, -0.0305, 0.219,
  ]
  weights[24]: [
    -0.324, -0.242, -0.128, -0.0299, -0.122, -0.101, 0.0133, -0.186,
    -0.0757, -0.0807, -0.159, 0.0861, -0.0752, 0.0789, -0.145, -0.11,
    -0.0354, -0.0639, -0.343, -0.108, -0.198, -0.288, 0.0162, -0.169,
    -0.0918, -0.185, -0.303, 0.0281, -0.0198, -0.111, -0.0476, 0.102,
  ]
  weights[25]: [
    -0.023, -0.109, 0.195, 0.251, -0.0767, 0.185, 0.236, -0.0585,
    0.208, -0.072, 0.173, 0.168, 0.0641, -0.0211, -0.0472, -0.0464,
    0.105, 0.278, 0.112, -0.11, -0.0672, 0.322, -0.186, 0.058,
    -0.0446, 0.239, 0.0185, -0.042, 0.213, 0.225, 0.144, -0.0115,
  ]
  weights[26]: [
    0.0308, -0.179, -0.286, -0.199, -0.0701, 0.0829, 0.00252, -0.168,
    -0.165, -0.0908, 0.174, 0.184, -0.0411, 0.0379, -0.0423, 0.151,
    -0.296, -0.305, 0.166, 0.192, -0.0503, -0.287, 0.0666, -0.214,
    0.0732, 0.108, -0.187, -0.0808, -0.241, -0.104, -0.229, -0.185,
  ]
  weights[27]: [
    0.0398, 0.131, -0.0756, -0.0958, -0.0939, -0.107, -0.254, -0.12,
    -0.163, -0.131, -0.0261, -0.0337, -0.163, 0.202, -0.146, 0.151,
    -0.109, -0.00164, 0.0638, 0.104, 0.0281, -0.148, 0.0681, 0.0311,
    -0.0807, -0.225, -0.244, 0.000197, -0.219, -0.243, 0.00931, -0.208,
  ]
  weights[28]: [
    -0.253, -0.164, 0.214, 0.105, 0.0485, 0.146, 0.00751, -0.122,
    -0.0764, 0.143, -0.184, -0.0934, 0.0982, 0.119, -0.000513, -0.127,
    0.0896, 0.256, -0.187, -0.153, 0.15, 0.00351, -0.183, 0.0246,
    0.0741, -0.134, 0.261, -0.147, -0.0475, 0.151, 0.117, 0.129,
  ]
  weights[29]: [
    -0.0792, -0.19, -0.228, -0.0972, -0.0151, 0.217, -0.102, -0.176,
    -0.0189, 0.095, -0.0592, -0.202, 0.158, 0.167, -0.105, -0.00421,
    0.222, 0.0865, -0.129, -0.142, 0.116, -0.0824, 0.0616, -0.158,
    -0.103, -0.206, -0.0767, -0.221, -0.0714, -0.0464, -0.0982, -0.182,
  ]
  weights[30]: [
    -0.0198, 0.011, -0.0782, -0.0629, 0.139, -0.188, -0.279, -0.091,
    -0.291, -0.119, 0.0166, 0.169, -0.304, 0.0719, -0.282, -0.047,
    -0.179, -0.031, 0.0904, 0.0796, 0.0139, -0.26, -0.0092, -0.208,
    0.0459, -0.00124, -0.304, 0.152, -0.21, -0.02, -0.122, -0.233,
  ]
  weights[31]: [
    -0.196, -0.16, -0.14, -0.0262, -0.173, 0.143, 0.143, 0.213,
    0.232, 0.000963, 0.105, -0.159, 0.0501, -0.0759, -0.0718, 0.202,
    0.0755, 0.209, 0.102, 0.117, -0.0728, 0.127, 0.165, 0.0137,
    0.102, 0.12, 0.152, 0.0499, 0.0243, -0.144, 0.221, -0.128,
  ]
  biases: [
    0.0351, -0.127, 0.0609, -0.131, 0.0645, -0.165, 0.0563, 0.0378,
    0.0403, 0.0795, 0.0231, 0.0113, -0.029, -0.0595, 0.123, -0.0202,
    0.0469, -0.0617, 0.0343, -0.0638, 0.0405, 0.0543, 0.0539, -0.11,
    0.132, 0.00815, 0.0331, 0.103, 0.0733, -0.0299, 0.0358, 0.00932,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.23, 0.277, 0.206, -0.0412, 0.233, 0.158, 0.164, 0.165,
    0.238, 0.241, 0.196, 0.22, 0.118, 0.266, 0.0664, 0.148,
    0.147, 0.278, 0.205, 0.184, 0.224, 0.213, 0.103, 0.307,
    0.095, 0.198, 0.115, 0.166, 0.21, 0.118, 0.112, 0.208,
  ]
layer: BatchNormalization
  weights: [
    0.512, 1.91, 0.79, 1.7, 0.535, 2.76, 1.32, 2.24,
    0.967, 0.855, 0.823, 0.732, 2.63, 1.57, 2.11, 0.789,
    1.39, 1.32, 1.33, 0.619, 0.98, 1.33, 1.75, 1.19,
    1.76, 0.55, 1.76, 0.999, 0.923, 2.28, 1.08, 1.28,
  ]
  biases: [
    -0.376, -0.241, -0.457, -0.823, -0.336, -0.252, -0.765, -0.592,
    -0.408, -0.339, -0.391, -0.309, -0.884, -0.514, -1.4, -0.363,
    -0.91, -0.472, -0.341, -0.396, -0.364, -0.357, -1.04, -0.423,
    -1.46, -0.337, -0.96, -0.82, -0.544, -0.906, -0.847, -0.339,
  ]
layer: FullyConnected
  weights[0]: [
    -0.227, 0.161, -0.202, 0.462, -0.0797, 0.27, -0.134, -0.0865,
    -0.151, -0.0422, -0.232, -0.188, 0.352, 0.0755, 0.24, -0.14,
    -0.319, 0.3, -0.177, -0.0845, -0.129, -0.134, -0.318, 0.277,
    0.417, -0.185, -0.213, -0.213, -0.204, 0.365, -0.112, -0.229,
  ]
  biases: [
    -0.0704,
  ]
layer: Activation
  function: Sigmoid
