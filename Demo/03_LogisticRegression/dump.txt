layer: InputScaling
  scale: [
    0.1,
  ]
layer: FullyConnected
  weights[0]: [
    -0.681,
  ]
  weights[1]: [
    -0.601,
  ]
  weights[2]: [
    0.296,
  ]
  weights[3]: [
    -0.953,
  ]
  weights[4]: [
    0.3,
  ]
  weights[5]: [
    0.343,
  ]
  weights[6]: [
    0.904,
  ]
  weights[7]: [
    -0.154,
  ]
  weights[8]: [
    0.312,
  ]
  weights[9]: [
    0.564,
  ]
  weights[10]: [
    -1.28,
  ]
  weights[11]: [
    -0.817,
  ]
  weights[12]: [
    -0.375,
  ]
  weights[13]: [
    1.12,
  ]
  weights[14]: [
    -1.24,
  ]
  weights[15]: [
    -0.807,
  ]
  weights[16]: [
    -0.742,
  ]
  weights[17]: [
    0.859,
  ]
  weights[18]: [
    1.31,
  ]
  weights[19]: [
    0.892,
  ]
  weights[20]: [
    -1.56,
  ]
  weights[21]: [
    0.169,
  ]
  weights[22]: [
    -1.26,
  ]
  weights[23]: [
    1.07,
  ]
  weights[24]: [
    0.184,
  ]
  weights[25]: [
    1.34,
  ]
  weights[26]: [
    0.069,
  ]
  weights[27]: [
    -0.688,
  ]
  weights[28]: [
    0.404,
  ]
  weights[29]: [
    -0.939,
  ]
  weights[30]: [
    -1.39,
  ]
  weights[31]: [
    -0.126,
  ]
  biases: [
    -0.00126, 0.374, 0.174, 0.381, 0.276, 0.403, -0.183, -0.0897,
    0.537, -0.395, -0.356, 0.327, 0.262, -0.337, 0.0394, 0.0159,
    0.362, 0.205, -0.108, 0.127, -0.142, 0.439, -0.303, 0.258,
    -0.129, 0.0255, 0.405, -0.0177, 0.442, -0.0495, 0.11, -0.145,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.259, 0.232, 0.25, 0.227, 0.25, 0.25, 0.292, 0.259,
    0.234, 0.139, 0.289, 0.235, 0.248, 0.117, 0.259, 0.242,
    0.24, 0.25, 0.25, 0.25, 0.262, 0.248, 0.29, 0.25,
    0.0628, 0.249, 0.252, 0.255, 0.25, 0.256, 0.234, 0.284,
  ]
layer: BatchNormalization
  weights: [
    20.6, 8.1, 11.8, 7.81, 11.4, 10.1, 4.15, 85.1,
    11.1, 15.4, 9.38, 9.13, 11.6, 3.6, 11.1, 17.9,
    8.27, 4.15, 2.61, 3.85, 8.49, 19.9, 9.8, 3.27,
    49.8, 2.45, 51.1, 19.6, 8.62, 14.5, 10.1, 92.3,
  ]
  biases: [
    2, -0.624, -3.96, -0.0726, -5.03, -5.92, -1.39, 3.81,
    -7.78, -0.33, 2.81, -0.0668, -0.818, -1.14, 1.84, 1.87,
    -0.291, -2.8, -1.62, -2.38, 2.19, -10.5, 2.77, -2.74,
    -0.453, -1.88, -22.6, 1.97, -5.67, 2.08, 1.55, 5.53,
  ]
layer: FullyConnected
  weights[0]: [
    0.0792, -0.185, 0.182, -0.212, -0.144, 0.214, 0.0583, -0.0946,
    -0.0576, -0.00241, -0.0936, -0.0952, 0.179, 0.059, 0.104, 0.0875,
    0.0882, -0.179, 0.000994, -0.171, 0.106, -0.0468, 0.0359, -0.172,
    -0.091, 0.0601, -0.121, -0.124, -0.0221, 0.204, -0.136, 0.149,
  ]
  weights[1]: [
    -0.0659, 0.168, -0.0832, 0.224, 0.128, -0.0301, -0.231, -0.0301,
    0.14, -0.0128, -0.0065, -0.157, 0.202, -0.198, 0.231, 0.103,
    0.0218, 0.0752, 0.0118, -0.014, 0.007, 0.163, 0.184, -0.0296,
    0.177, 0.14, -0.115, -0.00058, -0.0929, -0.137, 0.0387, 0.114,
  ]
  weights[2]: [
    -0.25, -0.21, 0.0903, 0.0312, 0.177, 0.202, 0.21, -0.0107,
    0.144, 0.279, 0.1, 0.00954, -0.0157, 0.225, -0.0687, -0.232,
    0.113, 0.193, -0.0952, 0.184, 0.0161, -0.124, 0.0169, 0.195,
    0.248, 0.106, -0.0862, -0.127, -0.129, -0.147, -0.153, -0.228,
  ]
  weights[3]: [
    -0.219, -0.202, -0.123, 0.0215, -0.045, 0.23, 0.239, -0.162,
    0.0611, 0.123, -0.00663, 0.0609, -0.162, 0.142, 0.0714, 0.133,
    -0.202, 0.102, -0.168, -0.0563, 0.0123, -0.0802, -0.13, 0.127,
    0.195, -0.127, 0.135, 0.00562, 0.163, -0.00688, 0.175, 0.176,
  ]
  weights[4]: [
    0.0384, 0.168, 0.055, 0.0252, -0.2, 0.102, -0.104, 0.178,
    -0.0866, 0.16, 0.0199, 0.208, 0.144, -0.085, 0.0988, 0.0772,
    0.197, -0.247, -0.169, -0.123, -0.0303, 0.0572, 0.247, 0.132,
    0.079, -0.194, -0.0772, -0.121, 0.126, 0.165, -0.00274, 0.0747,
  ]
  weights[5]: [
    -0.106, 0.158, 0.152, -0.0162, 0.0608, 0.161, 0.00778, -0.098,
    0.013, 0.15, -0.0321, -0.123, 0.112, -0.144, -0.0746, -0.224,
    -0.183, -0.128, -0.0104, 0.1, -0.196, 0.194, 0.0333, -0.0376,
    -0.097, -0.129, -0.218, -0.19, 0.0969, 0.176, 0.106, -0.106,
  ]
  weights[6]: [
    -0.0796, -0.0514, 0.205, 0.213, -0.104, 0.0426, 0.108, 0.0604,
    -0.195, -0.00651, -0.111, -0.172, 0.164, 0.0196, -0.0131, -0.169,
    -0.0482, -0.148, -0.119, 0.0575, -0.0322, 0.0784, -0.00245, -0.0564,
    0.205, 0.229, 0.107, -0.137, 0.144, -0.214, -0.0633, 0.0399,
  ]
  weights[7]: [
    -0.136, -0.0983, -0.108, 0.0424, -0.0173, 0.176, 0.173, -0.256,
    0.0675, 0.0607, -0.0851, -0.159, 0.0278, 0.176, -0.203, -0.192,
    0.0713, 0.167, 0.227, 0.0786, -0.209, 0.0902, -0.131, 0.147,
    0.00207, -0.153, -0.215, 0.0502, 0.0958, 0.0795, -0.175, 0.105,
  ]
  weights[8]: [
    -0.167, -0.106, -0.0767, 0.24, 0.00906, 0.0139, -0.00797, -0.153,
    -0.0174, 0.204, 0.0544, -0.128, -0.00728, 0.0371, -0.159, -0.0333,
    -0.0913, -0.0202, -0.052, 0.0958, -0.184, 0.047, -0.165, -0.217,
    0.0677, -0.185, -0.118, -0.0383, -0.0108, -0.105, 0.0885, -0.0781,
  ]
  weights[9]: [
    0.0106, -0.194, -0.00292, -0.00547, -0.133, -0.0777, 0.0964, -0.0476,
    0.0359, -0.0536, 0.187, 0.0755, -0.114, 0.00848, -0.168, -0.126,
    0.0384, -0.154, -0.163, 0.201, 0.0374, 0.15, 0.129, 0.166,
    -0.181, -0.147, 0.196, -0.162, -0.0761, 0.174, -0.0209, -0.119,
  ]
  weights[10]: [
    0.152, 0.0341, 0.00774, -0.0513, -0.0736, 0.0115, 0.0822, 0.0851,
    -0.0731, 0.103, 0.195, 0.244, 0.189, 0.109, 0.101, -0.0416,
    0.0917, -0.234, 0.159, 0.00789, -0.181, -0.054, 0.0334, 0.138,
    -0.0539, 0.18, 0.000852, 0.165, -0.227, 0.124, -0.121, -0.0765,
  ]
  weights[11]: [
    0.148, 0.242, -0.068, -0.0675, 0.167, 0.114, -0.131, 0.0742,
    -0.0667, 0.157, 0.0419, 0.0554, 0.154, 0.015, 0.189, 0.0623,
    -0.0682, -0.207, -0.197, -0.0872, -0.0147, 0.179, 0.0691, 0.0754,
    -0.216, -0.0581, 0.00139, -0.0585, 0.154, -0.0173, 0.0622, 0.0954,
  ]
  weights[12]: [
    0.0537, 0.0209, 0.172, -0.0245, 0.0612, 0.0497, 0.14, -0.205,
    -0.162, 0.116, -0.0281, 0.058, 0.00322, 0.018, 0.0215, 0.18,
    0.00543, 0.0444, 0.183, -0.169, -0.0222, 0.0983, -0.182, 0.0558,
    0.142, -0.144, -0.0725, -0.212, 0.168, -0.142, -0.0116, -0.168,
  ]
  weights[13]: [
    0.0341, 0.0137, 0.0487, -0.164, -0.000153, -0.0831, 0.22, 0.164,
    -0.199, 0.0778, 0.148, -0.2, -0.123, -0.00101, 0.037, -0.113,
    -0.141, -0.182, 0.158, 0.178, 0.0418, -0.0907, 0.0415, -0.105,
    -0.0642, -0.16, 0.0706, 0.118, -0.189, -0.162, -0.0316, 0.116,
  ]
  weights[14]: [
    -0.216, 0.133, -0.0732, 0.0918, -0.0892, -0.167, 0.0466, -0.0362,
    -0.248, 0.185, -0.191, -0.133, 0.0611, -0.0445, -0.0138, -0.153,
    -0.156, 0.205, 0.0244, 0.18, -0.0347, -0.0649, 0.0726, -0.0126,
    0.0753, -0.0804, -0.137, -0.0378, -0.165, -0.198, -0.0559, 0.0385,
  ]
  weights[15]: [
    0.0944, 0.0761, 0.0219, -0.0505, 0.171, -0.221, -0.244, 0.0419,
    -0.0894, -0.15, -0.035, 0.116, -0.091, -0.207, -0.0826, 0.115,
    0.0492, 0.103, -0.022, -0.00324, 0.224, -0.107, 0.165, 0.102,
    -0.0956, -0.171, 0.0922, 0.0877, -0.0113, 0.199, 0.226, -0.18,
  ]
  weights[16]: [
    -0.0423, 0.142, -0.111, -0.101, -0.0147, -0.0121, -0.144, 0.142,
    0.00562, 0.184, -0.0137, 0.123, -0.132, 0.0135, 0.111, -0.169,
    -0.104, -0.114, 0.144, -0.026, -0.22, 0.141, 0.0485, 0.15,
    0.133, 0.134, -0.192, 0.00855, 0.204, 0.137, -0.054, 0.0346,
  ]
  weights[17]: [
    -0.202, -0.158, 0.156, 0.108, 0.157, 0.149, 0.104, 0.0875,
    -0.173, 0.101, -0.0309, 0.174, -0.173, -0.0936, -0.125, -0.203,
    -0.128, 0.192, 0.181, -0.0186, -0.0674, 0.106, -0.00587, -0.114,
    0.00639, 0.0325, -0.0894, -0.179, -0.00937, 0.158, -0.0483, -0.0904,
  ]
  weights[18]: [
    -0.032, -0.178, -0.0995, 0.128, -0.000637, -0.0646, 0.168, 0.0462,
    -0.0973, 0.256, 0.178, 0.192, 0.168, -0.196, -0.107, 0.0786,
    -0.221, 0.199, 0.0679, 0.0156, 0.134, -0.0312, 0.0937, 0.114,
    0.155, 0.0117, 0.129, -0.104, -0.156, -0.129, 0.0943, 0.153,
  ]
  weights[19]: [
    0.182, -0.124, 0.118, 0.0713, -0.0391, 0.075, 0.149, -0.0327,
    0.188, 0.0883, 0.218, 0.159, 0.0496, -0.0816, -0.00922, 0.242,
    0.244, 0.0565, -0.00388, -0.102, 0.113, 0.0914, 0.0291, -0.226,
    0.083, -0.124, 0.00346, 0.12, -0.222, 0.181, 0.0277, -0.119,
  ]
  weights[20]: [
    0.112, -0.0962, -0.2, 0.16, -0.231, 0.116, -0.237, -0.00579,
    0.183, 0.0964, 0.0198, 0.19, 0.157, -4.43e-05, 0.136, -0.0254,
    0.156, -0.15, -0.12, 0.0958, 0.0906, 0.165, -0.134, -0.225,
    -0.0429, 0.0682, -0.0605, -0.143, 0.122, -0.111, -0.0497, -0.106,
  ]
  weights[21]: [
    0.0755, -0.0661, -0.0466, 0.123, -0.132, 0.06, -0.0121, -0.205,
    -0.173, 0.125, -0.212, 0.172, 0.175, 0.22, -0.212, -0.151,
    0.123, -0.174, 0.177, 0.183, -0.198, 0.154, -0.195, -0.172,
    0.16, 0.191, -0.178, -0.198, -0.0685, 0.112, -0.0428, 0.142,
  ]
  weights[22]: [
    -0.169, -0.06, -0.0929, 0.00022, -0.158, -0.0149, 0.131, -0.217,
    0.218, -0.0263, -0.118, 0.0463, 0.0503, -0.228, -0.0614, 0.163,
    -0.0158, 0.155, -0.0422, -0.0916, -0.0147, 0.159, 0.197, 0.0175,
    0.161, -0.164, -0.0326, 0.186, 0.0454, 0.177, 0.00968, -0.186,
  ]
  weights[23]: [
    0.15, 0.0625, 0.067, 0.0454, -0.16, 0.16, 0.0735, 0.168,
    0.0735, 0.231, 0.076, 0.176, 0.0103, -0.0935, -0.133, -0.191,
    -0.037, -0.13, 0.0726, 0.0782, -0.0863, 0.0568, -0.164, -0.0192,
    -0.039, 0.0723, 0.216, -0.118, -0.166, -0.175, 0.171, -0.168,
  ]
  weights[24]: [
    0.159, -0.152, -0.203, -0.0218, 0.0988, -0.199, -0.0428, -0.133,
    0.167, 0.153, 0.0729, -0.198, -0.17, 0.0991, 0.0824, 0.119,
    -0.0947, -0.0498, -0.0975, -0.00693, 0.124, -0.102, 0.0295, -0.179,
    0.17, 0.0544, -0.144, 0.0944, 0.15, 0.175, -0.0103, 0.00812,
  ]
  weights[25]: [
    0.0352, 0.0658, 0.134, 0.0149, 0.178, -0.0946, -0.196, -0.000272,
    -0.224, 0.176, -0.145, -0.0886, -0.0458, 0.192, 0.21, 0.112,
    0.191, 0.119, -0.213, 0.0244, -0.0512, 0.109, -0.00812, -0.0857,
    -0.203, -0.0364, -0.215, 0.0708, -0.0391, 0.214, 0.181, -0.169,
  ]
  weights[26]: [
    0.124, -0.0501, -0.111, -0.2, 0.203, -0.0311, 0.103, -0.114,
    -0.0406, 0.225, -0.0872, 0.162, 0.122, 0.124, -0.248, -0.141,
    -0.179, 0.166, 0.13, 0.202, -0.226, 0.00594, -0.122, 0.00436,
    -0.0757, -0.0891, -0.199, -0.000983, 0.156, -0.0931, -0.0287, -0.107,
  ]
  weights[27]: [
    0.199, -0.101, -0.176, 0.242, -0.0574, 0.0576, -0.095, -0.0821,
    -0.0791, -0.0531, -0.000467, 0.133, 0.127, -0.0893, 0.0234, -0.0473,
    -0.106, -0.136, 0.127, -0.0248, -0.0728, 0.149, 0.221, -0.206,
    0.00109, -0.156, 0.184, -0.024, -0.0349, -0.0767, -0.0432, -0.0495,
  ]
  weights[28]: [
    0.0943, 0.163, -0.0717, -0.0288, 0.047, -0.0865, 0.135, 0.214,
    0.0971, 0.263, -0.0385, -0.0982, -0.0779, 0.086, -0.0725, -0.113,
    -0.0291, -0.0141, 0.122, -0.219, 0.059, -0.0719, 0.0253, 0.165,
    0.132, 0.181, 0.16, -0.127, -0.00662, -0.178, -0.0302, 0.0826,
  ]
  weights[29]: [
    0.0518, -0.159, 0.0523, 0.0429, 0.197, 0.107, 0.0836, -0.0614,
    0.157, 0.201, -0.149, -0.0712, -0.106, 0.0108, -0.0867, -0.00139,
    -0.168, 0.0654, -0.168, 0.0952, 0.00887, -0.0394, 0.115, -0.0449,
    0.131, -0.0397, -0.182, 0.169, 0.152, -0.225, 0.0121, -0.163,
  ]
  weights[30]: [
    0.0204, -0.199, 0.25, 0.164, 0.232, 0.143, 0.0668, 0.113,
    0.0126, 0.201, 0.046, 0.0265, 0.061, 0.0458, -0.154, 0.0771,
    -0.212, 0.156, 0.0544, 0.0278, -0.08, 0.0662, -0.24, 0.0861,
    0.172, -0.106, -0.182, -0.00178, 0.191, 0.00337, 0.0369, 0.11,
  ]
  weights[31]: [
    -0.132, -0.191, 0.039, 0.154, -0.0943, -0.146, -0.144, -0.0111,
    -0.104, 0.0567, 0.129, 0.169, -0.197, 0.185, 0.0425, -0.173,
    -0.102, 0.119, -0.123, 0.057, -0.0125, -0.128, 0.0444, -0.112,
    0.047, -0.201, -0.156, -0.0204, 0.132, 0.0465, -0.015, 0.122,
  ]
  biases: [
    -0.0326, 0.0394, 0.0825, 0.0389, 0.00177, 0.0183, -0.0125, 8.84e-05,
    -0.133, -0.0276, -0.0434, 0.0256, 0.00772, -0.038, 0.0417, 0.0257,
    -0.0307, 0.0299, -0.0662, 0.075, 0.0647, -0.0278, -0.0202, -0.0468,
    -0.0235, -0.035, 0.0596, 0.0481, -0.188, -0.028, 0.0501, -0.037,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.286, 0.244, 0.213, 0.238, 0.283, 0.284, 0.215, 0.269,
    0.265, 0.257, 0.302, 0.239, 0.224, 0.246, 0.223, 0.262,
    0.267, 0.231, 0.419, 0.217, 0.212, 0.196, 0.251, 0.234,
    0.235, 0.312, 0.207, 0.194, 0.268, 0.228, 0.217, 0.207,
  ]
layer: BatchNormalization
  weights: [
    3.12, 1.48, 0.492, 1.11, 0.716, 1.6, 1.29, 0.711,
    1.92, 6.52, 1.67, 1.34, 1.05, 11.8, 2.85, 0.902,
    2.54, 0.985, 9.31, 1.05, 1.55, 1.52, 16.6, 2.11,
    6.84, 1.66, 0.787, 1.64, 1.49, 0.998, 0.895, 3.57,
  ]
  biases: [
    -0.444, -0.473, -0.397, -0.477, -0.513, -0.508, -0.496, -0.542,
    -0.436, -0.471, -0.493, -0.533, -0.459, 0.118, -0.333, -0.541,
    -0.407, -0.471, 0.305, -0.421, -0.39, -0.437, -0.458, -0.502,
    -0.464, -0.565, -0.456, -0.532, -0.428, -0.489, -0.448, -0.343,
  ]
layer: FullyConnected
  weights[0]: [
    0.0686, -0.203, 0.151, 0.167, -0.233, 0.193, -0.0541, 0.0653,
    -0.143, 0.202, -0.00933, -0.107, 0.12, -0.165, 0.192, 0.00659,
    0.0322, 0.23, 0.0919, 0.151, 0.0983, 0.147, -0.197, -0.198,
    0.0181, 0.0574, 0.137, 0.0378, -0.102, 0.0718, 0.239, -0.176,
  ]
  weights[1]: [
    0.0446, 0.156, -0.132, -0.0982, -0.214, -0.141, -0.0661, -0.00641,
    0.201, 0.0204, 0.188, -0.187, -0.162, 0.0413, -0.0779, -0.0516,
    -0.0349, -0.0333, 0.125, 0.058, -0.0471, -0.0474, 0.174, -0.0132,
    -0.00878, 0.142, 0.0868, -0.125, 0.142, 0.152, 0.056, 0.142,
  ]
  weights[2]: [
    0.2, 0.2, 0.0816, -0.244, -0.0875, -0.248, -0.199, 0.0288,
    -0.0241, 0.258, 0.172, 0.0869, -0.195, 0.0436, 0.143, 0.0858,
    -0.0307, -0.183, -2.73e-05, -0.112, 0.195, 0.0397, 0.0981, -0.0442,
    -0.042, -0.178, -0.0158, -0.014, -0.18, -0.0403, -0.0658, 0.0557,
  ]
  weights[3]: [
    0.127, 0.127, 0.0446, -0.148, -0.0471, 0.000837, -0.0585, 0.17,
    0.102, -0.238, 0.191, 0.16, -0.194, 0.238, -0.191, 0.112,
    0.141, -0.116, 0.0328, 0.212, 0.0444, -0.022, -0.0832, 0.166,
    0.0644, 0.189, -0.0937, -0.0794, 0.178, 0.182, -0.132, 0.0733,
  ]
  weights[4]: [
    -0.083, -0.102, 0.0119, 0.159, -0.154, 0.0855, 0.141, -0.0385,
    0.133, -0.164, -0.0992, -0.163, 0.197, -0.000466, 0.00962, 0.0175,
    0.0587, 0.21, 0.0938, 0.0589, 0.0496, -0.0599, -0.0557, -0.186,
    -0.0484, 0.182, 0.0715, 0.0977, 0.143, -0.0542, 0.148, -0.0665,
  ]
  weights[5]: [
    0.0856, -0.0379, -0.0899, 0.239, 0.194, 0.0142, 0.0361, 0.108,
    -0.151, 0.178, 0.0497, 0.0771, 0.116, -0.164, -0.0297, 0.0841,
    -0.0264, -0.00425, 0.161, -0.186, -0.14, -0.0961, -0.0683, -0.0155,
    0.169, 0.206, -0.159, -0.11, 0.139, -0.168, -0.156, 0.00731,
  ]
  weights[6]: [
    0.092, 0.22, -0.0697, -0.15, 0.089, 0.0852, -0.0411, 0.095,
    -0.0423, 0.144, -0.112, -0.152, -0.0445, -0.0061, -0.0441, -0.019,
    -0.203, -0.26, 0.000584, -0.017, -0.0216, -0.152, 0.212, -0.0353,
    0.133, -0.00604, -0.176, 0.0664, -0.185, -0.258, -0.116, -0.184,
  ]
  weights[7]: [
    0.0238, 0.00712, 0.0702, -0.146, 0.173, -0.0127, -0.0764, -0.159,
    0.0578, -0.059, 0.0297, -0.0675, 0.125, 0.00316, 0.00342, -0.107,
    0.026, -0.136, 0.254, 0.186, 0.173, -0.0239, 0.151, -0.12,
    -0.14, -0.215, -0.0215, -0.0865, -0.00346, -0.00316, 0.00347, 0.131,
  ]
  weights[8]: [
    -0.0858, 0.169, 0.126, 0.163, -0.0243, 0.00137, 0.171, -0.0699,
    -0.104, 0.0188, -0.231, 0.0252, 0.0126, -0.151, 0.117, -0.118,
    -0.127, -0.182, -0.0273, 0.134, -0.0419, -0.0349, -0.103, -0.224,
    -0.167, 0.0226, 0.0323, 0.0329, 0.181, 0.0236, -0.0111, 0.134,
  ]
  weights[9]: [
    0.0628, -0.183, -0.137, 0.176, -0.199, 0.125, 0.0808, -0.0281,
    0.0271, 0.143, 0.0448, -0.113, 0.0725, 0.0637, 0.0335, -0.199,
    -0.00952, 0.0716, -0.0122, -0.197, -0.188, 0.0445, -0.121, -0.183,
    -0.0107, -0.00679, -0.097, -0.0518, -0.0283, -0.148, 0.107, -0.115,
  ]
  weights[10]: [
    -0.128, -0.208, 0.0934, 0.183, 0.0803, 0.0127, 0.104, 0.174,
    -0.137, -0.0652, -0.236, -0.124, 0.152, 0.0653, 0.198, 0.0978,
    0.203, 0.0438, 0.0509, 0.158, 0.0228, -0.163, 0.0682, 0.0262,
    -0.0937, 0.192, -0.147, 0.124, 0.0174, 0.221, 0.21, -0.057,
  ]
  weights[11]: [
    0.117, -0.162, 0.176, 0.103, -0.171, 0.183, -0.0263, 0.235,
    0.0898, -0.0451, 0.141, 0.0532, 0.0299, -0.154, -0.0324, -0.00642,
    -0.0497, 0.0308, -0.0595, 0.0526, -0.0989, 0.128, -0.137, -0.157,
    0.177, 0.215, -0.0584, -0.124, 0.082, 0.24, -0.0611, 0.0963,
  ]
  weights[12]: [
    0.185, 0.00479, 0.0872, -0.204, -0.188, 0.122, -0.0954, -0.106,
    -0.127, 0.096, -0.194, -0.25, -0.138, -0.0446, -0.0438, -0.0785,
    0.145, -0.157, -0.0239, -0.0583, 0.0708, 0.0505, -0.07, -0.184,
    0.177, -0.0548, 0.00176, -0.204, -0.116, 0.0508, -0.166, -0.0577,
  ]
  weights[13]: [
    -0.00601, -0.18, 0.00395, 0.11, 0.216, 0.061, 0.0527, -0.0996,
    0.126, -0.123, -0.022, 0.115, 0.0288, 0.0999, 0.1, 0.185,
    0.106, -0.0911, 0.051, 0.0522, 0.0103, -0.0537, -0.191, -0.03,
    0.0699, -0.0542, -0.00668, 0.164, -0.228, -0.114, -0.058, -0.00693,
  ]
  weights[14]: [
    -0.0925, 0.0158, -0.18, -0.113, 0.056, -0.227, -0.00659, 0.162,
    -0.239, 0.0874, -0.18, -0.164, -0.0456, 0.0496, -0.242, -0.229,
    -0.262, 0.107, -0.184, -0.0836, -0.0776, -0.117, -0.211, -0.0239,
    0.167, 0.114, 0.114, 0.00172, -0.268, -0.0142, -0.0159, -0.0955,
  ]
  weights[15]: [
    -0.148, -0.0181, 0.117, 0.0972, 0.0856, 0.135, 0.197, -0.0526,
    0.221, -0.00682, 0.111, -0.0857, 0.177, 0.035, -0.0473, -0.111,
    0.173, 0.189, -0.0947, -0.0952, 0.0672, 0.167, 0.0286, 0.107,
    -0.0511, -0.0694, 0.125, -0.165, -0.0582, 0.18, -0.102, 0.102,
  ]
  weights[16]: [
    -0.0996, 0.12, -0.12, -0.173, 0.154, -0.143, -0.231, -0.238,
    -0.228, 0.016, -0.107, -0.101, 0.125, -0.0353, -0.145, 0.119,
    -0.167, 0.0229, 0.157, 0.104, -0.102, -0.135, -0.00443, -0.077,
    -0.109, -0.0986, -0.0937, 0.0796, 0.0113, -0.139, 0.0944, -0.0932,
  ]
  weights[17]: [
    -0.194, -0.0111, -0.102, -0.195, 0.184, -0.205, 0.17, -0.108,
    0.21, -0.0788, 0.199, 0.104, -0.0139, 0.0082, -0.0778, 0.0679,
    -0.111, -0.0995, -0.0854, -0.135, -0.166, 0.238, -0.153, 0.209,
    0.111, 0.00416, -0.0231, 0.234, 0.0851, 0.154, 0.0814, 0.171,
  ]
  weights[18]: [
    0.082, -0.00753, -0.174, -0.00594, 0.0661, -0.175, 0.00529, -0.108,
    -0.0245, -0.172, 0.196, 0.205, -0.0699, -0.218, -0.0672, 0.108,
    -0.0439, -0.204, 0.209, 0.0316, 0.105, -0.00308, -0.0662, 0.173,
    -0.0579, -0.192, 0.108, 0.138, -0.0622, 0.173, -0.0988, 0.0727,
  ]
  weights[19]: [
    0.209, 0.0906, 0.233, 0.106, 0.0442, -0.0423, 0.147, 0.135,
    0.331, -0.263, 0.231, -0.0294, 0.182, 0.0746, 0.277, 0.206,
    0.347, 0.128, 0.554, 0.0351, -0.0572, 0.183, 0.226, 0.149,
    -0.0127, -0.0166, 0.157, 0.217, 0.368, 0.198, -0.0715, 0.00744,
  ]
  weights[20]: [
    0.0688, 0.0974, 0.0538, 0.0844, 0.0253, -0.142, -0.0449, 0.256,
    -0.0902, -0.139, -0.2, -0.0511, 0.239, -0.0344, 0.00131, -0.143,
    0.171, 0.0945, -0.15, -0.0392, 0.11, 0.215, -0.16, 0.131,
    -0.16, -0.00902, -0.00192, -0.0287, 0.0472, -0.00524, 0.0938, 0.00983,
  ]
  weights[21]: [
    0.152, 0.218, -0.217, 0.0825, -0.0523, 7.49e-05, -0.0433, -0.046,
    -0.148, 0.118, -0.0934, 0.0288, 0.14, -0.221, -0.163, 0.15,
    0.0333, 0.0309, -0.0337, 0.184, 0.176, 0.0136, -0.129, 0.103,
    -0.227, 0.115, -0.208, 0.246, -0.21, 0.00204, 0.114, 0.0631,
  ]
  weights[22]: [
    -0.088, 0.116, 0.106, 0.0492, 0.0658, -0.0882, -0.0245, -0.245,
    -0.0785, -0.107, -0.0235, 0.122, -0.188, 0.00158, 0.128, 0.169,
    -0.19, -0.195, 0.227, -0.0369, -0.141, -0.0344, -0.0194, -0.0332,
    -0.242, -0.33, 0.0771, -0.107, -0.0302, -0.16, -0.158, -0.196,
  ]
  weights[23]: [
    -0.0852, 0.107, -0.0604, -0.108, -0.114, 0.239, -0.0611, 0.226,
    0.123, 0.0072, -0.0673, 0.135, -0.0686, 0.105, -0.131, -0.0817,
    0.142, -0.0972, -0.0483, -0.237, -0.211, -0.027, -0.0469, 0.249,
    -0.155, 0.13, 0.0225, 0.0748, -0.0661, -0.0338, 0.00512, 0.166,
  ]
  weights[24]: [
    -0.222, -0.232, -0.073, 0.0423, -0.119, -0.0726, 0.101, -0.0757,
    -0.0745, 0.0104, -0.137, 0.0776, -0.0196, 0.212, -0.156, -0.0858,
    -0.29, -0.024, -0.437, -0.116, -0.232, -0.16, -0.00117, -0.258,
    0.094, -0.0043, -0.25, -0.0198, 0.0337, -0.0312, 0.00914, 0.0912,
  ]
  weights[25]: [
    0.00254, -0.126, 0.144, 0.192, -0.0913, 0.162, 0.183, -0.12,
    0.182, -0.0866, 0.153, 0.152, 0.0155, -0.00811, -0.0819, -0.0621,
    0.154, 0.233, 0.0711, -0.124, -0.0874, 0.248, -0.216, 0.0241,
    -0.0979, 0.17, -0.0255, -0.0501, 0.154, 0.163, 0.0951, -0.027,
  ]
  weights[26]: [
    -0.0858, -0.19, -0.184, -0.0724, -0.0814, 0.118, 0.0917, -0.0801,
    -0.105, -0.0153, 0.141, 0.176, 0.0529, 0.0612, 0.00861, 0.109,
    -0.248, -0.201, 0.145, 0.194, -0.0394, -0.251, 0.0799, -0.166,
    0.00959, 0.0725, -0.0994, -0.0552, -0.172, -0.0113, -0.125, -0.157,
  ]
  weights[27]: [
    -0.0533, 0.13, -0.0542, -0.0494, -0.0871, -0.119, -0.226, -0.0921,
    -0.0787, -0.0457, -0.0163, -0.0272, -0.141, 0.149, -0.135, 0.137,
    -0.0572, 0.0171, 0.127, 0.113, 0.0421, -0.132, 0.113, 0.0894,
    -0.146, -0.288, -0.228, 0.0334, -0.182, -0.209, 0.0431, -0.17,
  ]
  weights[28]: [
    -0.232, -0.17, 0.194, 0.0847, 0.0477, 0.125, -0.0165, -0.145,
    -0.0898, 0.158, -0.189, -0.087, 0.0762, 0.183, -0.0222, -0.14,
    0.0957, 0.235, -0.225, -0.153, 0.148, -0.0329, -0.205, -0.00022,
    0.0978, -0.165, 0.243, -0.14, -0.0713, 0.128, 0.0979, 0.132,
  ]
  weights[29]: [
    0.0091, -0.145, -0.24, -0.104, 0.019, 0.181, -0.103, -0.176,
    -0.0224, 0.146, -0.0177, -0.165, 0.146, 0.229, -0.142, 0.0328,
    0.0627, 0.0676, -0.233, -0.11, 0.137, -0.0761, 0.0832, -0.186,
    0.02, -0.137, -0.0933, -0.21, -0.103, -0.0564, -0.11, -0.16,
  ]
  weights[30]: [
    -0.161, -0.00356, 0.0249, 0.0564, 0.111, -0.136, -0.171, -0.00173,
    -0.187, -0.0285, -0.00871, 0.146, -0.19, 0.0805, -0.195, -0.0846,
    -0.108, 0.0674, 0.1, 0.0782, 0.0246, -0.208, 0.0183, -0.131,
    -0.0259, -0.039, -0.201, 0.17, -0.123, 0.0748, -0.00773, -0.176,
  ]
  weights[31]: [
    -0.207, -0.18, -0.162, -0.0539, -0.193, 0.141, 0.119, 0.182,
    0.201, -0.0334, 0.0801, -0.179, 0.0305, -0.0726, -0.0783, 0.181,
    0.092, 0.194, 0.0888, 0.103, -0.0879, 0.0861, 0.156, -0.0155,
    0.0818, 0.0856, 0.133, 0.0365, -0.00173, -0.172, 0.2, -0.151,
  ]
  biases: [
    0.0632, -0.139, 0.0874, -0.0246, 0.061, -0.137, 0.0552, 0.0524,
    0.0503, 0.099, 0.0472, 0.0387, -0.0205, -0.0449, -0.000567, 0.0473,
    0.0665, -0.0802, 0.0382, -0.183, 0.0543, 0.0448, 0.0837, -0.104,
    -0.0421, 0.0503, 0.104, 0.0824, 0.0989, -0.0597, 0.105, 0.0363,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.234, 0.278, 0.215, 0.302, 0.223, 0.24, 0.212, 0.21,
    0.255, 0.223, 0.197, 0.218, 0.143, 0.276, 0.0439, 0.215,
    0.213, 0.301, 0.205, -0.118, 0.225, 0.208, 0.213, 0.286,
    0.0791, 0.215, 0.214, 0.214, 0.208, 0.108, 0.214, 0.229,
  ]
layer: BatchNormalization
  weights: [
    0.852, 8.15, 1.14, 1.07, 0.874, 2.98, 1.17, 1.91,
    3.87, 1.19, 0.91, 2.02, 2.63, 1.58, 2.19, 0.586,
    1.27, 2.58, 0.9, 0.69, 0.974, 0.995, 2.9, 2.79,
    1.79, 0.716, 1.07, 1.44, 0.949, 2.05, 0.966, 0.88,
  ]
  biases: [
    -0.45, 0.338, -0.547, -0.457, -0.281, -0.174, -0.537, -0.362,
    -0.644, -0.481, -0.352, -0.309, -0.813, -0.495, -1.3, -0.308,
    -0.625, -0.277, -0.345, -0.768, -0.386, -0.363, -0.776, -0.305,
    -1.06, -0.304, -0.518, -0.681, -0.616, -0.877, -0.485, -0.299,
  ]
layer: FullyConnected
  weights[0]: [
    -0.181, 0.126, -0.201, 0.206, -0.0414, 0.18, -0.0628, -0.078,
    -0.132, -0.0593, -0.178, -0.117, 0.305, 0.0766, 0.277, -0.0439,
    -0.248, 0.314, -0.197, 0.269, -0.0878, -0.164, -0.213, 0.174,
    0.421, -0.11, -0.0624, -0.176, -0.2, 0.355, -0.0321, -0.164,
  ]
  biases: [
    -0.0812,
  ]
layer: Activation
  function: Sigmoid
