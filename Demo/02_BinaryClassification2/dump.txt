layer: InputScaling
  scale: [
    1, 1,
  ]
layer: FullyConnected
  weights[0]: [
    1.64, -1.75,
  ]
  weights[1]: [
    -0.66, -1.53,
  ]
  weights[2]: [
    -1.25, 0.582,
  ]
  weights[3]: [
    -0.0812, -0.346,
  ]
  weights[4]: [
    0.651, -1.26,
  ]
  weights[5]: [
    0.272, 0.182,
  ]
  weights[6]: [
    1.55, 0.123,
  ]
  weights[7]: [
    -0.593, 0.787,
  ]
  weights[8]: [
    -1.36, -1.23,
  ]
  weights[9]: [
    -0.637, 1.59,
  ]
  weights[10]: [
    -1.24, -1.01,
  ]
  weights[11]: [
    -0.633, 0.918,
  ]
  weights[12]: [
    1.4, 1.38,
  ]
  weights[13]: [
    -1.7, -0.433,
  ]
  weights[14]: [
    -0.735, 0.689,
  ]
  weights[15]: [
    0.386, 1.84,
  ]
  weights[16]: [
    -0.427, -1.01,
  ]
  weights[17]: [
    0.138, -1.17,
  ]
  weights[18]: [
    -1.19, 0.77,
  ]
  weights[19]: [
    0.753, -1.25,
  ]
  weights[20]: [
    1.69, -1.98,
  ]
  weights[21]: [
    -0.714, 1.35,
  ]
  weights[22]: [
    0.155, -1.15,
  ]
  weights[23]: [
    -1.08, -0.124,
  ]
  weights[24]: [
    -0.637, -0.689,
  ]
  weights[25]: [
    1.63, 0.649,
  ]
  weights[26]: [
    -0.488, -0.386,
  ]
  weights[27]: [
    1.02, -1.2,
  ]
  weights[28]: [
    0.353, -1.69,
  ]
  weights[29]: [
    0.701, -0.755,
  ]
  weights[30]: [
    -0.0483, -1.33,
  ]
  weights[31]: [
    -1.02, 0.66,
  ]
  biases: [
    -1.7e-06, -0.48, 0.667, 0.437, 0.312, -0.172, 0.283, 0.141,
    0.333, 0.265, 0.714, 0.444, 0.169, 0.413, -0.000461, 0.279,
    -0.245, -0.173, 0.222, 0.206, 0.000419, -0.128, -0.245, -0.145,
    0.496, 0.0724, -1.15, 0.449, 0.513, 0.0541, -0.16, 0.357,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.31, 0.371, 0.237, 0.232, 0.29, 0.397, 0.25, 0.257,
    0.364, 0.356, 0.29, 0.237, 0.242, 0.324, 0.284, 0.22,
    0.317, 0.326, 0.248, 0.274, 0.349, 0.355, 0.341, 0.366,
    0.257, 0.24, 0.42, 0.233, 0.317, 0.364, 0.287, 0.287,
  ]
layer: BatchNormalization
  weights: [
    1.48, 4.03, 2.38, 5.72, 2.53, 9.41, 1.53, 2.78,
    2.98, 1.57, 2.74, 2.15, 1.28, 3.11, 3.01, 1.24,
    6.79, 6.11, 2.34, 2.49, 1.39, 1.89, 5.58, 6.5,
    4.88, 1.34, 7.61, 1.9, 2.32, 3.24, 5.28, 2.56,
  ]
  biases: [
    -0.465, 2.24, -0.959, -1.2, -0.598, -0.835, -1.67, -0.882,
    0.817, -1.26, -0.074, -1.25, -1.96, 0.377, -0.376, -1.67,
    2.01, 1.32, -0.498, -0.49, -0.432, -0.723, 1.35, 1.68,
    -0.222, -1.61, 4.92, -0.887, -0.41, -0.518, 1.25, -0.761,
  ]
layer: FullyConnected
  weights[0]: [
    -0.295, -0.183, 0.184, 0.131, -0.284, 0.0534, -0.223, 0.35,
    -0.0667, 0.379, 0.143, 0.194, -0.231, -0.0032, 0.312, 0.11,
    -0.092, -0.349, 0.352, -0.334, 0.0191, 0.278, -0.174, 0.228,
    -0.0175, -0.0783, 0.0338, -0.0669, 0.025, -0.143, 0.0618, 0.388,
  ]
  weights[1]: [
    -0.195, 0.0303, -0.0693, -0.0957, 0.0104, 0.0619, -0.231, -0.201,
    0.132, 0.0475, 0.202, 0.119, 0.108, 0.114, 0.162, 0.175,
    0.22, 0.0837, 0.0599, 0.155, -0.0526, -0.22, 0.17, 0.197,
    -0.0479, 0.0923, 0.0843, -0.187, 0.107, 0.116, 0.204, 0.03,
  ]
  weights[2]: [
    -0.171, -0.255, -0.0787, -0.289, -0.232, -0.0683, -0.218, -0.0444,
    -0.371, 0.193, -0.303, 0.318, 0.363, -0.183, 0.21, 0.233,
    -0.151, -0.0531, -0.0212, -0.0112, -0.0105, 0.296, -0.309, 0.081,
    -0.416, -0.0733, -0.0546, -0.168, -0.244, -0.0309, 0.0237, -0.0543,
  ]
  weights[3]: [
    0.353, 0.185, -0.042, 0.117, 0.42, 0.233, 0.166, -0.0682,
    -0.0358, -0.254, -0.306, -0.0595, 0.0138, -0.0208, -0.293, -0.00394,
    0.138, 0.333, -0.0502, 0.136, 0.244, -0.162, 0.286, -0.376,
    -0.281, 0.055, -0.0933, 0.286, 0.472, 0.367, 0.253, -0.35,
  ]
  weights[4]: [
    -0.269, -0.124, 0.371, 0.191, -0.138, -0.149, -0.275, 0.273,
    0.242, 0.0839, 0.153, 0.259, -0.142, 0.0875, 0.145, 0.137,
    0.0352, -0.145, 0.335, -0.293, -0.236, -0.123, -0.272, 0.0312,
    0.0663, -0.0821, -0.212, 0.0599, 0.0196, -0.239, -0.159, -0.00665,
  ]
  weights[5]: [
    -0.346, -0.199, 0.248, 0.196, -0.0356, -0.226, -0.19, 0.0964,
    0.242, 0.365, -0.0728, 0.181, 0.00341, 0.182, -0.0207, 0.00962,
    -0.102, -0.314, 0.345, -0.159, -0.146, -0.00049, -0.189, -0.0479,
    -0.114, -0.0803, -0.0457, -0.0899, -0.0855, -0.211, 0.0576, 0.382,
  ]
  weights[6]: [
    0.214, -0.0676, 0.00859, -0.159, 0.0371, 0.0544, 0.0436, -0.155,
    -0.203, -0.00163, -0.11, 0.0256, 0.136, -0.354, 0.0289, -0.107,
    0.0114, -0.0647, -0.0342, 0.207, -0.0639, -0.234, 0.17, -0.0319,
    0.125, 0.123, -0.214, 0.203, 0.000817, 0.23, 0.00145, -0.323,
  ]
  weights[7]: [
    -0.315, 0.0382, 0.167, 0.0964, -0.294, 0.0556, -0.285, -0.00521,
    -0.0339, 0.345, 0.0586, 0.144, -0.0386, -0.104, 0.0177, 0.298,
    -0.0192, -0.341, 0.0796, -0.0931, -0.335, 0.0612, -0.284, 0.102,
    -0.058, 0.0368, -0.245, -0.148, -0.345, -0.304, -0.0613, -0.0568,
  ]
  weights[8]: [
    -0.0178, 0.0425, -0.162, -0.0387, 0.223, -0.141, 0.163, -0.27,
    0.0038, -0.135, -0.137, -0.292, 0.0661, -0.17, -0.139, -0.0901,
    0.286, 0.237, -0.265, 0.174, 0.00083, -0.312, 0.186, -0.302,
    -0.167, 0.26, -0.0178, 0.369, 0.291, 0.389, -0.0592, -0.34,
  ]
  weights[9]: [
    0.33, -0.158, -0.254, 0.152, 0.0908, -0.0546, 0.319, -0.0626,
    -0.0785, -0.159, -0.171, -0.0808, 0.196, -0.104, -0.167, 0.0755,
    0.167, 0.272, -0.00077, 0.238, 0.205, -0.142, 0.146, -0.398,
    0.0657, 0.18, -0.202, 0.0497, 0.0851, 0.309, 0.0146, 0.0728,
  ]
  weights[10]: [
    0.112, 0.209, -0.296, 0.162, -0.0471, -0.158, 0.201, 0.137,
    -0.0287, -0.202, 0.203, 0.0783, -0.132, -0.0249, -0.161, 0.102,
    0.0691, 0.0678, 0.046, 0.146, 0.274, -0.0311, -0.0285, -0.268,
    -0.165, -0.0162, -0.0823, 0.268, 0.125, 0.229, -0.125, -0.0967,
  ]
  weights[11]: [
    -0.0535, 0.000165, 0.179, 0.0786, 0.0429, -0.0526, 0.0263, -0.0223,
    0.339, -0.0649, 0.261, -0.0063, -0.0296, -0.0945, -0.124, 0.00969,
    0.0848, 0.117, 0.0255, -0.00205, 0.0221, 0.157, 0.0479, 0.106,
    0.355, -0.281, 0.0794, 0.141, -0.127, 0.0259, 0.159, -0.199,
  ]
  weights[12]: [
    -0.0872, -0.337, 0.0363, -0.218, -0.0994, -0.0342, 0.165, 0.0241,
    -0.0825, -0.0357, -0.109, -0.153, 0.332, 0.0814, -0.328, 0.189,
    0.0356, -0.259, -0.211, -0.111, -0.0316, -0.0835, -0.207, -0.317,
    0.0672, 0.285, 0.0323, -0.162, -0.0675, -0.222, -0.174, -0.311,
  ]
  weights[13]: [
    0.0758, -0.0863, -0.352, -0.328, -0.111, 0.378, -0.0363, 0.142,
    -0.301, 0.186, -0.297, -0.218, 0.228, -0.142, -0.255, 0.245,
    -0.374, -0.261, -0.032, -0.13, 0.0275, -0.0894, -0.193, 0.0106,
    -0.18, 0.328, -0.101, -0.0753, -0.0423, -0.0426, -0.122, -0.204,
  ]
  weights[14]: [
    -0.191, 0.0504, -0.157, -0.107, -0.00196, 0.0139, -0.0162, -0.00146,
    0.127, -0.169, 0.284, -0.23, -0.28, 0.0798, -0.183, -0.18,
    -0.017, 0.106, -0.0821, -0.192, -0.188, 0.0254, 0.0664, 0.211,
    0.0897, -0.0341, 0.181, -0.149, 0.175, 0.0693, -0.00848, -0.113,
  ]
  weights[15]: [
    0.186, 0.166, -0.122, 0.269, 0.338, -0.266, 0.102, 0.026,
    -0.122, -0.224, -0.037, -0.19, -0.193, 0.0446, -0.102, 0.0109,
    0.106, 0.244, -0.254, 0.125, 0.26, -0.294, 0.00159, -0.268,
    0.117, 0.0365, -0.229, 0.287, 0.206, 0.308, 0.207, -0.0323,
  ]
  weights[16]: [
    -0.268, 0.157, 0.301, 0.295, -0.00685, -0.133, -0.358, -0.183,
    0.296, 0.073, 0.306, 0.107, -0.111, 0.334, -0.115, -0.0664,
    0.133, 0.311, -0.0221, -0.134, -0.179, -0.228, 0.00467, 0.338,
    0.333, -0.239, 0.00094, 0.105, 0.109, -0.256, 0.0781, 0.0312,
  ]
  weights[17]: [
    -0.0519, -0.185, 0.0141, 0.147, -0.0819, -0.103, -0.0523, -0.0547,
    -0.134, 0.239, -0.0328, -0.0105, 0.148, 0.0808, -0.00329, 0.254,
    0.163, 0.132, 0.234, -0.247, -0.116, 0.181, -0.252, 0.216,
    -0.000378, -0.0194, 0.177, -0.0836, 0.041, 0.0784, 0.0738, 0.0682,
  ]
  weights[18]: [
    0.0875, -0.213, -0.254, -0.223, 0.045, 0.371, 0.251, -0.135,
    -0.00821, 0.0862, -0.145, 0.114, 0.375, -0.219, 0.118, 0.238,
    0.0494, 0.0297, -0.0864, -0.0835, -0.106, 0.235, 0.143, -0.0396,
    -0.107, 0.105, 0.0684, 0.0379, -0.103, -0.229, 0.0547, -0.134,
  ]
  weights[19]: [
    0.0538, 0.182, -0.234, 0.213, 0.0924, -0.168, 0.114, -0.205,
    -0.154, 0.0483, -0.2, 0.0871, -0.203, -0.0841, 0.0843, 0.0499,
    0.0816, 0.233, 0.0659, 0.134, 0.182, -0.134, 0.194, -0.156,
    -0.097, 0.165, 0.0392, 0.27, -0.065, -0.103, 0.0618, 0.0487,
  ]
  weights[20]: [
    -0.197, -0.309, 0.312, -0.271, -0.181, -0.101, 0.0167, 0.0268,
    -0.164, 0.228, -0.256, 0.196, 0.0736, -0.208, -0.061, 0.188,
    -0.328, 0.0397, 0.327, 0.107, -0.313, -0.0186, -0.00681, -0.122,
    0.0464, 0.16, -0.213, 0.00389, -0.31, -0.317, 0.0368, 0.318,
  ]
  weights[21]: [
    -0.354, -0.329, -0.0602, 0.00769, -0.178, 0.272, -0.0612, 0.0835,
    -0.228, 0.169, -0.294, 0.113, 0.245, -0.325, 0.304, 0.0616,
    -0.237, -0.0795, 0.0265, -0.327, -0.207, 0.316, -0.145, 0.0464,
    -0.173, -0.00101, -0.00113, 0.0317, 0.0836, -0.138, -0.0215, -0.101,
  ]
  weights[22]: [
    -0.2, 0.253, 0.16, 0.251, -0.0284, -0.288, 0.0374, 0.126,
    0.162, 0.0928, -0.0681, 0.258, -0.0312, 0.283, 0.135, 0.168,
    0.14, 0.133, 0.129, -0.214, -0.269, -0.112, -0.127, -0.0117,
    0.161, -0.0383, -0.0724, -0.116, -0.18, -0.124, -0.0813, 0.19,
  ]
  weights[23]: [
    0.104, -0.307, -0.306, -0.334, 0.0561, 0.0964, 0.302, -0.125,
    -0.416, 0.0779, -0.0844, -0.22, 0.2, -0.283, 0.0937, 0.318,
    -0.133, -0.31, -0.295, -0.000973, 0.000601, 0.151, -0.197, -0.205,
    -0.27, 0.204, 0.0673, -0.155, -0.125, -0.258, 0.0611, -0.0604,
  ]
  weights[24]: [
    -0.218, -0.0252, 0.196, 0.0501, -0.111, 0.0874, 0.0136, 0.121,
    0.0419, 0.0671, 0.0819, -0.00459, -0.0658, -0.0734, -0.151, 0.294,
    -0.292, -0.224, -0.0429, 0.111, 0.0882, 0.158, 0.0568, 0.123,
    -0.3, 0.0905, -0.0592, 0.065, -0.137, -0.142, -0.277, 0.0393,
  ]
  weights[25]: [
    -0.281, -0.028, -0.124, 0.158, 0.0597, -0.0642, 0.281, -0.0209,
    -0.225, -0.15, 0.0928, -0.138, 0.133, -0.118, -0.0685, 0.206,
    -0.108, 0.147, 0.114, -0.0425, -0.305, -0.101, -0.218, 0.0318,
    0.0678, 0.236, -0.199, -0.106, -0.126, -0.104, -0.213, -0.266,
  ]
  weights[26]: [
    -0.084, 0.16, 0.0719, 0.0432, 0.159, -0.111, 0.164, -0.321,
    -0.0889, 0.00213, 0.0289, -0.00942, -0.0995, -0.126, -0.222, -0.163,
    0.0553, 0.237, 0.0496, 0.0561, 0.0585, -0.261, -0.054, -0.101,
    0.218, 0.000384, -0.112, 0.23, 0.349, -0.0872, 0.167, -0.188,
  ]
  weights[27]: [
    0.0989, -0.0256, 0.11, -0.0688, -0.0968, -0.159, -0.0252, 0.0777,
    0.0181, -0.127, 0.145, 0.00739, 0.0774, 0.285, 0.118, 0.076,
    -0.0233, -0.19, -0.0314, 0.0443, -0.169, -0.119, -0.14, 0.108,
    0.217, -0.293, 0.00592, -0.11, 0.0097, 0.11, 0.141, 0.291,
  ]
  weights[28]: [
    0.0417, -0.331, -0.0527, -0.36, -0.211, 0.23, 0.249, -0.0865,
    -0.138, 0.161, 0.0109, 0.167, 0.256, -0.232, 0.221, 0.33,
    -0.304, -0.238, -0.183, -0.159, -0.207, 0.119, -0.365, -0.127,
    -0.351, 0.259, -0.00743, -0.213, -0.00611, -0.15, -0.0531, -0.0713,
  ]
  weights[29]: [
    -0.198, 0.34, 0.0992, -0.064, 0.0648, -0.256, -0.00279, -0.244,
    0.401, 0.122, 0.408, 0.016, -0.174, 0.364, -0.00521, 0.0137,
    0.24, 0.175, 0.0976, 0.0198, -0.0987, 0.0454, -0.0542, 0.239,
    0.216, -0.148, 0.107, 0.0844, -0.107, 0.0351, 0.228, -0.212,
  ]
  weights[30]: [
    -0.0186, 0.228, 0.0215, 0.25, 0.24, -0.0391, -0.0851, -0.329,
    0.209, -0.0242, 0.0847, -0.304, -0.34, 0.0158, -0.243, -0.121,
    0.312, 0.335, -0.293, 0.316, 0.173, -0.332, 0.0362, 0.0925,
    0.0608, -0.016, -0.0275, -0.0418, 0.221, 0.0298, 0.193, -0.342,
  ]
  weights[31]: [
    -0.272, -0.154, 0.24, -0.0769, -0.158, 0.229, 0.131, -0.0572,
    -0.0141, 0.257, -0.333, 0.299, 0.0348, -0.101, -0.0819, 0.329,
    -0.104, -0.2, 0.158, -0.294, 0.042, 0.172, -0.159, 0.119,
    -0.0151, 0.288, 0.131, 0.00353, -0.293, -0.342, -0.0843, 0.141,
  ]
  biases: [
    -0.0252, -0.0196, 0.14, 0.16, 0.17, 0.159, 0.117, 0.091,
    0.168, 0.0769, 0.0409, -0.0583, 0.000685, -0.0778, -0.0375, 0.118,
    0.121, -0.0853, 0.0547, -0.0417, 0.0981, 0.129, 0.0806, -0.0301,
    0.095, 0.0821, 0.132, 0.077, 0.116, -0.136, 0.115, 0.118,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.343, 0.201, 0.384, 0.123, 0.193, 0.225, 0.135, 0.236,
    0.177, 0.169, 0.141, 0.407, 0.335, 0.431, 0.373, 0.171,
    0.367, 0.313, 0.286, 0.329, 0.235, 0.249, 0.35, 0.398,
    0.202, 0.253, 0.187, 0.243, 0.373, 0.431, 0.316, 0.301,
  ]
layer: BatchNormalization
  weights: [
    0.394, 1.33, 0.445, 0.35, 0.56, 0.506, 0.74, 0.472,
    0.422, 0.509, 0.881, 0.913, 0.612, 0.473, 0.922, 0.449,
    0.427, 1.07, 0.653, 0.873, 0.498, 0.506, 0.711, 0.478,
    0.836, 0.879, 0.646, 1.04, 0.41, 0.554, 0.421, 0.471,
  ]
  biases: [
    -0.604, -0.38, -0.442, -0.397, -0.58, -0.408, -0.609, -0.624,
    -0.362, -0.541, -0.337, -0.59, -0.736, -0.609, -0.612, -0.564,
    -0.42, -0.529, -0.427, -0.569, -0.694, -0.602, -0.609, -0.557,
    -0.51, -0.459, -0.524, -0.523, -0.523, -0.608, -0.582, -0.571,
  ]
layer: FullyConnected
  weights[0]: [
    0.394, -0.0648, -0.109, 0.379, 0.523, 0.137, -0.0328, 0.376,
    -0.175, -0.0823, 0.0675, -0.417, -0.367, -0.288, -0.0584, 0.0899,
    0.0938, 0.196, -0.57, 0.347, -0.032, -0.123, 0.173, -0.333,
    0.256, -0.203, -0.0744, 0.0775, 0.0484, -0.0944, -0.102, 0.231,
  ]
  weights[1]: [
    0.197, -0.107, 0.296, -0.0309, 0.18, 0.309, 0.0782, 0.383,
    0.0291, -0.384, -0.198, -0.381, -0.275, -0.0459, -0.071, 0.0428,
    0.108, 0.324, -0.286, 0.00676, 0.428, 0.384, 0.27, -0.291,
    0.0443, -0.245, 0.0821, 0.24, 0.267, -0.153, -0.0971, 0.104,
  ]
  weights[2]: [
    0.255, 0.0601, 0.0725, -0.226, 0.262, 0.37, -0.115, 0.347,
    -0.136, -0.424, -0.304, 0.0121, -0.279, -0.0549, 0.0384, -0.426,
    0.488, 0.471, -0.439, -0.11, 0.0815, 0.222, 0.46, -0.361,
    0.262, -0.14, -0.125, 0.258, -0.128, 0.277, -0.25, 0.42,
  ]
  weights[3]: [
    -0.211, -0.137, 0.299, 0.114, -0.229, -0.079, -0.058, -0.0595,
    -0.199, 0.0823, -0.268, -0.00472, 0.301, 0.0795, 0.11, -0.279,
    -0.296, -0.193, 0.306, -0.0883, 0.0579, 0.183, -0.142, 0.536,
    0.204, 0.498, -0.0441, -0.196, 0.116, -0.354, -0.173, 0.264,
  ]
  weights[4]: [
    0.0852, 0.0536, 0.34, 0.0603, 0.114, -0.0231, 0.303, 0.155,
    0.0652, 0.435, 0.379, -0.211, 0.0286, 0.231, -0.402, 0.209,
    -0.153, 0.0947, 0.214, -0.0399, 0.156, 0.332, -0.172, 0.117,
    0.335, -0.236, -0.159, -0.251, 0.174, -0.322, 0.0364, 0.356,
  ]
  weights[5]: [
    -0.576, -0.0848, -0.0197, -0.0323, -0.384, -0.311, 0.252, 0.0633,
    0.297, 0.0842, 0.225, 0.165, -0.079, 0.0815, -0.107, 0.36,
    -0.42, -0.35, -0.0148, 0.166, -0.13, -0.189, -0.464, -0.334,
    -0.306, -0.257, 0.161, -0.212, 0.0482, -0.294, 0.359, -0.0798,
  ]
  weights[6]: [
    -0.304, 0.146, -0.409, -0.347, -0.00819, -0.24, -0.147, -0.226,
    -0.047, -0.321, 0.0353, 0.222, -0.00787, -0.369, 0.395, -0.149,
    0.24, -0.141, 0.113, -0.106, -0.164, -0.412, 0.157, -0.235,
    0.118, 0.271, 0.202, 0.181, -0.141, 0.115, 0.114, -0.444,
  ]
  weights[7]: [
    0.188, -0.171, 0.188, -0.0847, 0.207, 0.436, -0.152, 0.332,
    -0.0284, 0.0407, -0.0743, -0.198, -0.0728, -0.194, -0.256, -0.0834,
    -0.259, 0.213, -0.0815, -0.222, 0.22, 0.00839, 0.0317, -0.276,
    0.0447, 0.0904, -0.105, 0.0275, 0.00347, -0.429, -0.274, 0.145,
  ]
  weights[8]: [
    0.189, -0.0805, 0.347, 0.000702, 0.126, 0.364, 0.134, -0.0043,
    -0.225, 0.16, -0.186, -0.0181, -0.0884, -0.209, -0.13, 0.0819,
    0.0574, 0.17, -0.0653, 0.111, 0.205, -0.0922, 0.1, -0.0695,
    0.101, -0.34, -0.289, 0.152, -0.0237, -0.264, -0.0903, 0.158,
  ]
  weights[9]: [
    -0.229, -0.0578, 0.00445, -0.261, 0.0558, -0.247, -0.0793, -0.159,
    -0.074, 0.107, 0.0465, -0.0688, 0.175, 0.242, -0.189, -0.137,
    -0.447, -0.123, 0.175, 0.00375, 0.227, 0.185, -0.0393, 0.32,
    0.0917, 0.491, -0.0394, -0.232, 0.178, -0.165, -0.131, 0.203,
  ]
  weights[10]: [
    -0.473, 0.184, -0.17, 0.353, 0.0275, -0.224, 0.289, -0.292,
    0.41, 0.207, 0.00985, 0.184, -0.217, 0.067, 0.0111, 0.18,
    0.107, -0.0854, -0.0823, 0.00913, -0.236, -0.125, -0.359, -0.28,
    -0.229, -0.134, 0.132, 0.0188, -0.247, -0.208, 0.365, 0.0118,
  ]
  weights[11]: [
    -0.374, 0.0525, -0.289, 0.0457, 0.0996, 0.134, -0.0409, -0.172,
    -0.0952, -0.42, -0.266, 0.383, -0.269, -0.484, 0.179, 0.172,
    0.114, -0.266, -0.29, -0.295, -0.301, -0.414, 0.41, -0.513,
    0.0296, 0.0439, 0.244, 0.4, -0.412, 0.2, 0.362, -0.332,
  ]
  weights[12]: [
    0.137, -0.273, -0.089, 0.225, -0.101, 0.0401, 0.0927, -0.184,
    0.182, 0.298, 0.374, -0.0872, -0.0455, -0.177, -0.0986, 0.0138,
    -0.236, 0.156, -0.0933, 0.274, 0.116, 0.103, 0.1, -0.143,
    0.0563, -0.143, 0.0449, -0.0309, -0.278, -0.217, 0.0557, -0.0839,
  ]
  weights[13]: [
    -0.0187, 0.0951, -0.107, -0.162, -0.0821, -0.105, -0.072, 0.0817,
    -0.209, -0.155, 0.0202, -0.259, 0.13, 0.305, -0.163, -0.0141,
    -0.226, -0.13, 0.0847, -0.194, -0.127, -0.0867, -0.262, 0.283,
    0.0486, 0.0966, -0.0861, -0.128, -0.013, 0.0223, 0.0264, 0.209,
  ]
  weights[14]: [
    -0.0839, 0.238, -0.315, -0.0979, 0.0996, -0.0135, -0.269, -0.0771,
    -0.0332, 0.0049, 0.0949, 0.388, 0.0348, -0.256, 0.518, 0.0685,
    0.317, -0.112, -0.125, -0.0316, -0.198, -0.206, 0.247, 0.00295,
    -0.156, -0.0807, 0.166, 0.2, -0.0355, 0.397, 0.0435, -0.255,
  ]
  weights[15]: [
    -0.0115, -0.346, 0.0815, 0.354, -0.277, 0.0694, 0.0964, 0.347,
    0.0979, 0.0696, 0.215, -0.322, 0.0262, 0.037, -0.475, -0.0851,
    -0.315, -0.179, 0.423, -0.00166, 0.103, 0.329, -0.292, 0.31,
    0.215, 0.152, -0.224, -0.208, 0.192, -0.32, -0.243, 0.233,
  ]
  weights[16]: [
    -0.243, 0.144, -0.0341, -0.222, 0.159, -0.138, -0.287, -0.138,
    -0.202, -0.231, 0.0247, 0.0491, 0.0877, -0.2, 0.409, -0.0611,
    0.291, 0.024, -0.159, -0.0712, -0.166, -0.0476, -0.0417, -0.206,
    -0.0947, -0.138, -0.159, 0.252, -0.265, 0.349, 0.147, -0.139,
  ]
  weights[17]: [
    0.282, 0.149, 0.246, -0.135, 0.381, 0.51, 0.044, 0.154,
    -0.246, -0.108, -0.084, -0.316, -0.054, -0.0973, -0.162, -0.321,
    0.124, 0.36, -0.0198, -0.241, 0.0975, 0.215, 0.0658, -0.182,
    0.214, -0.0734, -0.011, 0.104, -0.00012, 0.0188, -0.138, 0.0171,
  ]
  weights[18]: [
    0.0559, 0.0752, 0.0397, 0.105, -0.167, 0.00941, 0.212, 0.00534,
    0.11, -0.00892, -0.167, -0.18, 0.257, 0.273, 0.264, -0.0835,
    0.146, -0.175, 0.258, 0.0126, 0.199, 0.356, 0.0724, 0.284,
    0.192, 0.191, -0.174, -0.0714, 0.345, -0.132, -0.161, -0.0753,
  ]
  weights[19]: [
    0.0426, 0.102, 0.293, 0.0477, -0.274, -0.121, 0.138, 0.173,
    -0.0888, -0.00978, -0.0339, -0.282, 0.142, 0.46, -0.166, -0.22,
    -0.404, -0.0387, 0.357, -0.103, 0.044, 0.0241, -0.0141, 0.445,
    -0.0907, 0.273, 0.0348, 0.0697, 0.0337, 0.00914, -0.264, 0.0296,
  ]
  weights[20]: [
    0.11, -0.052, 0.243, -0.214, 0.224, 0.233, -0.0256, 0.365,
    -0.327, -0.0226, -0.235, -0.137, -0.0887, -0.0739, -0.242, -0.0543,
    -0.231, 0.178, 0.209, -0.342, 0.0794, 0.363, 0.307, -0.0109,
    0.0287, 0.0885, 0.0122, 0.182, 0.0174, -0.147, -0.353, 0.356,
  ]
  weights[21]: [
    -0.267, 0.294, -0.335, -0.0486, 0.144, 0.0111, -0.157, 0.044,
    0.0912, -0.00142, 0.0396, 0.106, 0.0288, -0.258, 0.113, -0.132,
    0.19, 0.103, -0.219, 0.0107, 0.0484, 0.0471, -0.000329, -0.278,
    0.0695, 0.054, -0.0621, 0.0928, -0.19, 0.15, -0.0248, -0.273,
  ]
  weights[22]: [
    0.0375, -0.0689, -0.0546, -0.233, -0.302, -0.341, -0.0773, 0.0692,
    -0.23, -0.26, -0.188, 0.307, 0.112, 0.394, 0.235, -0.0937,
    0.00121, 0.15, -0.00185, 0.0687, -0.266, -0.062, -0.0239, 0.0268,
    -0.0687, -0.0335, -0.202, -0.243, -0.0079, 0.304, -0.15, -0.000316,
  ]
  weights[23]: [
    -0.115, 0.114, -0.101, -0.198, -0.171, 0.0846, -0.289, -0.179,
    -0.175, 0.0225, -0.148, -0.04, 0.299, 0.12, 0.0732, -0.22,
    -0.0537, 0.119, 0.0733, -0.0188, -0.0367, 0.0251, -0.208, 0.198,
    -0.123, 0.1, -0.259, -0.153, 0.16, -0.107, -0.0491, 0.0638,
  ]
  weights[24]: [
    -0.324, 0.102, 0.00438, -0.128, -0.0202, 0.063, -0.0742, -0.219,
    -0.0106, -0.0146, -0.157, 0.268, 0.245, -0.16, 0.286, -0.0764,
    0.327, 0.179, -0.0544, -0.0423, -0.234, -0.132, 0.134, 0.169,
    0.0573, -0.0387, -0.0372, 0.221, -0.295, 0.238, -0.00233, 0.0277,
  ]
  weights[25]: [
    -0.191, -0.138, 0.165, 0.0483, -0.0637, -0.115, -0.0494, -0.177,
    -0.137, -0.0574, -0.167, 0.102, 0.271, 0.0753, -0.0573, -0.137,
    0.105, 0.0797, 0.299, -0.14, 0.118, 0.188, -0.302, -0.0399,
    0.105, 0.293, -0.104, -0.257, 0.152, -0.242, 0.00626, 0.257,
  ]
  weights[26]: [
    -0.174, -0.0706, -0.171, 0.15, -0.176, -0.202, 0.0806, 0.0252,
    0.133, 0.145, 0.0218, -0.0683, -0.316, -0.143, -0.143, 0.11,
    -0.0556, -0.0747, -0.0745, 0.294, -0.163, 0.0471, -0.0777, 0.0997,
    -0.0357, 0.0633, 0.0952, -0.219, -0.00668, 0.0549, 0.0292, -0.309,
  ]
  weights[27]: [
    -0.472, -0.087, -0.124, 0.185, -0.0762, -0.399, -0.00315, -0.15,
    0.508, 0.239, 0.435, -0.0857, -0.0765, -0.171, -0.315, 0.244,
    -0.268, -0.151, 0.0528, 0.422, -0.0545, -0.0891, -0.135, 0.252,
    -0.231, -0.209, 0.269, -0.152, -0.14, -0.111, 0.122, -0.206,
  ]
  weights[28]: [
    0.0234, 0.153, -0.351, 0.119, 0.0824, 0.0745, -0.182, -0.3,
    -0.186, -0.0991, 0.104, 0.522, -0.425, -0.568, 0.287, 0.256,
    0.293, -0.302, -0.0981, 0.0755, -0.293, -0.171, 0.395, -0.256,
    -0.216, -0.0947, 0.312, 0.131, -0.119, 0.23, 0.14, -0.294,
  ]
  weights[29]: [
    -0.196, -0.193, -0.0886, 0.205, -0.268, -0.278, -0.0523, -0.11,
    0.318, 0.399, 0.355, -0.192, -0.304, -0.0223, -0.342, 0.0444,
    -0.0715, 0.121, -0.249, 0.278, -0.257, -0.181, -0.167, 0.144,
    -0.028, 0.00659, 0.0853, -0.266, -0.0749, -0.251, 0.122, 0.0113,
  ]
  weights[30]: [
    -0.35, 0.127, 0.00866, 0.0364, -0.106, -0.336, -0.154, -0.0926,
    -0.233, -0.175, -0.319, -0.00318, 0.234, 0.299, 0.145, -0.133,
    -0.0309, -0.257, 0.217, -0.268, -0.00102, 0.331, -0.0932, 0.344,
    0.118, 0.388, -0.217, -0.0541, 0.323, -0.151, -0.0752, 0.207,
  ]
  weights[31]: [
    0.0399, 0.0519, -0.13, -0.329, 0.118, -0.2, -0.283, 0.126,
    -0.309, 0.0216, -0.162, 0.304, 0.0348, 0.00694, -0.0692, -0.0948,
    -0.0475, -0.147, 0.198, -0.00717, 0.00223, -0.0866, -0.171, 0.255,
    -0.219, 0.116, -0.092, -0.15, -0.167, 0.398, 0.186, -0.161,
  ]
  biases: [
    -0.169, 0.172, 0.218, -0.094, 0.182, 0.236, 0.021, 0.137,
    -0.029, -0.0812, 0.191, 0.28, -0.0969, -0.0608, 0.087, 0.207,
    0.0286, 0.262, -0.09, -0.139, 0.149, -0.0239, -0.209, -0.149,
    -0.103, 0.0233, 0.136, 0.0477, 0.177, 0.0829, 0.132, -0.11,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.493, 0.138, 0.0499, 0.451, 0.296, 0.0344, 0.438, 0.102,
    0.333, 0.458, 0.0524, 0.0214, 0.447, 0.424, 0.372, 0.174,
    0.506, 0.0349, 0.491, 0.445, 0.0667, 0.261, 0.565, 0.5,
    0.52, 0.381, 0.0322, 0.0458, 0.171, 0.191, 0.434, 0.467,
  ]
layer: BatchNormalization
  weights: [
    0.556, 0.391, 0.388, 0.37, 0.534, 0.356, 0.436, 0.502,
    0.67, 0.455, 0.454, 0.423, 0.671, 0.767, 0.38, 0.453,
    0.461, 0.383, 0.573, 0.503, 0.407, 0.626, 1.85, 0.954,
    0.633, 0.576, 0.636, 0.321, 0.395, 0.404, 0.443, 1.15,
  ]
  biases: [
    -0.839, -0.364, -0.75, -0.659, -0.687, -0.369, -0.727, -0.574,
    -0.777, -0.693, -0.756, -0.537, -0.687, -0.619, -0.29, -0.626,
    -0.795, -0.232, -0.617, -0.747, -0.631, -0.732, 0.631, -0.337,
    -0.454, -0.775, -0.396, -0.429, -0.654, -0.438, -0.102, -0.181,
  ]
layer: FullyConnected
  weights[0]: [
    -0.323, -0.294, -0.62, 0.497, 0.0343, -0.366, 0.00951, -0.129,
    0.0431, 0.433, -0.507, -0.334, 0.0463, 0.368, -0.344, 0.0968,
    -0.142, -0.152, 0.409, 0.488, -0.43, -0.103, 0.434, 0.449,
    0.0724, 0.437, -0.295, 0.0619, -0.277, -0.0445, 0.224, 0.228,
  ]
  weights[1]: [
    -0.277, 0.406, 0.0628, 0.0486, 0.503, 0.271, -0.348, 0.459,
    0.0738, 0.0823, 0.095, -0.112, 0.11, 0.0139, -0.45, 0.414,
    -0.563, 0.328, -0.0538, 0.0792, 0.471, -0.341, -0.526, -0.12,
    -0.364, 0.14, 0.331, 0.516, -0.247, 0.239, 0.222, -0.428,
  ]
  weights[2]: [
    0.64, 0.369, 0.282, -0.284, -0.0218, 0.388, -0.404, 0.353,
    0.459, -0.178, 0.296, -0.503, 0.542, -0.163, -0.27, -0.174,
    -0.334, 0.266, -0.357, -0.202, 0.111, -0.189, -0.274, -0.152,
    -0.344, -0.352, 0.364, 0.336, -0.19, 0.515, -0.385, -0.216,
  ]
  biases: [
    -0.272, 0.283, -0.929,
  ]
layer: Activation
  function: Sigmoid
