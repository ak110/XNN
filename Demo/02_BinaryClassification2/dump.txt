layer: InputScaling
  scale: [
    1, 1,
  ]
layer: FullyConnected
  weights[0]: [
    1.64, -1.75,
  ]
  weights[1]: [
    -0.661, -1.53,
  ]
  weights[2]: [
    -1.25, 0.582,
  ]
  weights[3]: [
    -0.0796, -0.346,
  ]
  weights[4]: [
    0.651, -1.26,
  ]
  weights[5]: [
    0.27, 0.182,
  ]
  weights[6]: [
    1.55, 0.123,
  ]
  weights[7]: [
    -0.595, 0.786,
  ]
  weights[8]: [
    -1.36, -1.23,
  ]
  weights[9]: [
    -0.635, 1.59,
  ]
  weights[10]: [
    -1.24, -1.01,
  ]
  weights[11]: [
    -0.633, 0.918,
  ]
  weights[12]: [
    1.4, 1.38,
  ]
  weights[13]: [
    -1.7, -0.432,
  ]
  weights[14]: [
    -0.735, 0.688,
  ]
  weights[15]: [
    0.386, 1.84,
  ]
  weights[16]: [
    -0.426, -1.01,
  ]
  weights[17]: [
    0.139, -1.17,
  ]
  weights[18]: [
    -1.19, 0.771,
  ]
  weights[19]: [
    0.753, -1.25,
  ]
  weights[20]: [
    1.69, -1.98,
  ]
  weights[21]: [
    -0.715, 1.35,
  ]
  weights[22]: [
    0.155, -1.15,
  ]
  weights[23]: [
    -1.08, -0.124,
  ]
  weights[24]: [
    -0.636, -0.689,
  ]
  weights[25]: [
    1.63, 0.649,
  ]
  weights[26]: [
    -0.487, -0.39,
  ]
  weights[27]: [
    1.02, -1.2,
  ]
  weights[28]: [
    0.354, -1.69,
  ]
  weights[29]: [
    0.701, -0.755,
  ]
  weights[30]: [
    -0.0481, -1.33,
  ]
  weights[31]: [
    -1.02, 0.66,
  ]
  biases: [
    -2.85e-06, -0.481, 0.667, 0.44, 0.311, -0.172, 0.282, 0.14,
    0.333, 0.265, 0.713, 0.444, 0.169, 0.414, -0.000836, 0.28,
    -0.245, -0.172, 0.223, 0.206, 0.000391, -0.128, -0.245, -0.145,
    0.497, 0.0723, -1.15, 0.449, 0.514, 0.0543, -0.16, 0.357,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.31, 0.371, 0.237, 0.232, 0.29, 0.402, 0.25, 0.257,
    0.364, 0.355, 0.29, 0.237, 0.242, 0.324, 0.284, 0.22,
    0.317, 0.326, 0.248, 0.274, 0.349, 0.355, 0.341, 0.366,
    0.257, 0.24, 0.42, 0.233, 0.316, 0.364, 0.287, 0.287,
  ]
layer: BatchNormalization
  weights: [
    1.48, 4.03, 2.38, 5.73, 2.54, 9.47, 1.53, 2.78,
    2.98, 1.57, 2.74, 2.15, 1.28, 3.11, 3.01, 1.24,
    6.8, 6.11, 2.34, 2.49, 1.4, 1.89, 5.58, 6.51,
    4.87, 1.34, 7.58, 1.9, 2.32, 3.24, 5.29, 2.56,
  ]
  biases: [
    -0.465, 2.24, -0.959, -1.23, -0.597, -0.823, -1.67, -0.877,
    0.818, -1.26, -0.0733, -1.25, -1.96, 0.375, -0.375, -1.67,
    2.01, 1.32, -0.5, -0.489, -0.432, -0.723, 1.35, 1.68,
    -0.223, -1.61, 4.91, -0.888, -0.412, -0.518, 1.25, -0.761,
  ]
layer: FullyConnected
  weights[0]: [
    -0.295, -0.183, 0.184, 0.131, -0.284, 0.0538, -0.223, 0.35,
    -0.0666, 0.378, 0.144, 0.194, -0.231, -0.00335, 0.312, 0.11,
    -0.092, -0.349, 0.351, -0.334, 0.0194, 0.278, -0.174, 0.228,
    -0.0175, -0.0782, 0.033, -0.0667, 0.0252, -0.143, 0.0619, 0.388,
  ]
  weights[1]: [
    -0.195, 0.0303, -0.0692, -0.0959, 0.0104, 0.062, -0.231, -0.201,
    0.132, 0.0475, 0.203, 0.119, 0.108, 0.114, 0.162, 0.175,
    0.22, 0.0837, 0.0599, 0.155, -0.0527, -0.22, 0.17, 0.197,
    -0.0478, 0.0923, 0.0844, -0.187, 0.107, 0.116, 0.204, 0.03,
  ]
  weights[2]: [
    -0.171, -0.255, -0.0787, -0.29, -0.232, -0.0673, -0.218, -0.0444,
    -0.371, 0.193, -0.303, 0.318, 0.363, -0.183, 0.21, 0.233,
    -0.151, -0.0531, -0.0212, -0.0112, -0.0105, 0.296, -0.309, 0.081,
    -0.416, -0.0733, -0.0557, -0.168, -0.244, -0.0309, 0.0236, -0.0543,
  ]
  weights[3]: [
    0.353, 0.184, -0.0419, 0.121, 0.42, 0.231, 0.166, -0.068,
    -0.0358, -0.254, -0.306, -0.0594, 0.0138, -0.0207, -0.293, -0.00377,
    0.138, 0.333, -0.0501, 0.136, 0.244, -0.162, 0.286, -0.376,
    -0.281, 0.055, -0.0919, 0.286, 0.472, 0.367, 0.253, -0.35,
  ]
  weights[4]: [
    -0.269, -0.124, 0.371, 0.19, -0.138, -0.149, -0.275, 0.273,
    0.243, 0.0836, 0.153, 0.259, -0.143, 0.0876, 0.145, 0.136,
    0.0354, -0.145, 0.335, -0.293, -0.236, -0.123, -0.271, 0.0314,
    0.0665, -0.0822, -0.212, 0.0599, 0.0198, -0.239, -0.159, -0.00669,
  ]
  weights[5]: [
    -0.346, -0.199, 0.248, 0.196, -0.0356, -0.226, -0.19, 0.0966,
    0.242, 0.365, -0.0727, 0.181, 0.00339, 0.182, -0.0207, 0.00962,
    -0.102, -0.314, 0.345, -0.159, -0.146, -0.000529, -0.189, -0.0478,
    -0.113, -0.0804, -0.0459, -0.09, -0.0855, -0.212, 0.0577, 0.382,
  ]
  weights[6]: [
    0.215, -0.0677, 0.00854, -0.158, 0.0371, 0.0536, 0.0437, -0.155,
    -0.203, -0.00162, -0.11, 0.0256, 0.136, -0.355, 0.0289, -0.107,
    0.0114, -0.0647, -0.0342, 0.207, -0.0639, -0.234, 0.17, -0.0321,
    0.125, 0.123, -0.213, 0.203, 0.000851, 0.23, 0.00144, -0.323,
  ]
  weights[7]: [
    -0.314, 0.0381, 0.167, 0.096, -0.294, 0.0558, -0.285, -0.0052,
    -0.0339, 0.345, 0.0586, 0.144, -0.0386, -0.104, 0.0177, 0.297,
    -0.0192, -0.341, 0.0795, -0.0929, -0.335, 0.0611, -0.284, 0.102,
    -0.0581, 0.0367, -0.245, -0.148, -0.345, -0.304, -0.0611, -0.0568,
  ]
  weights[8]: [
    -0.0179, 0.0424, -0.162, -0.0376, 0.223, -0.142, 0.163, -0.27,
    0.00372, -0.135, -0.137, -0.292, 0.0662, -0.17, -0.138, -0.09,
    0.286, 0.237, -0.265, 0.174, 0.000758, -0.312, 0.186, -0.302,
    -0.167, 0.26, -0.0173, 0.369, 0.291, 0.389, -0.0593, -0.34,
  ]
  weights[9]: [
    0.33, -0.158, -0.254, 0.153, 0.0907, -0.0554, 0.319, -0.0625,
    -0.0784, -0.159, -0.171, -0.0806, 0.196, -0.104, -0.167, 0.0756,
    0.167, 0.272, -0.000656, 0.238, 0.205, -0.142, 0.146, -0.398,
    0.0657, 0.18, -0.202, 0.0496, 0.085, 0.308, 0.0145, 0.0729,
  ]
  weights[10]: [
    0.112, 0.209, -0.296, 0.162, -0.0472, -0.158, 0.201, 0.137,
    -0.0287, -0.202, 0.203, 0.0783, -0.132, -0.0249, -0.161, 0.102,
    0.069, 0.0678, 0.046, 0.146, 0.274, -0.031, -0.0286, -0.268,
    -0.166, -0.0162, -0.0817, 0.268, 0.125, 0.229, -0.126, -0.0967,
  ]
  weights[11]: [
    -0.0536, -1.03e-05, 0.179, 0.0784, 0.0429, -0.0524, 0.0264, -0.0221,
    0.339, -0.0648, 0.261, -0.00626, -0.0295, -0.0945, -0.123, 0.00985,
    0.0846, 0.117, 0.0255, -0.00206, 0.0221, 0.157, 0.0478, 0.106,
    0.355, -0.281, 0.0795, 0.141, -0.127, 0.0259, 0.159, -0.199,
  ]
  weights[12]: [
    -0.0871, -0.337, 0.0363, -0.218, -0.0993, -0.034, 0.165, 0.0234,
    -0.0825, -0.0355, -0.109, -0.153, 0.332, 0.0816, -0.328, 0.189,
    0.0357, -0.259, -0.211, -0.111, -0.0316, -0.0836, -0.207, -0.317,
    0.0673, 0.285, 0.0324, -0.162, -0.0674, -0.222, -0.174, -0.311,
  ]
  weights[13]: [
    0.076, -0.0859, -0.352, -0.328, -0.111, 0.377, -0.0365, 0.142,
    -0.301, 0.186, -0.297, -0.218, 0.227, -0.142, -0.255, 0.245,
    -0.374, -0.26, -0.0319, -0.13, 0.0277, -0.0895, -0.193, 0.0108,
    -0.18, 0.327, -0.101, -0.0752, -0.042, -0.0425, -0.121, -0.204,
  ]
  weights[14]: [
    -0.191, 0.0504, -0.157, -0.107, -0.00194, 0.0139, -0.0162, -0.00145,
    0.127, -0.169, 0.284, -0.23, -0.28, 0.0798, -0.183, -0.18,
    -0.017, 0.106, -0.0821, -0.192, -0.188, 0.0254, 0.0664, 0.211,
    0.0897, -0.0341, 0.181, -0.149, 0.175, 0.0693, -0.00852, -0.113,
  ]
  weights[15]: [
    0.186, 0.166, -0.122, 0.27, 0.338, -0.267, 0.102, 0.0261,
    -0.123, -0.224, -0.0373, -0.189, -0.193, 0.0443, -0.102, 0.011,
    0.106, 0.244, -0.254, 0.125, 0.26, -0.294, 0.00155, -0.269,
    0.117, 0.0369, -0.228, 0.287, 0.206, 0.308, 0.207, -0.0323,
  ]
  weights[16]: [
    -0.268, 0.157, 0.301, 0.295, -0.00669, -0.133, -0.357, -0.183,
    0.296, 0.0729, 0.306, 0.107, -0.111, 0.334, -0.115, -0.0665,
    0.134, 0.311, -0.0223, -0.134, -0.179, -0.228, 0.00478, 0.338,
    0.333, -0.239, 0.000875, 0.105, 0.109, -0.255, 0.0781, 0.031,
  ]
  weights[17]: [
    -0.0523, -0.185, 0.0141, 0.146, -0.0821, -0.103, -0.0525, -0.0546,
    -0.134, 0.239, -0.0326, -0.0106, 0.148, 0.0811, -0.00342, 0.255,
    0.163, 0.132, 0.234, -0.247, -0.117, 0.181, -0.252, 0.216,
    -0.00022, -0.0197, 0.177, -0.0839, 0.0409, 0.0782, 0.0736, 0.068,
  ]
  weights[18]: [
    0.0876, -0.213, -0.254, -0.223, 0.0451, 0.372, 0.251, -0.135,
    -0.00824, 0.0862, -0.145, 0.114, 0.375, -0.219, 0.117, 0.238,
    0.0495, 0.0298, -0.0864, -0.0834, -0.106, 0.235, 0.143, -0.0397,
    -0.107, 0.105, 0.0685, 0.038, -0.103, -0.229, 0.0548, -0.134,
  ]
  weights[19]: [
    0.0537, 0.181, -0.234, 0.214, 0.0922, -0.169, 0.114, -0.205,
    -0.154, 0.0485, -0.2, 0.0873, -0.203, -0.084, 0.0844, 0.05,
    0.0815, 0.233, 0.066, 0.133, 0.182, -0.134, 0.194, -0.155,
    -0.097, 0.165, 0.0399, 0.27, -0.0652, -0.103, 0.0617, 0.0487,
  ]
  weights[20]: [
    -0.196, -0.309, 0.312, -0.271, -0.181, -0.1, 0.017, 0.0267,
    -0.164, 0.227, -0.256, 0.196, 0.0739, -0.208, -0.0611, 0.188,
    -0.328, 0.0397, 0.327, 0.107, -0.313, -0.0186, -0.00679, -0.122,
    0.0465, 0.161, -0.213, 0.00393, -0.31, -0.317, 0.0368, 0.318,
  ]
  weights[21]: [
    -0.353, -0.329, -0.0602, 0.0076, -0.178, 0.272, -0.0612, 0.0834,
    -0.228, 0.169, -0.294, 0.113, 0.245, -0.325, 0.304, 0.0616,
    -0.237, -0.0795, 0.0266, -0.327, -0.207, 0.316, -0.145, 0.0464,
    -0.173, -0.00101, -0.00132, 0.0318, 0.0836, -0.138, -0.0215, -0.101,
  ]
  weights[22]: [
    -0.2, 0.253, 0.16, 0.251, -0.0283, -0.288, 0.0374, 0.126,
    0.162, 0.0928, -0.068, 0.258, -0.0312, 0.283, 0.135, 0.168,
    0.14, 0.133, 0.129, -0.214, -0.269, -0.112, -0.127, -0.0116,
    0.161, -0.0384, -0.0728, -0.116, -0.18, -0.124, -0.0813, 0.19,
  ]
  weights[23]: [
    0.104, -0.307, -0.306, -0.334, 0.0561, 0.0967, 0.302, -0.126,
    -0.416, 0.078, -0.0843, -0.22, 0.199, -0.282, 0.0937, 0.318,
    -0.133, -0.31, -0.295, -0.000974, 0.000598, 0.151, -0.196, -0.205,
    -0.27, 0.204, 0.0673, -0.155, -0.125, -0.258, 0.0612, -0.0604,
  ]
  weights[24]: [
    -0.218, -0.0251, 0.197, 0.0499, -0.111, 0.0875, 0.0134, 0.121,
    0.0419, 0.0671, 0.082, -0.00452, -0.0659, -0.0732, -0.151, 0.294,
    -0.292, -0.224, -0.0427, 0.111, 0.0882, 0.159, 0.0568, 0.123,
    -0.3, 0.0903, -0.0597, 0.065, -0.137, -0.142, -0.277, 0.0394,
  ]
  weights[25]: [
    -0.281, -0.028, -0.124, 0.158, 0.0596, -0.0638, 0.281, -0.0212,
    -0.226, -0.15, 0.0927, -0.138, 0.133, -0.118, -0.0685, 0.206,
    -0.108, 0.147, 0.114, -0.0426, -0.305, -0.101, -0.218, 0.0318,
    0.0678, 0.236, -0.199, -0.106, -0.126, -0.104, -0.213, -0.266,
  ]
  weights[26]: [
    -0.0841, 0.161, 0.072, 0.0437, 0.159, -0.111, 0.164, -0.321,
    -0.0887, 0.0022, 0.0291, -0.0093, -0.0997, -0.126, -0.222, -0.163,
    0.0555, 0.237, 0.0498, 0.056, 0.0583, -0.261, -0.054, -0.101,
    0.218, 0.000197, -0.111, 0.229, 0.349, -0.0873, 0.167, -0.187,
  ]
  weights[27]: [
    0.0989, -0.0255, 0.11, -0.069, -0.0968, -0.159, -0.0252, 0.0777,
    0.0181, -0.127, 0.145, 0.00734, 0.0773, 0.285, 0.117, 0.076,
    -0.0233, -0.19, -0.0313, 0.0443, -0.169, -0.119, -0.14, 0.109,
    0.217, -0.293, 0.00585, -0.11, 0.00972, 0.11, 0.141, 0.291,
  ]
  weights[28]: [
    0.0419, -0.331, -0.0525, -0.36, -0.211, 0.23, 0.249, -0.0868,
    -0.138, 0.161, 0.0109, 0.167, 0.256, -0.232, 0.221, 0.33,
    -0.304, -0.238, -0.183, -0.159, -0.207, 0.119, -0.365, -0.126,
    -0.351, 0.259, -0.00754, -0.213, -0.00597, -0.15, -0.0529, -0.0712,
  ]
  weights[29]: [
    -0.198, 0.339, 0.0992, -0.0653, 0.0648, -0.256, -0.00323, -0.244,
    0.401, 0.122, 0.408, 0.0161, -0.174, 0.367, -0.00509, 0.0142,
    0.24, 0.175, 0.0977, 0.0199, -0.0988, 0.0456, -0.0545, 0.24,
    0.217, -0.148, 0.106, 0.0844, -0.107, 0.0349, 0.227, -0.212,
  ]
  weights[30]: [
    -0.0187, 0.228, 0.0215, 0.251, 0.24, -0.0401, -0.0851, -0.329,
    0.209, -0.0242, 0.0848, -0.304, -0.34, 0.0159, -0.243, -0.121,
    0.312, 0.335, -0.293, 0.316, 0.173, -0.332, 0.0362, 0.0925,
    0.0609, -0.016, -0.0265, -0.0418, 0.221, 0.0298, 0.193, -0.342,
  ]
  weights[31]: [
    -0.272, -0.154, 0.24, -0.077, -0.158, 0.229, 0.131, -0.0573,
    -0.014, 0.257, -0.333, 0.298, 0.0348, -0.101, -0.082, 0.329,
    -0.104, -0.2, 0.158, -0.294, 0.042, 0.172, -0.159, 0.12,
    -0.015, 0.288, 0.131, 0.0036, -0.293, -0.342, -0.0843, 0.141,
  ]
  biases: [
    -0.0254, -0.0196, 0.14, 0.16, 0.17, 0.159, 0.117, 0.0909,
    0.168, 0.0768, 0.0409, -0.0582, 0.000525, -0.078, -0.0375, 0.118,
    0.121, -0.0848, 0.0546, -0.0418, 0.0981, 0.129, 0.0807, -0.0304,
    0.0951, 0.082, 0.132, 0.0771, 0.116, -0.135, 0.115, 0.118,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.343, 0.201, 0.383, 0.123, 0.193, 0.225, 0.135, 0.236,
    0.177, 0.169, 0.14, 0.406, 0.335, 0.431, 0.373, 0.171,
    0.366, 0.312, 0.286, 0.329, 0.235, 0.249, 0.35, 0.397,
    0.201, 0.253, 0.187, 0.243, 0.372, 0.431, 0.316, 0.301,
  ]
layer: BatchNormalization
  weights: [
    0.395, 1.33, 0.445, 0.35, 0.56, 0.506, 0.74, 0.473,
    0.422, 0.509, 0.881, 0.914, 0.612, 0.474, 0.922, 0.448,
    0.427, 1.07, 0.653, 0.874, 0.498, 0.506, 0.711, 0.478,
    0.835, 0.879, 0.646, 1.04, 0.41, 0.554, 0.421, 0.471,
  ]
  biases: [
    -0.604, -0.379, -0.442, -0.396, -0.58, -0.408, -0.609, -0.624,
    -0.361, -0.541, -0.337, -0.59, -0.736, -0.609, -0.612, -0.563,
    -0.419, -0.53, -0.428, -0.569, -0.695, -0.603, -0.609, -0.557,
    -0.51, -0.459, -0.524, -0.523, -0.523, -0.608, -0.582, -0.572,
  ]
layer: FullyConnected
  weights[0]: [
    0.394, -0.0646, -0.109, 0.378, 0.523, 0.137, -0.0331, 0.376,
    -0.175, -0.0819, 0.068, -0.416, -0.367, -0.288, -0.0582, 0.0904,
    0.0936, 0.196, -0.57, 0.346, -0.0326, -0.123, 0.173, -0.333,
    0.256, -0.203, -0.0743, 0.0774, 0.0481, -0.094, -0.102, 0.23,
  ]
  weights[1]: [
    0.197, -0.107, 0.296, -0.0309, 0.18, 0.309, 0.0783, 0.383,
    0.0291, -0.384, -0.198, -0.38, -0.275, -0.0458, -0.071, 0.0429,
    0.108, 0.324, -0.286, 0.00678, 0.428, 0.384, 0.27, -0.291,
    0.0445, -0.245, 0.082, 0.24, 0.267, -0.153, -0.0971, 0.104,
  ]
  weights[2]: [
    0.255, 0.0602, 0.0721, -0.226, 0.262, 0.37, -0.115, 0.347,
    -0.135, -0.424, -0.304, 0.0143, -0.279, -0.0549, 0.0385, -0.426,
    0.488, 0.471, -0.439, -0.11, 0.0809, 0.222, 0.46, -0.361,
    0.262, -0.141, -0.124, 0.258, -0.128, 0.278, -0.25, 0.42,
  ]
  weights[3]: [
    -0.211, -0.136, 0.299, 0.114, -0.229, -0.079, -0.0578, -0.0595,
    -0.199, 0.0823, -0.268, -0.00468, 0.301, 0.0795, 0.11, -0.279,
    -0.296, -0.193, 0.306, -0.0882, 0.058, 0.183, -0.143, 0.536,
    0.204, 0.498, -0.044, -0.196, 0.116, -0.354, -0.173, 0.264,
  ]
  weights[4]: [
    0.0853, 0.0535, 0.34, 0.0604, 0.114, -0.023, 0.303, 0.155,
    0.0653, 0.436, 0.379, -0.211, 0.0284, 0.23, -0.402, 0.209,
    -0.153, 0.0949, 0.213, -0.0398, 0.156, 0.332, -0.172, 0.117,
    0.335, -0.236, -0.159, -0.251, 0.174, -0.322, 0.0364, 0.356,
  ]
  weights[5]: [
    -0.576, -0.085, -0.0195, -0.0324, -0.384, -0.311, 0.252, 0.0634,
    0.297, 0.0842, 0.225, 0.165, -0.0789, 0.0816, -0.107, 0.36,
    -0.42, -0.35, -0.0147, 0.166, -0.129, -0.189, -0.464, -0.334,
    -0.305, -0.257, 0.16, -0.212, 0.0484, -0.294, 0.359, -0.0797,
  ]
  weights[6]: [
    -0.304, 0.146, -0.409, -0.347, -0.0079, -0.24, -0.147, -0.226,
    -0.047, -0.321, 0.0351, 0.222, -0.00792, -0.369, 0.395, -0.15,
    0.24, -0.141, 0.113, -0.106, -0.164, -0.412, 0.156, -0.235,
    0.117, 0.271, 0.202, 0.181, -0.141, 0.115, 0.114, -0.444,
  ]
  weights[7]: [
    0.188, -0.171, 0.188, -0.0847, 0.207, 0.436, -0.152, 0.332,
    -0.0284, 0.0407, -0.0741, -0.198, -0.0725, -0.194, -0.256, -0.0834,
    -0.259, 0.213, -0.0815, -0.222, 0.22, 0.00843, 0.0316, -0.276,
    0.0448, 0.0903, -0.105, 0.0274, 0.00356, -0.429, -0.274, 0.145,
  ]
  weights[8]: [
    0.189, -0.0805, 0.347, 0.000794, 0.126, 0.364, 0.134, -0.00429,
    -0.225, 0.161, -0.186, -0.018, -0.0884, -0.209, -0.13, 0.0822,
    0.0571, 0.17, -0.0654, 0.111, 0.205, -0.0924, 0.1, -0.0695,
    0.101, -0.34, -0.289, 0.152, -0.0237, -0.264, -0.0903, 0.158,
  ]
  weights[9]: [
    -0.229, -0.0577, 0.00442, -0.261, 0.0558, -0.247, -0.0792, -0.159,
    -0.0739, 0.107, 0.0465, -0.0688, 0.175, 0.242, -0.189, -0.137,
    -0.447, -0.123, 0.175, 0.00382, 0.227, 0.185, -0.0393, 0.32,
    0.0915, 0.491, -0.0393, -0.232, 0.178, -0.165, -0.131, 0.203,
  ]
  weights[10]: [
    -0.473, 0.184, -0.17, 0.353, 0.0277, -0.224, 0.289, -0.292,
    0.409, 0.207, 0.00976, 0.183, -0.217, 0.067, 0.0112, 0.18,
    0.108, -0.0852, -0.0823, 0.00902, -0.236, -0.125, -0.359, -0.28,
    -0.229, -0.134, 0.132, 0.0189, -0.247, -0.208, 0.365, 0.0119,
  ]
  weights[11]: [
    -0.374, 0.0525, -0.289, 0.0457, 0.1, 0.134, -0.0409, -0.172,
    -0.0953, -0.42, -0.266, 0.383, -0.269, -0.484, 0.179, 0.171,
    0.114, -0.266, -0.29, -0.295, -0.301, -0.414, 0.41, -0.512,
    0.0296, 0.044, 0.244, 0.4, -0.412, 0.2, 0.362, -0.332,
  ]
  weights[12]: [
    0.137, -0.273, -0.089, 0.225, -0.101, 0.04, 0.0925, -0.184,
    0.181, 0.298, 0.374, -0.0873, -0.0452, -0.176, -0.0985, 0.0137,
    -0.236, 0.156, -0.0932, 0.274, 0.116, 0.103, 0.1, -0.143,
    0.0565, -0.143, 0.0445, -0.031, -0.278, -0.217, 0.0557, -0.0839,
  ]
  weights[13]: [
    -0.0188, 0.0951, -0.107, -0.162, -0.0821, -0.105, -0.0719, 0.0817,
    -0.209, -0.155, 0.0202, -0.259, 0.13, 0.305, -0.163, -0.0141,
    -0.226, -0.13, 0.0846, -0.194, -0.127, -0.0868, -0.262, 0.283,
    0.0485, 0.0966, -0.0861, -0.128, -0.0131, 0.0225, 0.0264, 0.209,
  ]
  weights[14]: [
    -0.0842, 0.238, -0.315, -0.0978, 0.0999, -0.0136, -0.269, -0.0771,
    -0.0332, 0.00491, 0.0948, 0.388, 0.0349, -0.256, 0.518, 0.0684,
    0.317, -0.111, -0.124, -0.0316, -0.198, -0.206, 0.247, 0.00308,
    -0.156, -0.0806, 0.166, 0.2, -0.0355, 0.397, 0.0435, -0.255,
  ]
  weights[15]: [
    -0.0114, -0.346, 0.0815, 0.354, -0.278, 0.0694, 0.0965, 0.346,
    0.0979, 0.0695, 0.215, -0.322, 0.0262, 0.037, -0.475, -0.0848,
    -0.315, -0.179, 0.423, -0.00142, 0.103, 0.329, -0.292, 0.31,
    0.215, 0.152, -0.224, -0.208, 0.192, -0.32, -0.243, 0.233,
  ]
  weights[16]: [
    -0.243, 0.144, -0.0341, -0.222, 0.159, -0.138, -0.287, -0.138,
    -0.202, -0.231, 0.0242, 0.0492, 0.0877, -0.2, 0.409, -0.0612,
    0.291, 0.024, -0.159, -0.0712, -0.166, -0.0476, -0.0417, -0.206,
    -0.0947, -0.138, -0.159, 0.252, -0.265, 0.349, 0.147, -0.139,
  ]
  weights[17]: [
    0.282, 0.148, 0.246, -0.135, 0.381, 0.51, 0.0441, 0.154,
    -0.246, -0.108, -0.0838, -0.316, -0.0539, -0.0971, -0.162, -0.321,
    0.124, 0.36, -0.0199, -0.241, 0.0974, 0.215, 0.0659, -0.182,
    0.214, -0.0736, -0.011, 0.104, -4.62e-05, 0.0188, -0.138, 0.0171,
  ]
  weights[18]: [
    0.056, 0.0753, 0.0397, 0.105, -0.167, 0.0095, 0.212, 0.00534,
    0.11, -0.00901, -0.167, -0.18, 0.257, 0.273, 0.264, -0.0835,
    0.147, -0.175, 0.258, 0.0127, 0.199, 0.356, 0.0725, 0.284,
    0.192, 0.191, -0.174, -0.0712, 0.345, -0.132, -0.161, -0.0753,
  ]
  weights[19]: [
    0.0437, 0.102, 0.294, 0.0466, -0.273, -0.12, 0.136, 0.174,
    -0.0898, -0.0112, -0.0348, -0.282, 0.143, 0.46, -0.165, -0.22,
    -0.403, -0.0376, 0.357, -0.105, 0.0447, 0.0244, -0.0122, 0.445,
    -0.0909, 0.272, 0.0346, 0.0706, 0.0339, 0.0105, -0.265, 0.0301,
  ]
  weights[20]: [
    0.11, -0.0521, 0.243, -0.214, 0.224, 0.233, -0.0255, 0.365,
    -0.327, -0.0226, -0.234, -0.137, -0.0887, -0.0737, -0.242, -0.0542,
    -0.231, 0.178, 0.209, -0.342, 0.0794, 0.363, 0.307, -0.0108,
    0.0289, 0.0882, 0.0121, 0.182, 0.0175, -0.147, -0.353, 0.356,
  ]
  weights[21]: [
    -0.267, 0.294, -0.335, -0.0487, 0.144, 0.0112, -0.157, 0.0441,
    0.091, -0.00152, 0.0394, 0.106, 0.0288, -0.258, 0.113, -0.132,
    0.19, 0.103, -0.219, 0.0106, 0.0484, 0.0471, -0.000248, -0.278,
    0.0696, 0.0541, -0.062, 0.0929, -0.19, 0.15, -0.0248, -0.272,
  ]
  weights[22]: [
    0.0378, -0.0692, -0.0548, -0.233, -0.302, -0.341, -0.077, 0.0691,
    -0.23, -0.26, -0.188, 0.307, 0.112, 0.394, 0.235, -0.0939,
    0.00073, 0.15, -0.00191, 0.0693, -0.266, -0.0624, -0.0241, 0.0272,
    -0.0693, -0.0339, -0.202, -0.243, -0.0081, 0.304, -0.15, -0.000448,
  ]
  weights[23]: [
    -0.115, 0.114, -0.101, -0.198, -0.171, 0.0845, -0.289, -0.18,
    -0.175, 0.0224, -0.148, -0.0399, 0.299, 0.12, 0.0734, -0.22,
    -0.0535, 0.118, 0.0733, -0.0188, -0.0368, 0.0251, -0.208, 0.198,
    -0.124, 0.1, -0.259, -0.153, 0.16, -0.107, -0.049, 0.0637,
  ]
  weights[24]: [
    -0.324, 0.102, 0.00439, -0.128, -0.0201, 0.063, -0.0741, -0.219,
    -0.0105, -0.0145, -0.157, 0.268, 0.245, -0.16, 0.286, -0.0765,
    0.327, 0.179, -0.0544, -0.0423, -0.234, -0.132, 0.134, 0.169,
    0.0572, -0.0387, -0.0371, 0.221, -0.295, 0.238, -0.00232, 0.0277,
  ]
  weights[25]: [
    -0.191, -0.138, 0.165, 0.0484, -0.0637, -0.115, -0.0493, -0.177,
    -0.137, -0.0574, -0.167, 0.102, 0.271, 0.0752, -0.0573, -0.137,
    0.105, 0.0794, 0.298, -0.14, 0.118, 0.188, -0.302, -0.0399,
    0.105, 0.293, -0.104, -0.257, 0.152, -0.242, 0.00631, 0.257,
  ]
  weights[26]: [
    -0.174, -0.0706, -0.171, 0.15, -0.176, -0.202, 0.0805, 0.0253,
    0.133, 0.145, 0.0218, -0.0684, -0.316, -0.143, -0.143, 0.11,
    -0.0556, -0.0746, -0.0745, 0.294, -0.163, 0.0471, -0.0776, 0.0996,
    -0.0357, 0.0634, 0.0951, -0.219, -0.00668, 0.0549, 0.0291, -0.309,
  ]
  weights[27]: [
    -0.471, -0.0871, -0.124, 0.185, -0.0761, -0.399, -0.00333, -0.15,
    0.508, 0.239, 0.435, -0.086, -0.0763, -0.171, -0.315, 0.244,
    -0.268, -0.151, 0.0528, 0.422, -0.0544, -0.089, -0.135, 0.252,
    -0.231, -0.209, 0.268, -0.152, -0.14, -0.111, 0.122, -0.206,
  ]
  weights[28]: [
    0.0235, 0.153, -0.351, 0.118, 0.0829, 0.0747, -0.183, -0.3,
    -0.187, -0.0996, 0.104, 0.522, -0.425, -0.568, 0.288, 0.255,
    0.293, -0.301, -0.0981, 0.0749, -0.293, -0.171, 0.395, -0.256,
    -0.216, -0.0945, 0.312, 0.131, -0.119, 0.231, 0.14, -0.294,
  ]
  weights[29]: [
    -0.196, -0.193, -0.0886, 0.205, -0.268, -0.277, -0.0524, -0.109,
    0.318, 0.399, 0.355, -0.192, -0.304, -0.0223, -0.342, 0.0444,
    -0.0715, 0.121, -0.249, 0.278, -0.257, -0.18, -0.167, 0.144,
    -0.0279, 0.00668, 0.0852, -0.266, -0.0749, -0.251, 0.122, 0.0114,
  ]
  weights[30]: [
    -0.35, 0.127, 0.00855, 0.0364, -0.106, -0.336, -0.154, -0.0927,
    -0.233, -0.175, -0.319, -0.00286, 0.233, 0.299, 0.146, -0.133,
    -0.0305, -0.258, 0.217, -0.268, -0.00107, 0.33, -0.0931, 0.344,
    0.118, 0.388, -0.217, -0.0539, 0.323, -0.151, -0.075, 0.207,
  ]
  weights[31]: [
    0.04, 0.0519, -0.13, -0.329, 0.118, -0.2, -0.283, 0.127,
    -0.309, 0.0217, -0.162, 0.304, 0.0347, 0.00686, -0.0693, -0.0947,
    -0.0474, -0.147, 0.198, -0.00713, 0.00236, -0.0866, -0.171, 0.255,
    -0.219, 0.116, -0.0919, -0.15, -0.167, 0.398, 0.186, -0.161,
  ]
  biases: [
    -0.169, 0.172, 0.218, -0.094, 0.182, 0.236, 0.0208, 0.138,
    -0.0291, -0.0812, 0.191, 0.28, -0.0969, -0.0608, 0.0869, 0.208,
    0.0285, 0.262, -0.09, -0.139, 0.149, -0.0239, -0.209, -0.149,
    -0.103, 0.0233, 0.136, 0.0477, 0.177, 0.0828, 0.132, -0.11,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.494, 0.138, 0.0501, 0.451, 0.297, 0.0345, 0.438, 0.102,
    0.334, 0.458, 0.0526, 0.0215, 0.447, 0.424, 0.372, 0.174,
    0.506, 0.0349, 0.491, 0.446, 0.0667, 0.261, 0.566, 0.5,
    0.52, 0.381, 0.0323, 0.0461, 0.172, 0.192, 0.435, 0.467,
  ]
layer: BatchNormalization
  weights: [
    0.557, 0.391, 0.388, 0.37, 0.534, 0.356, 0.436, 0.502,
    0.671, 0.455, 0.454, 0.422, 0.671, 0.767, 0.38, 0.453,
    0.461, 0.383, 0.573, 0.504, 0.407, 0.626, 1.85, 0.954,
    0.633, 0.576, 0.636, 0.321, 0.395, 0.404, 0.443, 1.15,
  ]
  biases: [
    -0.839, -0.364, -0.75, -0.658, -0.687, -0.369, -0.727, -0.574,
    -0.776, -0.693, -0.756, -0.536, -0.687, -0.619, -0.291, -0.626,
    -0.794, -0.232, -0.616, -0.746, -0.631, -0.732, 0.64, -0.336,
    -0.454, -0.775, -0.396, -0.429, -0.653, -0.437, -0.102, -0.181,
  ]
layer: FullyConnected
  weights[0]: [
    -0.323, -0.294, -0.62, 0.497, 0.0342, -0.366, 0.00948, -0.129,
    0.043, 0.433, -0.507, -0.334, 0.0465, 0.368, -0.344, 0.0968,
    -0.142, -0.152, 0.409, 0.488, -0.43, -0.103, 0.435, 0.449,
    0.0722, 0.437, -0.295, 0.0621, -0.277, -0.0444, 0.224, 0.228,
  ]
  weights[1]: [
    -0.278, 0.406, 0.0626, 0.0487, 0.503, 0.271, -0.348, 0.459,
    0.0738, 0.0825, 0.0947, -0.112, 0.11, 0.014, -0.45, 0.414,
    -0.563, 0.328, -0.0537, 0.0787, 0.471, -0.341, -0.525, -0.12,
    -0.364, 0.141, 0.331, 0.516, -0.247, 0.239, 0.222, -0.428,
  ]
  weights[2]: [
    0.64, 0.369, 0.282, -0.284, -0.0213, 0.387, -0.404, 0.353,
    0.459, -0.178, 0.296, -0.503, 0.542, -0.162, -0.27, -0.174,
    -0.334, 0.266, -0.356, -0.202, 0.111, -0.189, -0.275, -0.152,
    -0.344, -0.352, 0.364, 0.336, -0.19, 0.515, -0.385, -0.216,
  ]
  biases: [
    -0.272, 0.283, -0.929,
  ]
layer: Activation
  function: Sigmoid
