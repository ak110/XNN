layer: InputScaling
  scale: [
    0.0526,
  ]
layer: FullyConnected
  weights[0]: [
    -0.731,
  ]
  weights[1]: [
    -1.02,
  ]
  weights[2]: [
    1.19,
  ]
  weights[3]: [
    0.482,
  ]
  weights[4]: [
    0.783,
  ]
  weights[5]: [
    -0.696,
  ]
  weights[6]: [
    -0.196,
  ]
  weights[7]: [
    0.643,
  ]
  weights[8]: [
    -1.58,
  ]
  weights[9]: [
    1.38,
  ]
  weights[10]: [
    -1.44,
  ]
  weights[11]: [
    -1.2,
  ]
  weights[12]: [
    -1.82,
  ]
  weights[13]: [
    2.27,
  ]
  weights[14]: [
    -0.896,
  ]
  weights[15]: [
    -1.3,
  ]
  weights[16]: [
    -2.03,
  ]
  weights[17]: [
    1.68,
  ]
  weights[18]: [
    1.66,
  ]
  weights[19]: [
    1.45,
  ]
  weights[20]: [
    -1.6,
  ]
  weights[21]: [
    -0.327,
  ]
  weights[22]: [
    -1.37,
  ]
  weights[23]: [
    -1.08,
  ]
  weights[24]: [
    1.07,
  ]
  weights[25]: [
    1.53,
  ]
  weights[26]: [
    -0.914,
  ]
  weights[27]: [
    -1.42,
  ]
  weights[28]: [
    0.94,
  ]
  weights[29]: [
    -1.67,
  ]
  weights[30]: [
    -2,
  ]
  weights[31]: [
    0.421,
  ]
  biases: [
    0.671, 0.817, 0.459, 1.6, 0.219, -0.16, -1.8, 0.391,
    -0.515, 0.531, 0.0273, 0.18, -0.396, 0.491, 0.795, 0.109,
    -0.111, 0.249, -0.336, 0.165, 0.0963, 0.329, 0.189, -2.42,
    0.288, -0.141, -0.261, -0.213, 0.43, -0.0635, 0.136, 0.207,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.239, 0.307, 0.25, 0.231, -0.094, 0.584, 1.07, 0.25,
    0.405, 0.25, 0.288, 0.258, 0.364, 0.25, 0.238, 0.291,
    0.346, 0.25, 0.503, 0.257, 0.263, -0.214, 0.302, 0.842,
    0.25, 0.25, 0.315, 0.327, 0.25, 0.328, 0.303, 0.25,
  ]
layer: BatchNormalization
  weights: [
    12.4, 11.1, 6.5, 15, 10.3, 20.2, 35, 11.7,
    13.2, 4.96, 18.9, 24.7, 12, 3.42, 9.62, 19.8,
    13, 5.61, 5.02, 5.34, 17.7, 20.7, 19.5, 7.18,
    7.51, 4.7, 25.2, 16, 8.49, 14.8, 13, 19.5,
  ]
  biases: [
    -1.5, -0.98, -8.83, -29.4, -8.42, 8.06, 72.1, -10.3,
    9.07, -7.73, 5.85, 4.74, 7.7, -7.57, -1.17, 5.08,
    7.45, -8.59, -4.75, -6.77, 5.29, -1.81, 5.07, 19.3,
    -8.28, -4.88, 7.53, 6.7, -9.64, 6.48, 5.49, -10.3,
  ]
layer: FullyConnected
  weights[0]: [
    0.215, -0.0285, 0.0457, -0.233, -0.282, 0.299, 0.0932, -0.212,
    0.0704, -0.131, 0.0463, 0.0401, 0.314, -0.0759, 0.243, 0.23,
    0.236, -0.329, -0.147, -0.31, 0.249, -0.00866, 0.179, -0.144,
    -0.23, -0.0771, 0.00636, 0.00873, -0.158, 0.342, 0.00993, -0.00136,
  ]
  weights[1]: [
    -0.119, 0.14, -0.0178, 0.283, 0.204, -0.0509, -0.276, -0.0251,
    0.059, 0.0444, -0.0732, -0.246, 0.134, -0.127, 0.195, 0.0472,
    -0.0499, 0.148, 0.0789, 0.0512, -0.0558, 0.108, 0.124, -0.0597,
    0.244, 0.205, -0.197, -0.0658, -0.0265, -0.206, -0.0192, 0.157,
  ]
  weights[2]: [
    -0.245, -0.26, 0.216, 0.182, 0.275, -0.067, 0.146, 0.227,
    0.0127, 0.392, -0.0164, -0.108, -0.136, 0.361, -0.118, -0.204,
    -0.0139, 0.325, 0.0334, 0.314, -0.108, -0.203, -0.078, 0.0755,
    0.374, 0.223, -0.209, -0.255, -0.00618, -0.27, -0.283, 0.0296,
  ]
  weights[3]: [
    -0.272, -0.29, 0.0176, 0.142, 0.0691, 0.0536, 0.171, 0.0433,
    -0.084, 0.252, -0.146, -0.0778, -0.305, 0.285, -0.00832, 0.0651,
    -0.349, 0.251, -0.0251, 0.083, -0.124, -0.106, -0.253, 0.0162,
    0.337, 0.00597, 0.00453, -0.136, 0.306, -0.148, 0.0356, 0.364,
  ]
  weights[4]: [
    0.1, 0.245, 0.0138, -0.0894, -0.248, 0.223, -0.0106, 0.0501,
    -0.0307, 0.114, 0.0657, 0.236, 0.191, -0.138, 0.157, 0.129,
    0.239, -0.307, -0.224, -0.17, 0.0149, 0.138, 0.303, 0.22,
    0.0324, -0.241, -0.0103, -0.0821, 0.0865, 0.215, 0.0411, -0.0993,
  ]
  weights[5]: [
    0.0692, 0.394, 0.0227, -0.0226, -0.0636, 0.248, 0.0737, -0.185,
    0.155, 0.035, 0.102, 0.0154, 0.247, -0.272, 0.0853, -0.0555,
    -0.0423, -0.27, -0.145, -0.0282, -0.066, 0.239, 0.184, 0.0243,
    -0.228, -0.259, -0.0743, -0.0626, -0.0334, 0.311, 0.237, -0.251,
  ]
  weights[6]: [
    -0.203, -0.214, 0.448, 0.299, 0.0995, -0.206, 0.0565, 0.348,
    -0.45, 0.203, -0.352, -0.426, -0.0792, 0.25, -0.152, -0.358,
    -0.316, 0.0995, 0.112, 0.288, -0.253, -0.0541, -0.212, -0.214,
    0.447, 0.459, -0.124, -0.381, 0.39, -0.458, -0.302, 0.337,
  ]
  weights[7]: [
    -0.149, -0.155, -0.00663, 0.17, 0.0661, -0.0453, 0.0954, -0.0477,
    -0.0535, 0.116, -0.191, -0.282, -0.0765, 0.283, -0.249, -0.191,
    -0.0616, 0.284, 0.346, 0.189, -0.324, 0.0366, -0.222, 0.0377,
    0.104, -0.0599, -0.31, -0.0536, 0.206, -0.0228, -0.291, 0.344,
  ]
  weights[8]: [
    -0.318, -0.312, 0.175, 0.289, 0.239, -0.211, -0.0494, 0.0574,
    -0.335, 0.405, -0.197, -0.388, -0.27, 0.275, -0.317, -0.232,
    -0.366, 0.241, 0.187, 0.333, -0.411, -0.0959, -0.397, -0.329,
    0.312, 0.0504, -0.396, -0.29, 0.245, -0.357, -0.158, 0.194,
  ]
  weights[9]: [
    0.389, 0.32, -0.342, 0.0828, -0.44, 0.202, 0.12, -0.377,
    0.377, -0.302, 0.527, 0.439, 0.229, -0.331, 0.191, 0.273,
    0.405, -0.504, -0.51, -0.143, 0.384, 0.302, 0.491, 0.265,
    -0.513, -0.482, 0.541, 0.18, -0.415, 0.513, 0.329, -0.498,
  ]
  weights[10]: [
    0.299, 0.233, -0.0984, -0.132, -0.176, 0.16, 0.183, -0.0509,
    0.0451, -0.0068, 0.305, 0.342, 0.295, -0.00232, 0.237, 0.106,
    0.197, -0.351, 0.0481, -0.0971, -0.0744, -0.0117, 0.16, 0.234,
    -0.165, 0.0735, 0.133, 0.268, -0.333, 0.233, -0.0187, -0.246,
  ]
  weights[11]: [
    0.303, 0.436, -0.194, -0.157, 0.0468, 0.249, -0.0406, -0.102,
    0.0508, 0.0253, 0.171, 0.151, 0.28, -0.112, 0.339, 0.212,
    0.0536, -0.347, -0.331, -0.214, 0.114, 0.212, 0.213, 0.163,
    -0.349, -0.184, 0.125, 0.0641, 0.0291, 0.11, 0.188, -0.0859,
  ]
  weights[12]: [
    0.0197, -0.0257, 0.257, 0.0665, 0.125, -0.0555, 0.0643, -0.11,
    -0.178, 0.162, -0.106, -0.0177, -0.0733, 0.0936, -0.00968, 0.137,
    -0.075, 0.13, 0.263, -0.106, -0.0903, 0.119, -0.258, -0.046,
    0.217, -0.0851, -0.0899, -0.298, 0.255, -0.225, -0.0845, -0.0883,
  ]
  weights[13]: [
    -0.0791, -0.147, 0.251, -0.00998, 0.175, -0.286, 0.128, 0.41,
    -0.405, 0.283, -0.0546, -0.365, -0.331, 0.198, -0.0761, -0.293,
    -0.345, 0.0304, 0.352, 0.37, -0.143, -0.148, -0.145, -0.266,
    0.141, 0.0319, -0.131, -0.0882, 0.0183, -0.367, -0.228, 0.377,
  ]
  weights[14]: [
    -0.274, 0.0141, 0.0819, 0.199, 0.0423, -0.358, -0.0214, 0.19,
    -0.411, 0.265, -0.347, -0.29, -0.105, 0.114, -0.0877, -0.255,
    -0.313, 0.365, 0.174, 0.328, -0.175, -0.14, -0.0674, -0.148,
    0.212, 0.0634, -0.291, -0.2, -0.00779, -0.357, -0.203, 0.264,
  ]
  weights[15]: [
    -0.0553, -0.0981, 0.234, -0.0491, 0.369, -0.329, -0.253, 0.163,
    -0.321, 0.0433, -0.246, -0.117, -0.308, -0.00127, -0.243, -0.0518,
    -0.175, 0.326, 0.185, 0.201, 0.0301, -0.189, -0.0287, 0.0501,
    0.109, 0.0242, -0.115, -0.119, 0.203, -0.00559, 0.036, -0.00728,
  ]
  weights[16]: [
    -0.231, -0.117, 0.189, -0.0108, 0.247, -0.312, -0.186, 0.489,
    -0.311, 0.445, -0.311, -0.173, -0.439, 0.308, -0.101, -0.408,
    -0.426, 0.196, 0.432, 0.261, -0.493, -0.04, -0.232, -0.0155,
    0.427, 0.418, -0.48, -0.294, 0.508, -0.167, -0.341, 0.384,
  ]
  weights[17]: [
    -0.281, -0.303, 0.34, 0.196, 0.314, -0.0635, 0.058, 0.324,
    -0.323, 0.267, -0.21, 0.00185, -0.357, 0.0862, -0.227, -0.329,
    -0.313, 0.38, 0.353, 0.152, -0.23, 0.0183, -0.172, -0.229,
    0.184, 0.199, -0.227, -0.364, 0.175, -0.0203, -0.22, 0.139,
  ]
  weights[18]: [
    -0.11, -0.25, 0.042, 0.222, 0.129, -0.193, 0.104, 0.225,
    -0.251, 0.358, 0.0359, 0.0458, 0.0229, -0.0537, -0.187, -0.0277,
    -0.376, 0.349, 0.207, 0.153, 0.000124, -0.102, -0.0359, 0.0111,
    0.292, 0.143, -0.00358, -0.247, -0.0113, -0.272, -0.0441, 0.438,
  ]
  weights[19]: [
    0.271, 0.023, 0.0497, -0.0294, -0.107, 0.292, 0.291, -0.198,
    0.256, 0.0324, 0.292, 0.229, 0.117, -0.139, 0.0766, 0.344,
    0.334, -0.0256, -0.0835, -0.174, 0.191, 0.0767, 0.117, -0.0819,
    0.0122, -0.193, 0.0918, 0.187, -0.292, 0.254, 0.118, -0.306,
  ]
  weights[20]: [
    0.2, 0.0264, -0.282, 0.0614, -0.308, 0.29, -0.111, -0.17,
    0.264, 0.0287, 0.106, 0.278, 0.237, -0.0752, 0.225, 0.0793,
    0.26, -0.247, -0.214, 0.0117, 0.18, 0.196, -0.0405, -0.101,
    -0.127, -0.0135, 0.0233, -0.067, 0.0385, -0.0251, 0.0492, -0.313,
  ]
  weights[21]: [
    -0.0398, -0.273, 0.173, 0.181, 0.0593, -0.211, -0.0687, 0.0317,
    -0.421, 0.3, -0.428, -0.0638, -0.0505, 0.43, -0.349, -0.312,
    -0.126, 0.0495, 0.384, 0.392, -0.396, -0.0203, -0.398, -0.303,
    0.368, 0.394, -0.418, -0.421, 0.155, -0.108, -0.259, 0.423,
  ]
  weights[22]: [
    0.015, 0.213, -0.245, -0.0367, -0.301, 0.151, 0.247, -0.352,
    0.346, -0.202, 0.034, 0.204, 0.191, -0.321, 0.112, 0.37,
    0.175, -0.00615, -0.2, -0.243, 0.139, 0.147, 0.374, 0.139,
    -0.016, -0.316, 0.0849, 0.337, -0.105, 0.334, 0.196, -0.335,
  ]
  weights[23]: [
    0.354, 0.271, -0.12, -0.0331, -0.339, 0.366, 0.156, -0.0182,
    0.226, 0.0105, 0.271, 0.353, 0.198, -0.288, 0.0621, 0.0171,
    0.14, -0.33, -0.126, -0.112, 0.108, 0.0437, 0.0401, 0.0684,
    -0.238, -0.115, 0.361, 0.0727, -0.353, 0.0193, 0.355, -0.389,
  ]
  weights[24]: [
    0.404, 0.159, -0.433, -0.0274, -0.12, 0.014, 0.0268, -0.369,
    0.414, -0.0672, 0.307, 0.0594, 0.0579, -0.14, 0.326, 0.377,
    0.146, -0.293, -0.339, -0.24, 0.362, -0.032, 0.279, -0.0861,
    -0.064, -0.177, 0.11, 0.323, -0.0814, 0.407, 0.222, -0.252,
  ]
  weights[25]: [
    0.149, 0.22, 0.0373, -0.028, 0.0846, 0.0216, -0.121, -0.145,
    -0.0864, 0.0723, -0.0461, 0.00645, 0.0487, 0.079, 0.324, 0.22,
    0.287, 0.0121, -0.321, -0.0737, 0.05, 0.16, 0.102, -0.0142,
    -0.306, -0.136, -0.0547, 0.167, -0.136, 0.314, 0.275, -0.33,
  ]
  weights[26]: [
    0.0445, -0.193, 0.108, -0.105, 0.395, -0.307, 0.0713, 0.213,
    -0.278, 0.414, -0.308, -0.0562, -0.0947, 0.35, -0.387, -0.256,
    -0.415, 0.4, 0.354, 0.422, -0.44, -0.141, -0.318, -0.127,
    0.142, 0.12, -0.416, -0.223, 0.383, -0.316, -0.246, 0.253,
  ]
  weights[27]: [
    0.436, 0.156, -0.438, 0.147, -0.302, 0.377, 0.00786, -0.428,
    0.19, -0.32, 0.266, 0.38, 0.384, -0.356, 0.276, 0.21,
    0.169, -0.413, -0.155, -0.294, 0.208, 0.19, 0.493, -0.0573,
    -0.267, -0.417, 0.448, 0.237, -0.298, 0.188, 0.231, -0.408,
  ]
  weights[28]: [
    -0.0623, -0.135, 0.206, -0.0485, 0.284, -0.328, 0.112, 0.442,
    -0.204, 0.357, -0.32, -0.437, -0.381, 0.325, -0.253, -0.379,
    -0.382, 0.278, 0.377, 0.0409, -0.19, -0.199, -0.235, -0.0136,
    0.379, 0.435, -0.0818, -0.408, 0.28, -0.462, -0.306, 0.318,
  ]
  weights[29]: [
    0.0168, -0.241, 0.179, 0.151, 0.307, -0.102, -0.0118, 0.102,
    0.0274, 0.314, -0.277, -0.215, -0.239, 0.127, -0.133, -0.0624,
    -0.328, 0.199, -0.0527, 0.218, -0.106, -0.118, 0.00961, -0.175,
    0.26, 0.0733, -0.312, 0.05, 0.284, -0.357, -0.117, 0.0243,
  ]
  weights[30]: [
    -0.04, -0.309, 0.397, 0.266, 0.361, -0.0716, -0.00505, 0.365,
    -0.141, 0.329, -0.0999, -0.122, -0.0873, 0.193, -0.227, -0.0283,
    -0.365, 0.31, 0.195, 0.167, -0.212, -0.0404, -0.372, -0.0658,
    0.317, 0.031, -0.341, -0.15, 0.34, -0.144, -0.104, 0.367,
  ]
  weights[31]: [
    -0.233, -0.233, 0.00356, 0.112, -0.126, -0.17, -0.304, -0.0405,
    -0.0694, 0.0114, 0.161, 0.205, -0.153, 0.135, 0.0243, -0.252,
    -0.0745, 0.0829, -0.168, 0.0166, 0.0316, -0.128, 0.0392, -0.173,
    0.0127, -0.235, -0.136, 0.0134, 0.0969, 0.0761, -0.00183, 0.118,
  ]
  biases: [
    0.2, 0.0545, -0.0558, 0.0236, 0.117, 0.00607, 0.283, -0.073,
    0.24, 0.294, 0.0358, 0.138, 0.102, 0.319, 0.138, 0.116,
    0.368, 0.151, 0.0935, 0.168, 0.14, 0.228, 0.0576, 0.221,
    0.233, 0.133, 0.0757, 0.381, 0.342, 0.125, 0.149, 0.171,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.0896, 0.0904, 0.184, 0.136, 0.0187, 0.106, 0.173, 0.185,
    0.161, 0.115, 0.086, 0.0849, 0.318, 0.164, 0.22, -0.021,
    0.0826, 0.226, 0.157, 0.16, 0.0711, 0.166, 0.137, 0.049,
    0.0716, 0.171, 0.2, 0.00199, 0.22, 0.19, 0.24, 0.299,
  ]
layer: BatchNormalization
  weights: [
    0.364, 0.908, 0.286, 0.424, 0.476, 0.444, 0.214, 0.362,
    0.191, 0.194, 0.393, 0.327, 0.717, 0.285, 0.268, 0.388,
    0.222, 0.218, 0.396, 0.312, 0.444, 0.221, 0.252, 0.384,
    0.294, 0.54, 0.232, 0.24, 0.189, 0.3, 0.224, 1.05,
  ]
  biases: [
    -0.854, -0.771, -0.636, -0.9, -0.838, -0.913, -0.998, -0.743,
    -0.714, -1.24, -1.04, -0.913, -0.89, -1.05, -0.931, -0.94,
    -1.1, -0.692, -0.874, -0.69, -0.877, -0.783, -0.827, -1.15,
    -1.1, -0.988, -0.962, -0.937, -0.765, -0.715, -0.605, -0.604,
  ]
layer: FullyConnected
  weights[0]: [
    0.0197, -0.0102, 0.482, 0.488, -0.286, 0.0595, 0.312, 0.453,
    0.171, 0.11, -0.0679, -0.156, 0.58, 0.234, 0.545, 0.284,
    0.418, 0.543, 0.392, 0.0994, 0.0598, 0.492, -0.26, -0.186,
    -0.0358, -0.0169, 0.514, -0.00564, 0.225, 0.401, 0.572, -0.31,
  ]
  weights[1]: [
    0.0671, 0.385, -0.362, -0.269, -0.207, -0.196, -0.401, -0.217,
    -0.131, 0.043, 0.132, -0.166, -0.294, -0.213, -0.376, -0.0559,
    -0.351, -0.327, 0.0609, 0.0721, -0.037, -0.359, 0.178, -0.00293,
    0.0104, 0.059, -0.21, -0.0941, -0.164, -0.145, -0.217, -0.0511,
  ]
  weights[2]: [
    0.2, 0.342, 0.454, 0.133, -0.116, -0.224, 0.185, 0.431,
    0.335, 0.159, 0.143, 0.0591, 0.284, 0.417, 0.517, 0.331,
    0.388, 0.154, 0.225, -0.162, 0.174, 0.421, 0.0329, -0.0122,
    0.0262, -0.0502, 0.377, -0.0387, 0.194, 0.32, 0.291, -0.00816,
  ]
  weights[3]: [
    0.615, 0.715, 0.369, 0.246, 0.526, 0.463, 0.264, 0.509,
    0.432, 0.326, 0.712, 0.704, 0.335, 0.501, 0.0973, 0.531,
    0.552, 0.196, 0.501, 0.661, 0.471, 0.328, 0.396, 0.64,
    0.466, 0.649, 0.228, 0.541, 0.524, 0.508, 0.22, -0.286,
  ]
  weights[4]: [
    -0.26, -0.268, 0.047, 0.193, -0.271, -0.0839, 0.194, -0.0387,
    0.199, -0.368, -0.267, -0.311, 0.23, 0.0839, 0.0469, 0.0428,
    0.0817, 0.281, 0.186, -0.0708, -0.0721, -0.0131, -0.196, -0.283,
    -0.248, -0.0161, 0.1, 0.00333, 0.195, -0.0248, 0.215, 0.0742,
  ]
  weights[5]: [
    0.357, 0.314, -0.312, 0.065, 0.496, 0.326, -0.256, -0.131,
    -0.427, 0.489, 0.343, 0.408, -0.0233, -0.379, -0.288, 0.0978,
    -0.293, -0.268, 0.125, 0.0542, 0.119, -0.37, 0.221, 0.218,
    0.443, 0.466, -0.41, 0.204, -0.128, -0.409, -0.384, -0.136,
  ]
  weights[6]: [
    0.098, 0.311, -0.188, -0.297, -0.115, 0.011, -0.275, 0.0239,
    -0.273, 0.184, -0.389, -0.35, -0.235, -0.316, -0.286, -0.36,
    -0.453, -0.48, -0.424, -0.0844, 0.0942, -0.375, 0.0895, -0.146,
    0.146, -0.00554, -0.378, 0.0953, -0.42, -0.46, -0.313, -0.298,
  ]
  weights[7]: [
    -0.192, -0.199, -0.0117, -0.333, -0.00828, -0.139, -0.216, -0.285,
    -0.0316, -0.321, -0.169, -0.288, -0.0389, -0.155, -0.103, -0.288,
    -0.117, -0.242, 0.0112, -0.0255, -0.00343, -0.125, -0.0912, -0.347,
    -0.325, -0.34, -0.155, -0.308, -0.107, -0.111, -0.0902, 0.259,
  ]
  weights[8]: [
    -0.374, -0.108, -0.18, -0.155, -0.293, -0.325, -0.174, -0.423,
    -0.388, -0.319, -0.522, -0.258, -0.465, -0.496, -0.209, -0.359,
    -0.502, -0.461, -0.303, -0.125, -0.302, -0.331, -0.368, -0.61,
    -0.488, -0.31, -0.334, -0.253, -0.135, -0.293, -0.313, 0.407,
  ]
  weights[9]: [
    -0.0136, -0.476, -0.243, 0.0936, -0.253, 0.0923, 0.102, -0.145,
    0.0281, -0.0115, 0.0754, -0.136, 0.0886, 0.126, 0.0303, -0.327,
    -0.0546, 0.0805, -0.0685, -0.319, -0.358, 0.0545, -0.204, -0.257,
    -0.119, -0.0943, -0.17, -0.143, -0.0555, -0.209, 0.11, -0.0149,
  ]
  weights[10]: [
    -0.162, -0.109, 0.234, 0.337, 0.0506, -0.0263, 0.262, 0.336,
    0.00886, -0.13, -0.237, -0.143, 0.364, 0.258, 0.355, 0.271,
    0.381, 0.176, 0.251, 0.114, -0.0214, -0.00391, 0.03, 0.0584,
    -0.115, 0.133, 0.0238, 0.0828, 0.159, 0.353, 0.343, -0.0506,
  ]
  weights[11]: [
    0.0774, -0.232, 0.0426, -0.0389, -0.334, 0.00163, -0.24, 0.109,
    -0.11, -0.0966, -0.0172, -0.0937, -0.207, -0.333, -0.244, -0.107,
    -0.265, -0.167, -0.253, 0.00223, -0.119, -0.0695, -0.219, -0.26,
    0.0832, 0.0458, -0.258, -0.218, -0.127, 0.0579, -0.256, 0.0594,
  ]
  weights[12]: [
    0.425, 0.257, -0.0672, -0.198, 0.149, 0.487, -0.163, -0.295,
    -0.181, 0.375, 0.157, 0.0954, -0.107, -0.213, -0.111, -0.0163,
    0.126, -0.253, 0.151, 0.217, 0.333, -0.0376, 0.231, 0.238,
    0.38, 0.336, -0.101, 0.118, -0.16, -0.0246, -0.255, -0.23,
  ]
  weights[13]: [
    0.332, 0.278, 0.338, 0.522, 0.615, 0.397, 0.322, 0.282,
    0.419, 0.236, 0.279, 0.469, 0.589, 0.322, 0.324, 0.47,
    0.496, 0.182, 0.386, 0.363, 0.309, 0.275, 0.103, 0.449,
    0.372, 0.267, 0.287, 0.62, 0.0971, 0.185, 0.29, -0.36,
  ]
  weights[14]: [
    -0.128, 0.179, -0.347, -0.253, -0.0609, -0.322, -0.3, 0.0541,
    -0.485, 0.0104, -0.316, -0.261, -0.242, -0.416, -0.474, -0.329,
    -0.451, -0.18, -0.115, -0.139, -0.042, -0.364, -0.236, -0.0195,
    0.0142, 0.0671, -0.122, -0.0221, -0.483, -0.262, -0.277, -0.343,
  ]
  weights[15]: [
    0.29, 0.543, 0.21, 0.222, 0.699, 0.478, 0.306, 0.0422,
    0.32, 0.517, 0.653, 0.468, 0.426, 0.203, 0.0118, 0.184,
    0.317, 0.269, 0.0654, 0.372, 0.506, 0.271, 0.548, 0.381,
    0.475, 0.372, 0.225, 0.344, 0.0011, 0.273, -0.0381, -0.186,
  ]
  weights[16]: [
    -0.367, -0.16, -0.194, -0.281, -0.128, -0.352, -0.386, -0.315,
    -0.355, -0.28, -0.421, -0.388, -0.065, -0.226, -0.292, -0.0775,
    -0.364, -0.0727, -0.113, -0.168, -0.34, -0.252, -0.309, -0.454,
    -0.346, -0.286, -0.232, -0.206, -0.125, -0.263, -0.0129, 0.209,
  ]
  weights[17]: [
    -0.676, -0.465, -0.315, -0.5, -0.188, -0.485, -0.0346, -0.392,
    0.0508, -0.57, -0.26, -0.305, -0.428, -0.198, -0.264, -0.191,
    -0.347, -0.25, -0.32, -0.554, -0.577, 0.0454, -0.583, -0.216,
    -0.388, -0.483, -0.261, -0.156, -0.0931, -0.0388, -0.105, 0.449,
  ]
  weights[18]: [
    -0.0141, -0.115, -0.0243, 0.122, -0.0284, -0.212, 0.167, 0.0309,
    0.134, -0.296, 0.121, 0.102, 0.0786, -0.0456, 0.0912, 0.115,
    0.122, -0.043, 0.19, -0.0706, -0.0189, 0.162, -0.186, 0.156,
    -0.1, -0.212, 0.259, 0.0368, 0.0979, 0.321, 0.0591, 0.232,
  ]
  weights[19]: [
    0.271, 0.307, 0.619, 0.599, 0.0595, -0.163, 0.567, 0.585,
    0.615, 0.111, 0.253, -0.0252, 0.782, 0.592, 0.606, 0.68,
    0.68, 0.529, 0.699, 0.0608, -0.0856, 0.482, 0.198, -0.0722,
    -0.026, -0.0726, 0.605, 0.282, 0.625, 0.566, 0.277, -0.283,
  ]
  weights[20]: [
    -0.353, -0.337, -0.247, -0.412, -0.365, -0.443, -0.354, -0.0856,
    -0.365, -0.607, -0.504, -0.447, -0.173, -0.283, -0.289, -0.521,
    -0.179, -0.169, -0.683, -0.413, -0.294, -0.0755, -0.543, -0.16,
    -0.638, -0.369, -0.345, -0.502, -0.251, -0.308, -0.207, 0.272,
  ]
  weights[21]: [
    -0.0544, -0.0975, -0.592, -0.298, -0.454, -0.464, -0.609, -0.393,
    -0.636, -0.173, -0.482, -0.377, -0.323, -0.819, -0.716, -0.203,
    -0.523, -0.452, -0.402, -0.0718, -0.0115, -0.492, -0.452, -0.198,
    -0.456, -0.131, -0.725, -0.0469, -0.726, -0.47, -0.347, 0.15,
  ]
  weights[22]: [
    -0.0801, 0.124, 0.273, 0.199, 0.0419, -0.079, 0.135, -0.0642,
    0.0869, -0.24, -0.051, 0.101, 0.0108, 0.197, 0.267, 0.215,
    -0.0146, -0.0385, 0.189, -0.0703, -0.167, 0.147, -0.103, -0.00999,
    -0.176, -0.184, 0.243, -0.131, 0.135, 0.00394, 0.0139, -0.154,
  ]
  weights[23]: [
    -0.0639, 0.28, -0.19, -0.226, -0.0954, 0.1, -0.214, 0.0913,
    -0.0342, -0.0375, -0.0894, 0.158, -0.23, 0.0218, -0.265, -0.0109,
    0.00542, -0.247, -0.022, -0.2, -0.189, -0.181, -0.0166, 0.1,
    -0.196, 0.0288, -0.125, 0.0818, -0.213, -0.188, -0.153, 0.205,
  ]
  weights[24]: [
    -0.363, -0.187, -0.277, -0.172, -0.254, -0.158, -0.21, -0.304,
    -0.308, -0.264, -0.211, -0.0442, -0.275, -0.305, -0.396, -0.243,
    -0.499, -0.297, -0.441, -0.238, -0.278, -0.414, -0.0805, -0.36,
    -0.152, -0.113, -0.532, -0.136, -0.182, -0.302, -0.258, 0.263,
  ]
  weights[25]: [
    -0.748, -0.761, -0.0752, -0.133, -0.734, -0.418, 0.000356, -0.459,
    0.00255, -0.937, -0.586, -0.49, -0.457, -0.113, -0.259, -0.256,
    -0.115, 0.0744, -0.142, -0.826, -0.703, 0.0612, -0.946, -0.676,
    -0.867, -0.54, -0.273, -0.802, -0.0421, -0.0547, -0.128, 0.427,
  ]
  weights[26]: [
    -0.115, 0.0924, 0.0178, 0.133, 0.0279, 0.368, 0.397, 0.109,
    0.163, -0.0223, 0.321, 0.308, 0.386, 0.315, 0.295, 0.266,
    0.0524, 0.0336, 0.271, 0.192, -0.099, 0.00484, 0.114, -0.0226,
    0.101, 0.287, 0.159, -0.0552, 0.0896, 0.247, 0.0975, -0.0979,
  ]
  weights[27]: [
    -0.231, -0.287, -0.251, -0.263, -0.503, -0.52, -0.554, -0.286,
    -0.34, -0.444, -0.436, -0.465, -0.466, -0.178, -0.465, -0.131,
    -0.368, -0.241, -0.233, -0.104, -0.0881, -0.401, -0.241, -0.146,
    -0.36, -0.524, -0.536, -0.24, -0.472, -0.469, -0.2, -0.0189,
  ]
  weights[28]: [
    -0.28, -0.16, 0.413, 0.307, -0.00227, -0.0297, 0.213, 0.113,
    0.133, 0.0208, -0.27, -0.156, 0.36, 0.388, 0.201, 0.144,
    0.338, 0.439, 0.0924, -0.223, 0.116, 0.213, -0.279, 0.00161,
    -0.0106, -0.261, 0.476, -0.16, 0.158, 0.345, 0.332, 0.186,
  ]
  weights[29]: [
    -0.398, -0.509, -0.315, -0.291, -0.232, 0.0171, -0.11, -0.358,
    -0.0024, -0.241, -0.252, -0.422, -0.101, 0.12, -0.118, -0.123,
    0.0448, 0.0799, -0.27, -0.422, -0.161, -0.0821, -0.213, -0.438,
    -0.384, -0.386, -0.147, -0.542, -0.0967, -0.075, -0.155, 0.163,
  ]
  weights[30]: [
    0.234, 0.258, -0.0989, 0.0449, 0.574, 0.286, -0.294, -0.169,
    -0.31, 0.376, 0.473, 0.629, -0.21, 0.006, -0.36, -0.0905,
    -0.182, -0.017, -0.0327, 0.503, 0.408, -0.357, 0.406, 0.288,
    0.516, 0.513, -0.36, 0.634, -0.24, 0.0291, -0.108, -0.517,
  ]
  weights[31]: [
    -0.237, -0.179, -0.174, -0.0689, -0.232, 0.0559, 0.105, 0.176,
    0.196, -0.0715, 0.0325, -0.222, 0.0187, -0.0473, -0.0887, 0.193,
    0.0791, 0.188, 0.115, 0.0757, -0.122, 0.0844, 0.124, -0.0685,
    0.0301, 0.00739, 0.121, 9.97e-05, -0.0204, -0.187, 0.198, -0.0903,
  ]
  biases: [
    -0.0505, 0.291, -0.0198, 0.591, 0.261, 0.304, 0.274, 0.194,
    0.298, 0.122, -0.00666, 0.191, -0.152, 0.712, 0.158, 0.0919,
    0.225, 0.453, 0.15, -0.0942, 0.368, 0.396, 0.0223, 0.122,
    0.0158, 0.173, -0.229, 0.408, 0.0282, -0.00216, -0.127, 0.0645,
  ]
layer: Activation
  function: PReLU
  weights: [
    -0.132, 0.135, -0.0545, 0.2, 0.406, 0.189, 0.188, -0.221,
    -0.175, 0.278, 0.312, 0.0124, 0.201, -0.0264, 0.109, -0.325,
    0.185, -0.289, 0.182, -0.0894, 0.375, -0.109, 0.22, 0.32,
    -0.231, -0.507, 0.219, 0.0524, 0.0663, -0.324, 0.142, 0.0873,
  ]
layer: BatchNormalization
  weights: [
    0.343, 0.614, 0.402, 0.537, 0.329, 0.235, 0.409, 1.23,
    0.749, 1.3, 0.336, 1.24, 0.352, 0.799, 0.625, 0.798,
    0.661, 0.787, 0.431, 0.262, 0.518, 0.624, 0.434, 1.07,
    0.963, 0.657, 1.06, 0.579, 0.327, 1.27, 0.234, 1.4,
  ]
  biases: [
    -1.67, -1.31, -1.61, -1.79, -0.246, -1.39, -1.07, -1.9,
    -2.44, -1.07, -0.855, -1.4, -1.05, -2.67, -1.41, -3.01,
    -0.865, -2.23, -0.783, -1.85, -0.955, -2.62, -0.641, -1.25,
    -3.05, -4.48, -1.13, -1.28, -1.15, -2.97, -1.31, -0.639,
  ]
layer: FullyConnected
  weights[0]: [
    -0.0839, 0.357, -0.0359, 0.876, -0.21, 0.504, 0.136, 0.124,
    -0.134, -0.0742, -0.143, -0.113, 0.595, 0.904, 0.159, 0.93,
    -0.381, 0.56, -0.118, 0.277, -0.428, -0.159, -0.107, 0.393,
    0.0365, 0.409, 0.514, -0.446, -0.156, 0.392, 0.348, -0.159,
  ]
  weights[1]: [
    -0.162, 0.284, 0.106, 0.193, -0.398, 0.217, 0.436, -0.102,
    -1.07, -0.278, -0.43, 0.246, 0.406, -0.0376, 0.0483, -0.195,
    -0.188, -0.067, -0.086, -0.0261, -0.417, 0.305, -0.234, 0.295,
    -0.157, -0.258, -0.631, 0.127, -0.126, -0.255, 0.496, -0.049,
  ]
  weights[2]: [
    -0.148, 0.215, -0.134, -0.82, -0.114, 0.0216, -0.00258, -0.935,
    -0.297, -0.0108, -0.333, 0.218, -0.147, -0.809, 0.328, -1.23,
    -0.753, -1, -0.21, -0.0168, -0.418, 0.248, -0.00352, 0.121,
    0.112, -0.448, 0.0471, 0.463, -0.131, -0.328, -0.105, 0.0812,
  ]
  weights[3]: [
    -0.178, -0.261, 0.0338, -0.355, -0.078, -0.791, 0.0832, -0.0711,
    0.399, -0.225, -0.246, 0.15, -0.53, -0.278, 0.131, -0.397,
    0.554, -0.41, -0.283, -0.313, 0.663, 0.462, -0.256, 0.0917,
    0.163, -1, -0.384, 0.707, -0.161, -1.02, -1, 0.00334,
  ]
  weights[4]: [
    0.264, 0.284, -0.0145, -0.302, -0.134, 0.0137, 0.482, 0.513,
    0.258, -0.243, -0.157, 0.579, -0.222, -0.202, 0.543, 0.278,
    0.533, 0.288, -0.315, -0.083, 0.338, 1, 0.122, 0.291,
    0.694, 0.243, -0.476, 0.569, 0.221, 0.00521, -0.434, 0.0891,
  ]
  weights[5]: [
    -0.313, -0.493, -0.244, -0.0809, 0.137, -0.5, -0.737, 0.621,
    0.499, 0.461, -0.394, -0.189, 0.0579, -0.398, -0.772, -0.238,
    0.53, 0.817, -0.0576, 0.122, 0.734, -0.0957, -0.394, -0.0437,
    0.24, 0.83, -0.0301, 0.321, -0.769, 0.658, 0.0486, -0.744,
  ]
  weights[6]: [
    -1.24, -0.00624, -1.11, -0.459, -0.194, -0.0707, -0.371, 0.267,
    0.362, 0.0639, -0.583, -0.93, -0.0509, -0.491, -0.533, -0.117,
    0.338, 0.688, -0.0708, -1.06, 0.268, -1.14, -0.0441, -0.4,
    -1.01, 0.514, -0.506, -0.255, -0.282, 0.558, -0.232, -0.289,
  ]
  weights[7]: [
    -0.272, -0.175, -0.43, -0.774, 0.336, -0.257, -0.291, -0.0124,
    -1.12, 0.0863, -0.0998, -0.203, -0.393, -1.24, -0.141, -0.523,
    0.0702, 0.327, 0.0256, -0.197, 0.0304, -0.0237, 0.216, -0.322,
    -0.38, 0.0318, -0.466, -0.905, 0.0765, -0.209, -0.42, 0.28,
  ]
  weights[8]: [
    0.24, 0.0589, 0.259, -0.0269, 0.35, -0.271, -0.254, -0.663,
    -0.297, 0.357, 0.286, -0.111, -0.0575, 0.0301, -0.0402, -0.649,
    -0.475, -0.055, 0.33, 0.287, -0.488, -0.158, 0.281, -0.26,
    -0.125, -0.186, -0.358, -0.163, 0.081, -0.29, -0.352, 0.1,
  ]
  weights[9]: [
    0.464, 0.00612, 0.752, 0.923, -0.0895, 0.363, 0.0322, 0.165,
    -0.0517, 0.313, 0.19, -0.0333, -0.0548, 0.922, -0.0846, 0.863,
    -0.144, -0.383, 0.305, 0.403, -0.0741, -0.00289, 0.36, 0.0452,
    0.415, -0.0356, 0.86, -0.0512, 0.503, -0.397, 0.149, 0.18,
  ]
  biases: [
    -0.377, 0.238, 0.262, 0.323, -0.0175, -0.108, 0.0687, 0.461,
    0.161, -0.471,
  ]
layer: Activation
  function: Softmax
