layer: InputScaling
  scale: [
    0.0526,
  ]
layer: FullyConnected
  weights[0]: [
    -0.409,
  ]
  weights[1]: [
    -0.543,
  ]
  weights[2]: [
    0.382,
  ]
  weights[3]: [
    -0.702,
  ]
  weights[4]: [
    0.279,
  ]
  weights[5]: [
    -0.157,
  ]
  weights[6]: [
    0.574,
  ]
  weights[7]: [
    0.0756,
  ]
  weights[8]: [
    -0.486,
  ]
  weights[9]: [
    0.445,
  ]
  weights[10]: [
    -0.871,
  ]
  weights[11]: [
    -0.975,
  ]
  weights[12]: [
    -0.721,
  ]
  weights[13]: [
    1.01,
  ]
  weights[14]: [
    -0.508,
  ]
  weights[15]: [
    -0.285,
  ]
  weights[16]: [
    -0.934,
  ]
  weights[17]: [
    0.818,
  ]
  weights[18]: [
    1.23,
  ]
  weights[19]: [
    0.407,
  ]
  weights[20]: [
    -0.809,
  ]
  weights[21]: [
    0.0889,
  ]
  weights[22]: [
    -0.452,
  ]
  weights[23]: [
    0.577,
  ]
  weights[24]: [
    0.459,
  ]
  weights[25]: [
    1.32,
  ]
  weights[26]: [
    -0.141,
  ]
  weights[27]: [
    -0.734,
  ]
  weights[28]: [
    0.217,
  ]
  weights[29]: [
    -1.1,
  ]
  weights[30]: [
    -1.29,
  ]
  weights[31]: [
    0.123,
  ]
  biases: [
    0.301, 0.396, 0.269, 0.368, 0.227, -0.0287, -0.407, 0.124,
    -0.0864, -0.327, -0.0438, -0.133, -0.00817, -0.123, 0.528, 0.542,
    0.204, 0.187, -0.0885, -0.318, 0.426, 0.37, 0.413, -0.425,
    0.21, 0.165, -0.0334, -0.0525, 0.19, -0.135, 0.188, 0.161,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.236, 0.24, 0.25, 0.231, 0.25, 0.328, 0.815, 0.25,
    0.291, -0.343, 0.264, 0.272, 0.27, 0.25, 0.234, 0.226,
    0.263, 0.25, 0.25, 0.292, 0.224, 0.251, 0.245, 0.118,
    0.25, 0.25, 0.22, 0.291, 0.25, 0.302, 0.252, 0.25,
  ]
layer: BatchNormalization
  weights: [
    29.5, 23.1, 17.2, 41.4, 23.7, 130, 13.3, 88.6,
    48.1, 28.3, 28.8, 24.6, 35, 6.94, 13.6, 23.4,
    29.7, 8.84, 5.68, 26.5, 37.3, 73.7, 17, 21.3,
    14.9, 4.95, 201, 30.9, 30.9, 20.6, 21.2, 55.5,
  ]
  biases: [
    -0.383, -0.341, -9.63, 1.64, -10.4, 6.3, -0.535, -16.1,
    6.35, -1.25, 5.37, 5.82, 5.27, -4.5, -1.85, -7.51,
    3.99, -7.17, -4.86, -0.447, 1.69, -32.3, -1.18, -1.08,
    -8.31, -5.81, 6.21, 5.47, -11, 6.05, 4.28, -14.1,
  ]
layer: FullyConnected
  weights[0]: [
    0.131, -0.131, 0.131, -0.157, -0.196, 0.214, 0.00442, -0.128,
    -0.0145, -0.0522, -0.0427, -0.0486, 0.23, 0.00856, 0.155, 0.139,
    0.144, -0.233, -0.0524, -0.219, 0.16, -0.0331, 0.0886, -0.227,
    -0.144, 0.00891, -0.0928, -0.0737, -0.0742, 0.256, -0.0788, 0.102,
  ]
  weights[1]: [
    -0.0754, 0.163, -0.0766, 0.208, 0.137, 0.012, -0.227, -0.0842,
    0.121, -0.0104, -0.0148, -0.186, 0.197, -0.188, 0.226, 0.101,
    0.0147, 0.0822, 0.0185, -0.00407, 0.00076, 0.13, 0.18, -0.0263,
    0.184, 0.15, -0.148, -0.00851, -0.0868, -0.146, 0.0405, 0.0859,
  ]
  weights[2]: [
    -0.227, -0.198, 0.0962, 0.0235, 0.181, 0.052, 0.231, 0.111,
    0.137, 0.313, 0.103, 0.00708, -0.0148, 0.241, -0.0694, -0.225,
    0.111, 0.202, -0.0888, 0.257, 0.00917, -0.0575, 0.0201, 0.251,
    0.257, 0.113, -0.0584, -0.136, -0.129, -0.154, -0.167, -0.102,
  ]
  weights[3]: [
    -0.213, -0.197, -0.105, -0.00157, -0.0271, 0.178, 0.268, -0.0768,
    0.0421, 0.169, -0.025, 0.0409, -0.182, 0.165, 0.0572, 0.116,
    -0.225, 0.124, -0.147, 0.011, -0.0099, -0.0361, -0.145, 0.187,
    0.216, -0.109, 0.138, -0.0146, 0.184, -0.0265, 0.154, 0.234,
  ]
  weights[4]: [
    0.022, 0.147, 0.0811, -0.028, -0.18, 0.154, -0.0825, 0.117,
    -0.0999, 0.182, -0.00435, 0.166, 0.122, -0.0711, 0.0786, 0.0541,
    0.163, -0.229, -0.15, -0.0965, -0.0553, 0.0922, 0.23, 0.165,
    0.102, -0.174, -0.086, -0.147, 0.154, 0.146, -0.0286, -0.0133,
  ]
  weights[5]: [
    -0.0311, 0.239, 0.0985, 0.0442, 0.00554, 0.169, -0.0415, -0.108,
    0.0774, 0.135, 0.0235, -0.0635, 0.17, -0.197, -0.0121, -0.169,
    -0.126, -0.185, -0.0643, 0.0698, -0.145, 0.185, 0.0936, -0.0636,
    -0.151, -0.184, -0.176, -0.137, 0.0429, 0.233, 0.16, -0.158,
  ]
  weights[6]: [
    -0.128, -0.134, 0.306, 0.0963, -0.0107, -0.0528, 0.213, 0.208,
    -0.299, 0.113, -0.211, -0.293, 0.0704, 0.109, -0.0912, -0.27,
    -0.171, -0.0497, -0.0235, 0.205, -0.129, 0.145, -0.0847, 0.1,
    0.306, 0.329, 0.0916, -0.237, 0.245, -0.317, -0.17, 0.19,
  ]
  weights[7]: [
    -0.0879, -0.0817, -0.133, 0.0447, -0.0414, 0.0819, 0.168, -0.173,
    0.0744, 0.0421, -0.0665, -0.159, 0.0513, 0.158, -0.187, -0.165,
    0.0683, 0.153, 0.219, 0.124, -0.203, 0.157, -0.112, 0.186,
    -0.0207, -0.181, -0.169, 0.0708, 0.08, 0.103, -0.168, 0.203,
  ]
  weights[8]: [
    -0.257, -0.227, 0.0485, 0.096, 0.135, -0.0791, 0.119, -0.0657,
    -0.201, 0.323, -0.0736, -0.274, -0.143, 0.154, -0.276, -0.154,
    -0.241, 0.112, 0.0728, 0.271, -0.31, 0.105, -0.286, -0.0421,
    0.189, -0.0653, -0.195, -0.165, 0.117, -0.235, -0.0443, 0.0618,
  ]
  weights[9]: [
    0.275, 0.144, -0.215, 0.25, -0.344, 0.0717, -0.116, -0.254,
    0.252, -0.0973, 0.397, 0.311, 0.105, -0.212, 0.0599, 0.0968,
    0.278, -0.375, -0.381, 0.0565, 0.257, 0.0733, 0.362, 0.00182,
    -0.388, -0.356, 0.245, 0.0511, -0.291, 0.387, 0.206, -0.375,
  ]
  weights[10]: [
    0.187, 0.0634, -0.000312, -0.0589, -0.0827, 0.0569, 0.0813, 0.0475,
    -0.0556, 0.128, 0.205, 0.242, 0.196, 0.0967, 0.119, -0.0313,
    0.0902, -0.243, 0.153, 0.0355, -0.177, -0.0913, 0.0478, 0.175,
    -0.064, 0.172, 0.00135, 0.172, -0.234, 0.133, -0.119, -0.134,
  ]
  weights[11]: [
    0.193, 0.277, -0.0994, -0.0717, 0.139, 0.153, -0.161, -0.00685,
    -0.0464, 0.138, 0.0726, 0.0524, 0.185, -0.0173, 0.228, 0.0927,
    -0.049, -0.243, -0.231, -0.0983, 0.0154, 0.155, 0.106, 0.0661,
    -0.253, -0.0887, -0.000819, -0.0297, 0.125, 0.0131, 0.0917, 0.0221,
  ]
  weights[12]: [
    0.0657, 0.0141, 0.173, -0.0234, 0.0563, 0.0334, 0.138, -0.191,
    -0.0874, 0.0789, -0.0238, 0.0616, 0.0133, 0.00935, 0.0318, 0.199,
    0.0142, 0.0388, 0.182, -0.189, -0.0149, 0.157, -0.184, 0.0501,
    0.133, -0.16, -0.00463, -0.215, 0.168, -0.141, -0.00504, -0.174,
  ]
  weights[13]: [
    -0.0147, -0.0596, 0.117, -0.202, 0.0695, -0.145, 0.292, 0.274,
    -0.264, 0.168, 0.0783, -0.24, -0.194, 0.0646, -0.0218, -0.181,
    -0.209, -0.11, 0.227, 0.261, -0.0236, -0.0376, -0.0218, -0.0131,
    0.00614, -0.0934, 0.0502, 0.0482, -0.12, -0.235, -0.103, 0.232,
  ]
  weights[14]: [
    -0.234, 0.0846, -0.0286, 0.0362, -0.0462, -0.246, 0.102, 0.0838,
    -0.296, 0.199, -0.241, -0.189, 0.00727, 0.00638, -0.0512, -0.199,
    -0.204, 0.255, 0.073, 0.276, -0.0817, -0.0135, 0.0306, 0.0849,
    0.103, -0.0362, -0.14, -0.09, -0.121, -0.25, -0.104, 0.15,
  ]
  weights[15]: [
    0.098, 0.0783, 0.0419, -0.101, 0.196, -0.13, -0.229, -0.0244,
    -0.12, -0.117, -0.0558, 0.0687, -0.112, -0.194, -0.0984, 0.0992,
    0.025, 0.123, -0.0039, 0.0398, 0.21, -0.178, 0.155, 0.151,
    -0.0831, -0.155, 0.038, 0.0714, 0.00815, 0.187, 0.222, -0.238,
  ]
  weights[16]: [
    -0.142, 0.0272, 0.0243, -0.241, 0.121, -0.137, -0.00303, 0.327,
    -0.136, 0.32, -0.151, -0.0177, -0.273, 0.148, -0.0153, -0.299,
    -0.261, 0.0274, 0.283, 0.162, -0.355, 0.235, -0.0792, 0.337,
    0.265, 0.27, -0.226, -0.129, 0.344, -0.00259, -0.192, 0.214,
  ]
  weights[17]: [
    -0.253, -0.227, 0.239, 0.0294, 0.238, 0.0466, 0.193, 0.23,
    -0.214, 0.201, -0.11, 0.0989, -0.255, -0.0139, -0.2, -0.283,
    -0.213, 0.28, 0.266, 0.116, -0.148, 0.189, -0.0781, 0.00991,
    0.0829, 0.11, -0.0566, -0.262, 0.07, 0.083, -0.131, 0.0368,
  ]
  weights[18]: [
    -0.0484, -0.181, -0.07, 0.0985, 0.029, -0.0775, 0.199, 0.116,
    -0.134, 0.269, 0.147, 0.154, 0.138, -0.165, -0.133, 0.0482,
    -0.26, 0.232, 0.0979, 0.0653, 0.103, -0.0349, 0.0658, 0.166,
    0.181, 0.0395, 0.109, -0.136, -0.125, -0.161, 0.0633, 0.277,
  ]
  weights[19]: [
    0.166, -0.138, 0.147, 0.0514, -0.0113, 0.195, 0.181, -0.102,
    0.161, 0.14, 0.193, 0.129, 0.0206, -0.0439, -0.0303, 0.218,
    0.231, 0.0822, 0.0228, -0.0547, 0.0884, 0.0165, 0.00705, -0.186,
    0.112, -0.0954, -0.0453, 0.094, -0.197, 0.156, 0.0184, -0.197,
  ]
  weights[20]: [
    0.104, -0.0967, -0.182, 0.153, -0.214, 0.187, -0.217, -0.069,
    0.163, 0.145, 0.00181, 0.175, 0.135, 0.0265, 0.122, -0.0392,
    0.149, -0.134, -0.103, 0.133, 0.0733, 0.157, -0.149, -0.19,
    -0.024, 0.0883, -0.0991, -0.166, 0.14, -0.129, -0.0556, -0.193,
  ]
  weights[21]: [
    0.0171, -0.168, 0.0537, -0.00991, -0.0353, -0.0855, 0.096, -0.0832,
    -0.296, 0.232, -0.317, 0.0468, 0.0721, 0.32, -0.31, -0.251,
    -0.0079, -0.0719, 0.285, 0.356, -0.306, 0.192, -0.291, -0.0127,
    0.254, 0.294, -0.222, -0.304, 0.0335, 0.0107, -0.157, 0.309,
  ]
  weights[22]: [
    -0.103, 0.0217, -0.136, 0.0662, -0.204, 0.0396, 0.0959, -0.245,
    0.237, -0.0514, -0.0795, 0.0918, 0.0823, -0.215, -0.0106, 0.216,
    0.0595, 0.112, -0.0856, -0.0954, 0.0257, 0.0928, 0.25, 0.0174,
    0.0968, -0.207, -0.077, 0.23, 0.00502, 0.224, 0.0859, -0.219,
  ]
  weights[23]: [
    0.224, 0.108, 0.0142, 0.0812, -0.213, 0.229, 0.0188, 0.119,
    0.0928, 0.16, 0.133, 0.216, 0.0652, -0.157, -0.0752, -0.12,
    -0.00202, -0.186, 0.018, 0.0419, -0.0314, -0.0293, -0.101, -0.0572,
    -0.102, 0.0196, 0.181, -0.0595, -0.221, -0.118, 0.219, -0.239,
  ]
  weights[24]: [
    0.258, -0.0485, -0.289, 0.0855, 0.0127, -0.132, -0.13, -0.225,
    0.271, 0.0939, 0.159, -0.0895, -0.0866, 0.00164, 0.176, 0.206,
    -0.00509, -0.14, -0.187, -0.0723, 0.214, -0.126, 0.123, -0.255,
    0.0834, -0.0314, -0.0939, 0.181, 0.063, 0.262, 0.0761, -0.0953,
  ]
  weights[25]: [
    0.0607, 0.0912, 0.118, 0.0206, 0.163, -0.0593, -0.214, -0.0621,
    -0.168, 0.162, -0.13, -0.0765, -0.0318, 0.159, 0.232, 0.123,
    0.199, 0.102, -0.234, 0.0195, -0.0352, 0.147, 0.0121, -0.0925,
    -0.224, -0.0555, -0.15, 0.0888, -0.0562, 0.232, 0.192, -0.225,
  ]
  weights[26]: [
    0.0984, -0.113, -0.027, -0.306, 0.295, -0.171, 0.21, 0.0824,
    -0.139, 0.36, -0.176, 0.0744, 0.0417, 0.223, -0.333, -0.229,
    -0.283, 0.265, 0.228, 0.388, -0.325, 0.0659, -0.202, 0.179,
    0.00952, -0.00564, -0.207, -0.0897, 0.25, -0.185, -0.122, 0.11,
  ]
  weights[27]: [
    0.283, -0.0297, -0.269, 0.33, -0.147, 0.211, -0.203, -0.262,
    0.0218, -0.17, 0.0885, 0.205, 0.218, -0.194, 0.119, 0.0526,
    -0.00538, -0.236, 0.0255, -0.124, 0.0337, 0.0573, 0.322, -0.337,
    -0.0954, -0.246, 0.196, 0.069, -0.131, 0.0148, 0.0603, -0.231,
  ]
  weights[28]: [
    0.00513, -0.016, 0.0337, -0.219, 0.159, -0.146, 0.236, 0.283,
    -0.0176, 0.202, -0.157, -0.287, -0.208, 0.16, -0.177, -0.245,
    -0.211, 0.101, 0.228, -0.153, -0.0462, 0.0248, -0.0822, 0.297,
    0.213, 0.288, 0.145, -0.241, 0.106, -0.299, -0.154, 0.133,
  ]
  weights[29]: [
    0.073, -0.181, 0.07, 0.00207, 0.22, 0.012, 0.108, -0.00383,
    0.144, 0.254, -0.17, -0.112, -0.128, 0.0206, -0.0984, -0.0181,
    -0.219, 0.0857, -0.158, 0.171, -0.0103, -0.0297, 0.111, 0.0224,
    0.153, -0.0271, -0.174, 0.161, 0.175, -0.25, -0.0145, -0.0953,
  ]
  weights[30]: [
    0.0045, -0.237, 0.285, 0.126, 0.266, 0.0507, 0.102, 0.256,
    -0.0177, 0.232, 0.0143, -0.013, 0.0326, 0.0785, -0.184, 0.0455,
    -0.25, 0.192, 0.0872, 0.072, -0.111, 0.113, -0.272, 0.138,
    0.204, -0.0763, -0.179, -0.0336, 0.225, -0.0293, 0.00349, 0.245,
  ]
  weights[31]: [
    -0.16, -0.201, 0.00945, 0.174, -0.124, -0.173, -0.19, -0.0362,
    -0.0721, -0.0696, 0.157, 0.2, -0.158, 0.142, 0.0556, -0.127,
    -0.0822, 0.0892, -0.155, -0.0173, 0.0195, -0.161, 0.0616, -0.239,
    0.0169, -0.233, -0.133, 0.00814, 0.103, 0.0732, -0.0105, 0.125,
  ]
  biases: [
    0.0674, 0.0514, -0.0998, -0.104, 0.0211, -0.069, 0.0348, -0.113,
    0.0141, 0.154, -0.0535, 0.0188, 0.0164, 0.126, -0.0385, -0.0404,
    0.1, -0.0384, -0.0248, 0.0118, -0.0231, -0.0415, -0.0791, 0.036,
    0.063, 0.0206, -0.114, 0.21, 0.153, -0.0325, 0.00923, 0.0361,
  ]
layer: Activation
  function: PReLU
  weights: [
    0.0325, 0.119, 0.215, 0.18, 0.169, 0.17, 0.225, 0.195,
    0.218, 0.111, 0.246, 0.21, 0.337, 0.217, 0.232, 0.0158,
    0.139, 0.251, 0.217, 0.193, 0.121, 0.216, 0.132, 0.168,
    0.0727, 0.248, 0.225, 0.0411, 0.263, 0.234, 0.267, 0.276,
  ]
layer: BatchNormalization
  weights: [
    0.968, 2.44, 0.644, 1.38, 1.47, 1.66, 0.416, 0.988,
    0.394, 0.337, 1.7, 0.86, 2.27, 0.624, 0.571, 1.45,
    0.389, 0.402, 1.17, 0.961, 1.48, 0.419, 0.752, 1.09,
    0.706, 1.76, 0.379, 0.473, 0.349, 0.887, 0.463, 4.14,
  ]
  biases: [
    -0.94, -0.741, -0.557, -0.666, -0.544, -0.773, -0.897, -0.63,
    -0.674, -1.16, -0.729, -0.696, -0.759, -0.906, -0.784, -0.856,
    -0.926, -0.634, -0.707, -0.711, -0.852, -0.708, -0.783, -0.837,
    -1.09, -0.905, -0.817, -0.929, -0.654, -0.642, -0.513, -0.785,
  ]
layer: FullyConnected
  weights[0]: [
    0.0929, -0.174, 0.381, 0.311, -0.22, 0.159, 0.147, 0.286,
    0.0386, 0.193, 0.0137, -0.0829, 0.227, 0.0841, 0.422, 0.0465,
    0.251, 0.409, 0.259, 0.174, 0.13, 0.362, -0.187, -0.124,
    0.0394, 0.0608, 0.373, 0.062, 0.0569, 0.276, 0.42, -0.271,
  ]
  weights[1]: [
    0.258, 0.384, -0.36, -0.282, -0.0406, -0.0494, -0.396, -0.256,
    -0.116, 0.219, 0.352, -0.00966, -0.358, -0.172, -0.349, 0.095,
    -0.329, -0.338, 0.079, 0.238, 0.13, -0.352, 0.367, 0.169,
    0.191, 0.213, -0.186, 0.11, -0.169, -0.113, -0.23, 0.257,
  ]
  weights[2]: [
    0.184, 0.184, 0.329, -0.0699, -0.132, -0.219, 0.0156, 0.266,
    0.201, 0.151, 0.14, 0.0498, -0.0295, 0.261, 0.374, 0.0722,
    0.208, 0.0154, 0.0715, -0.18, 0.157, 0.283, 0.0242, -0.0368,
    0.0079, -0.0648, 0.213, -0.062, 0.0323, 0.178, 0.138, 0.00986,
  ]
  weights[3]: [
    0.477, 0.503, 0.378, 0.16, 0.419, 0.472, 0.258, 0.475,
    0.403, 0.265, 0.714, 0.609, 0.0643, 0.515, 0.126, 0.606,
    0.498, 0.164, 0.466, 0.551, 0.45, 0.288, 0.301, 0.497,
    0.357, 0.589, 0.239, 0.333, 0.475, 0.51, 0.148, -0.252,
  ]
  weights[4]: [
    -0.291, -0.301, 0.0787, 0.25, -0.36, -0.136, 0.246, 0.0169,
    0.233, -0.4, -0.321, -0.386, 0.301, 0.119, 0.0822, -0.0946,
    0.131, 0.33, 0.232, -0.0841, -0.0983, 0.00536, -0.23, -0.331,
    -0.275, -0.041, 0.151, -0.0551, 0.242, -0.0086, 0.256, -0.0763,
  ]
  weights[5]: [
    0.345, 0.242, -0.407, -0.0261, 0.457, 0.229, -0.37, -0.234,
    -0.529, 0.427, 0.313, 0.333, -0.206, -0.484, -0.391, 0.282,
    -0.401, -0.369, 0.0547, 0.0342, 0.0819, -0.471, 0.163, 0.107,
    0.39, 0.395, -0.529, 0.159, -0.232, -0.516, -0.497, -0.0621,
  ]
  weights[6]: [
    0.328, 0.476, -0.144, -0.268, 0.137, 0.168, -0.194, 0.0235,
    -0.191, 0.394, -0.163, -0.0892, -0.22, -0.218, -0.194, -0.0911,
    -0.392, -0.417, -0.357, 0.164, 0.126, -0.294, 0.382, -0.0507,
    0.372, 0.151, -0.306, 0.397, -0.368, -0.39, -0.251, 0.0403,
  ]
  weights[7]: [
    -0.114, -0.146, -0.0104, -0.278, 0.0207, -0.117, -0.171, -0.26,
    -0.01, -0.247, -0.0954, -0.251, 0.0696, -0.114, -0.0771, -0.288,
    -0.0688, -0.221, 0.0429, 0.0418, 0.0208, -0.103, -0.0182, -0.284,
    -0.247, -0.304, -0.122, -0.265, -0.0735, -0.0872, -0.0643, 0.234,
  ]
  weights[8]: [
    -0.273, 0.00801, -0.187, -0.0666, -0.205, -0.267, -0.118, -0.373,
    -0.376, -0.214, -0.45, -0.158, -0.209, -0.458, -0.19, -0.316,
    -0.445, -0.434, -0.253, -0.0291, -0.221, -0.317, -0.269, -0.48,
    -0.383, -0.212, -0.299, -0.148, -0.0664, -0.273, -0.259, 0.289,
  ]
  weights[9]: [
    -0.0537, -0.347, -0.13, 0.244, -0.302, 0.0623, 0.2, 0.00766,
    0.118, -0.036, 0.0298, -0.186, 0.189, 0.214, 0.116, -0.306,
    0.0547, 0.173, 0.0443, -0.364, -0.366, 0.146, -0.261, -0.242,
    -0.155, -0.113, -0.0706, -0.215, 0.054, -0.13, 0.216, -0.196,
  ]
  weights[10]: [
    -0.198, -0.265, 0.233, 0.309, 0.0243, -0.0429, 0.242, 0.312,
    -0.00973, -0.165, -0.264, -0.188, 0.262, 0.246, 0.353, 0.0753,
    0.355, 0.166, 0.238, 0.0916, -0.0372, -0.0238, 0.00747, 0.0357,
    -0.15, 0.102, -0.00102, 0.0542, 0.139, 0.358, 0.339, -0.0557,
  ]
  weights[11]: [
    0.205, -0.0979, 0.0834, 0.00199, -0.195, 0.102, -0.159, 0.143,
    -0.0419, 0.0232, 0.125, 0.0543, -0.11, -0.247, -0.162, -0.0284,
    -0.205, -0.0943, -0.156, 0.0982, -0.0787, 0.00951, -0.0915, -0.179,
    0.213, 0.154, -0.18, -0.0598, -0.0578, 0.137, -0.185, 0.196,
  ]
  weights[12]: [
    0.383, 0.243, -0.0509, -0.212, 0.103, 0.473, -0.201, -0.263,
    -0.215, 0.332, 0.12, 0.0323, -0.189, -0.252, -0.138, 0.179,
    0.106, -0.284, 0.151, 0.18, 0.335, -0.0609, 0.178, 0.168,
    0.332, 0.298, -0.121, 0.0557, -0.182, -0.0347, -0.286, -0.282,
  ]
  weights[13]: [
    0.265, 0.104, 0.31, 0.389, 0.538, 0.408, 0.243, 0.165,
    0.354, 0.22, 0.265, 0.409, 0.167, 0.28, 0.31, 0.49,
    0.384, 0.114, 0.3, 0.3, 0.283, 0.197, 0.0575, 0.349,
    0.321, 0.234, 0.235, 0.497, -0.0155, 0.146, 0.176, -0.273,
  ]
  weights[14]: [
    0.00117, 0.137, -0.358, -0.295, -0.00433, -0.368, -0.279, -0.0276,
    -0.448, 0.036, -0.28, -0.207, -0.323, -0.38, -0.446, -0.312,
    -0.462, -0.142, -0.108, -0.0352, -0.0527, -0.325, -0.137, -0.0465,
    0.0938, 0.0826, -0.11, 0.125, -0.481, -0.227, -0.248, 0.34,
  ]
  weights[15]: [
    -0.0108, 0.233, 0.251, 0.182, 0.355, 0.226, 0.311, 0.0412,
    0.326, 0.212, 0.369, 0.122, 0.251, 0.218, 0.0459, 0.0816,
    0.296, 0.281, 0.0551, 0.0925, 0.27, 0.283, 0.218, 0.174,
    0.163, 0.07, 0.251, -0.00345, -0.0155, 0.299, -0.0574, -0.131,
  ]
  weights[16]: [
    -0.311, -0.103, -0.19, -0.208, -0.1, -0.369, -0.3, -0.292,
    -0.299, -0.235, -0.373, -0.351, 0.112, -0.152, -0.239, -0.13,
    -0.289, -0.0145, -0.0596, -0.115, -0.35, -0.203, -0.256, -0.391,
    -0.287, -0.258, -0.174, -0.166, -0.0545, -0.215, 0.0497, 0.169,
  ]
  weights[17]: [
    -0.659, -0.43, -0.355, -0.393, -0.206, -0.495, -0.00196, -0.341,
    0.0358, -0.525, -0.17, -0.312, -0.105, -0.197, -0.287, -0.26,
    -0.325, -0.241, -0.291, -0.548, -0.612, 0.0243, -0.546, -0.154,
    -0.348, -0.489, -0.259, -0.202, -0.0403, -0.0497, -0.0684, 0.196,
  ]
  weights[18]: [
    -0.0263, -0.128, 0.00178, 0.156, -0.0452, -0.209, 0.189, 0.0631,
    0.155, -0.309, 0.123, 0.0955, 0.097, -0.0316, 0.115, 0.035,
    0.147, -0.0331, 0.222, -0.0913, -0.0174, 0.184, -0.204, 0.159,
    -0.112, -0.222, 0.298, 0.0163, 0.118, 0.36, 0.0774, 0.0748,
  ]
  weights[19]: [
    0.266, 0.082, 0.603, 0.477, 0.062, -0.0839, 0.462, 0.485,
    0.556, 0.129, 0.294, -0.0372, 0.449, 0.509, 0.537, 0.314,
    0.576, 0.454, 0.628, 0.0327, -0.0385, 0.414, 0.199, -0.0475,
    -0.0371, -0.0727, 0.526, 0.275, 0.534, 0.521, 0.182, -0.275,
  ]
  weights[20]: [
    -0.33, -0.243, -0.22, -0.261, -0.297, -0.429, -0.261, -0.00187,
    -0.314, -0.55, -0.439, -0.383, 0.086, -0.21, -0.247, -0.501,
    -0.096, -0.102, -0.601, -0.379, -0.246, -0.0187, -0.504, -0.0417,
    -0.58, -0.323, -0.281, -0.467, -0.149, -0.249, -0.112, 0.0743,
  ]
  weights[21]: [
    0.116, 0.124, -0.518, -0.212, -0.295, -0.225, -0.416, -0.35,
    -0.501, -0.0164, -0.327, -0.191, -0.214, -0.616, -0.523, -0.0767,
    -0.361, -0.308, -0.304, 0.0622, 0.0307, -0.338, -0.27, -0.068,
    -0.285, 0.0426, -0.559, 0.151, -0.576, -0.314, -0.218, 0.603,
  ]
  weights[22]: [
    -0.0969, 0.0899, 0.289, 0.203, 0.0343, -0.0885, 0.146, -0.0808,
    0.0915, -0.255, -0.049, 0.0974, -0.0383, 0.218, 0.295, 0.156,
    -0.0155, -0.0409, 0.193, -0.0825, -0.195, 0.15, -0.105, -0.0375,
    -0.197, -0.217, 0.258, -0.158, 0.135, -0.000224, -0.000946, -0.16,
  ]
  weights[23]: [
    0.0443, 0.243, -0.225, -0.26, 0.00441, 0.163, -0.24, 0.0596,
    -0.0482, 0.0559, 0.0093, 0.254, -0.241, 0.00661, -0.295, 0.015,
    -0.0272, -0.268, -0.036, -0.117, -0.0935, -0.201, 0.0732, 0.201,
    -0.1, 0.0997, -0.151, 0.218, -0.235, -0.201, -0.162, 0.222,
  ]
  weights[24]: [
    -0.167, -0.125, -0.292, -0.187, -0.134, -0.118, -0.166, -0.316,
    -0.283, -0.146, -0.0765, 0.077, -0.284, -0.264, -0.372, -0.145,
    -0.484, -0.277, -0.428, -0.0602, -0.196, -0.377, 0.0657, -0.255,
    0.0175, 0.00349, -0.504, 0.0599, -0.165, -0.263, -0.231, 0.506,
  ]
  weights[25]: [
    -0.584, -0.671, -0.102, 0.00532, -0.579, -0.353, 0.0482, -0.371,
    0.0254, -0.756, -0.254, -0.347, -0.0633, -0.105, -0.283, -0.584,
    -0.0663, 0.11, -0.0904, -0.7, -0.711, 0.0826, -0.786, -0.426,
    -0.694, -0.463, -0.253, -0.718, 0.0212, -0.0393, -0.056, -0.018,
  ]
  weights[26]: [
    -0.109, -0.208, -0.0653, 0.0497, -0.0015, 0.333, 0.299, 0.0396,
    0.0652, -0.0161, 0.351, 0.262, 0.246, 0.208, 0.184, 0.184,
    -0.0727, -0.0577, 0.185, 0.225, 0.0102, -0.101, 0.107, 0.00863,
    0.108, 0.27, 0.0562, -0.0899, 0.00296, 0.16, 0.0123, -0.255,
  ]
  weights[27]: [
    -0.192, 0.00948, -0.301, -0.292, -0.383, -0.363, -0.53, -0.358,
    -0.338, -0.37, -0.384, -0.306, -0.395, -0.144, -0.443, -0.144,
    -0.363, -0.224, -0.252, -0.0728, -0.207, -0.397, -0.15, -0.0712,
    -0.289, -0.394, -0.532, -0.146, -0.454, -0.481, -0.189, 0.0914,
  ]
  weights[28]: [
    -0.273, -0.174, 0.394, 0.246, -0.00241, -0.011, 0.163, 0.0433,
    0.0916, 0.0466, -0.253, -0.149, 0.227, 0.362, 0.174, -0.124,
    0.296, 0.405, 0.0356, -0.213, 0.0977, 0.168, -0.261, -0.0226,
    0.00641, -0.261, 0.448, -0.171, 0.0924, 0.315, 0.273, 0.141,
  ]
  weights[29]: [
    -0.262, -0.372, -0.315, -0.171, -0.0968, 0.126, -0.0811, -0.267,
    -0.00172, -0.0789, -0.0707, -0.31, 0.218, 0.123, -0.142, -0.119,
    0.0837, 0.0947, -0.216, -0.275, -0.0234, -0.0822, -0.0784, -0.246,
    -0.259, -0.287, -0.139, -0.445, -0.0373, -0.0745, -0.101, -0.245,
  ]
  weights[30]: [
    0.108, 0.319, -0.0293, 0.0478, 0.55, 0.297, -0.274, -0.0867,
    -0.302, 0.295, 0.442, 0.586, -0.314, 0.0506, -0.318, 0.281,
    -0.149, 0.0124, -0.0127, 0.419, 0.37, -0.344, 0.319, 0.229,
    0.424, 0.479, -0.329, 0.535, -0.211, 0.075, -0.0909, -0.566,
  ]
  weights[31]: [
    -0.217, -0.191, -0.191, -0.0806, -0.208, 0.0848, 0.0971, 0.162,
    0.178, -0.0372, 0.0645, -0.195, 0.00569, -0.056, -0.0968, 0.175,
    0.0646, 0.175, 0.0997, 0.0952, -0.1, 0.0645, 0.151, -0.0237,
    0.0596, 0.0364, 0.111, 0.0228, -0.0344, -0.202, 0.181, -0.14,
  ]
  biases: [
    -0.139, 0.183, -0.0221, 0.0471, 0.17, 0.454, 0.189, 0.0978,
    0.258, 0.116, 0.00404, 0.098, -0.162, 0.452, 0.161, -0.144,
    0.142, 0.303, 0.0765, -0.131, 0.256, 0.212, 0.00158, 0.149,
    -0.0451, 0.117, -0.283, 0.382, -0.0131, 0.00362, -0.213, 0.000437,
  ]
layer: Activation
  function: PReLU
  weights: [
    -0.0856, 0.179, 0.0498, 0.321, 0.477, 0.136, 0.215, -0.229,
    -0.0194, 0.34, 0.379, 0.217, 0.23, 0.128, -0.0151, -0.3,
    0.309, -0.328, 0.247, -0.0683, 0.563, -0.0767, 0.252, 0.337,
    -0.211, -0.419, 0.379, 0.0451, 0.167, -0.241, 0.219, -0.0871,
  ]
layer: BatchNormalization
  weights: [
    0.485, 0.348, 0.831, 0.458, 0.267, 0.23, 0.283, 1.49,
    0.664, 0.464, 0.365, 1.11, 0.39, 0.78, 0.688, 1.92,
    0.715, 0.841, 0.504, 0.326, 0.489, 0.592, 0.503, 0.458,
    0.92, 0.706, 2.54, 0.58, 0.375, 1.97, 0.277, 2.32,
  ]
  biases: [
    -1.17, -0.831, -1.21, -0.916, -0.168, -1.42, -0.8, -1.98,
    -1.83, -0.943, -0.672, -0.682, -0.923, -1.68, -1.78, -3.03,
    -0.989, -2.63, -0.758, -1.43, -0.772, -2.25, -0.533, -1.08,
    -3.47, -4.35, 0.249, -1.47, -0.928, -3.24, -1.08, -0.834,
  ]
layer: FullyConnected
  weights[0]: [
    -0.136, 0.427, -0.0964, 0.582, -0.258, 0.51, 0.211, -0.0909,
    -0.372, -0.151, -0.242, -0.0139, 0.606, 0.523, -0.0522, 0.503,
    -0.488, 0.277, -0.167, 0.2, -0.486, -0.138, -0.171, 0.41,
    -0.0628, -0.0477, 0.476, -0.472, -0.267, 0.167, 0.348, -0.158,
  ]
  weights[1]: [
    -0.164, 0.237, 0.12, 0.397, -0.404, 0.216, 0.432, -0.0787,
    -0.835, -0.237, -0.442, 0.31, 0.4, 0.241, -0.0352, -0.698,
    -0.117, -0.0577, -0.0792, -0.00795, -0.342, 0.372, -0.233, 0.338,
    -0.00848, -0.126, -0.669, 0.133, -0.134, -0.229, 0.492, -0.0824,
  ]
  weights[2]: [
    -0.214, 0.227, -0.163, -0.612, -0.108, 0.0112, -0.0146, -0.844,
    -0.189, -0.033, -0.395, 0.245, -0.181, -0.729, 0.433, -0.243,
    -0.63, -0.873, -0.251, -0.0796, -0.185, 0.338, -0.0287, 0.176,
    0.216, -0.498, -0.0416, 0.452, -0.166, -0.337, -0.127, 0.0257,
  ]
  weights[3]: [
    -0.174, -0.264, 0.0738, -0.322, -0.0414, -0.656, 0.0271, 0.0671,
    0.378, -0.157, -0.175, -0.0315, -0.425, -0.25, 0.201, -0.335,
    0.493, -0.495, -0.221, -0.279, 0.255, 0.445, -0.23, 0.137,
    0.098, -1.03, -0.427, 0.617, -0.0979, -0.879, -0.91, -0.0163,
  ]
  weights[4]: [
    0.0656, 0.281, -0.159, -0.361, -0.16, -0.051, 0.326, 0.647,
    0.257, -0.274, -0.221, 0.458, -0.337, -0.296, 0.536, 0.0702,
    0.542, 0.458, -0.248, -0.218, 0.282, 0.823, 0.0522, 0.244,
    0.587, 0.304, -0.656, 0.49, 0.104, -0.146, -0.517, -0.0306,
  ]
  weights[5]: [
    -0.46, -0.472, -0.288, -0.102, 0.118, -0.55, -0.631, 0.526,
    0.43, 0.52, -0.268, -0.422, 0.0698, -0.413, -0.118, -0.0805,
    0.529, 0.794, -0.26, 0.102, 0.786, 0.096, -0.325, -0.107,
    0.283, 0.759, 0.293, 0.411, -0.562, 0.669, 0.0227, -0.737,
  ]
  weights[6]: [
    -0.824, 0.0323, -0.768, -0.435, -0.236, -0.0121, -0.337, 0.227,
    0.359, 0.0086, -0.451, -0.462, 0.0185, -0.488, -0.674, -0.127,
    0.347, 0.511, -0.106, -0.789, 0.251, -0.861, 0.0334, -0.303,
    -0.819, 0.335, -0.186, -0.11, -0.225, 0.509, -0.178, -0.126,
  ]
  weights[7]: [
    -0.0719, -0.139, -0.322, -0.373, 0.286, -0.2, -0.247, 0.234,
    -0.807, 0.041, -0.078, -0.125, -0.36, -0.798, -0.119, -1.09,
    0.201, 0.454, -0.0219, -0.0473, 0.197, -0.0218, 0.212, -0.258,
    -0.329, 0.209, -0.0324, -0.707, 0.0952, -0.0737, -0.384, 0.281,
  ]
  weights[8]: [
    0.219, 0.0105, 0.204, -0.257, 0.378, -0.327, -0.314, -0.666,
    -0.361, 0.402, 0.278, -0.197, -0.0958, -0.0801, -0.115, -0.058,
    -0.387, 0.116, 0.329, 0.277, -0.0163, -0.32, 0.273, -0.309,
    -0.264, 0.0436, -0.257, -0.191, 0.0582, -0.182, -0.409, 0.0785,
  ]
  weights[9]: [
    0.325, -0.0449, 0.639, 0.584, -0.0586, 0.329, -0.0212, -0.075,
    -0.279, 0.347, 0.157, -0.148, -0.102, 0.541, -0.158, 0.778,
    -0.293, -0.514, 0.361, 0.304, -0.321, -0.112, 0.347, 0.0212,
    0.258, -0.143, 0.407, -0.144, 0.481, -0.55, 0.0973, 0.191,
  ]
  biases: [
    -0.26, 0.167, 0.332, 0.174, 0.0442, -0.14, 0.0389, 0.321,
    0.214, -0.364,
  ]
layer: Activation
  function: Softmax
